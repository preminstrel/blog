<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on Blog de Preminstrel</title>
    <link>https://preminstrel.github.io/blog/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on Blog de Preminstrel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>preminstrel@gmail.com (Hanshi Sun)</managingEditor>
    <webMaster>preminstrel@gmail.com (Hanshi Sun)</webMaster>
    <lastBuildDate>Wed, 26 Jan 2022 17:47:40 +0800</lastBuildDate><atom:link href="https://preminstrel.github.io/blog/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Transformer</title>
      <link>https://preminstrel.github.io/blog/post/2022/01/26/transformer/</link>
      <pubDate>Wed, 26 Jan 2022 17:47:40 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/01/26/transformer/</guid>
      
      <description>&lt;p&gt;《Attention Is All You Need》是 Google 团队在 2017 年提出的一篇论文。该论文以“attention”为核心，提出了 Transformer 模型。Transformer 基于 Encoder-Decoder，摒弃了 CNNs，完全由 Attention mechanism 实现。&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;p&gt;传统 seq2seq 最大的问题在于将 Encoder 端的所有信息&lt;strong&gt;压缩到一个固定长度的向量&lt;/strong&gt;中，并将其作为 Decoder 端首个隐藏状态的输入，来预测 Decoder 端第一个单词(token)的隐藏状态。在输入序列比较长的时候，这样做显然会损失 Encoder 端的很多信息，而且这样一股脑的把该固定向量送入 Decoder 端，Decoder 端不能够关注到其想要关注的信息。并且模型计算不可并行，计算隐层状态 $h_t$ 依赖于 $h_{t-1}$ 以及状态 $t$ 时刻的输入，因此需要耗费大量时间。&lt;/p&gt;
&lt;p&gt;Transformer 完全依赖于 Attention Mechanism，解决了输入输出的长期依赖问题，并且拥有并行计算的能力，大大减少了计算资源的消耗。Self-Attention模块，让源序列和目标序列首先“自关联”起来，这样的话，源序列和目标序列自身的 embedding 表示所蕴含的信息更加丰富，而且后续的 FFN 层也增强了模型的表达能力。Muti-Head Attention 模块使得 Encoder 端拥有并行计算的能力。&lt;/p&gt;
&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;h3 id=&#34;structure&#34;&gt;Structure&lt;/h3&gt;
&lt;p&gt;Transformer 采用 Encoder-Decoder 架构，如下图所示。Encoder 层和 Decoder 层分别由 6 个相同的 Encoder 和decoder堆叠而成，模型架构更加复杂。其中，Encoder 层引入了 &lt;em&gt;&lt;strong&gt;Multi-Head&lt;/strong&gt;&lt;/em&gt; 机制，可以并行计算，Decoder 层仍旧需要串行计算。&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/Ml7Wiqra8TdAZv2&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/Ml7Wiqra8TdAZv2.png&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;Encoder 层和 Decoder 层内部结构如下图所示。&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/rCmxoUspEFbhfSd&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/rCmxoUspEFbhfSd.png&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Encoder 具有两层结构，&lt;strong&gt;Self-Attention 和前馈神经网络&lt;/strong&gt;。Self-Attention 计算句子中的每个词都和其他词的关联，从而帮助模型更好地理解上下文语义，引入 Muti-Head Attention 后，每个头关注句子的不同位置，增强了Attention 机制关注句子内部单词之间作用的表达能力。前馈神经网络为 Encoder 引入非线性变换，增强了模型的拟合能力。&lt;/li&gt;
&lt;li&gt;Decoder 接受 output 输入的&lt;strong&gt;同时接受 Encoder 的输入&lt;/strong&gt;，帮助当前节点获取到需要重点关注的内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multi-head-attention&#34;&gt;Multi-Head Attention&lt;/h3&gt;
&lt;p&gt;Multi-Head Attention 计算过程如下图，在讲解Multi-Head Attention 之前，我们需要了解Self-Attention。&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/vuW2BzLpKig3lrV&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/vuW2BzLpKig3lrV.png&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Query 与 Key 作用得到 Attention 的权值，之后这个权值作用在 Value 上得到 Attention值。&lt;/strong&gt; 这种通过 Query 和 Key 的相似性程度来确定 value 的权重分布的方法被称为 &lt;em&gt;&lt;strong&gt;scaled dot-product attention&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;$$\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^T}{\sqrt{D_k}})V$$&lt;/p&gt;
&lt;p&gt;这里给出我在知乎上看到的一个很不错的帖子里面的图片解释 scaled dot-product attention：&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/1VaBDNAm4S2Yex9&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/1VaBDNAm4S2Yex9.jpg&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;但是，在 Transformer 模型中，作者使用了 Muti-Head 机制代替了 single self-attention。&lt;/p&gt;
&lt;p&gt;$$
\text{MultiHead}(Q,K,V) =\text{Concat}\left(\text {head}_1, \ldots, \text{head}_h \right) W^{O}
$$&lt;/p&gt;
&lt;p&gt;$$
\text{where head}_{\mathrm{i}} =\operatorname{Attention}\left(QW_i^Q, KW_i^K, VW_i^V \right)
$$&lt;/p&gt;
&lt;p&gt;Where the projections are parameter matrices $W_{i}^{Q} \in \mathbb{R}^{d_{model} \times d_{k}}, W_{i}^{K} \in \mathbb{R}^{d_{model} \times d_{k}}, W_{i}^{V} \in \mathbb{R}^{d_{model} \times d_{v}}$ and $W^{O} \in \mathbb{R}^{h d_{v} \times d_{model}}$.&lt;/p&gt;
&lt;p&gt;论文中采用 8 个头，$h=8,d_{k}=d_{v}=d_{model} / h=64$。通过权重矩阵 $W_{i}^{Q},W_{i}^{K},W_{i}^{V}$ 将 $Q,K,V$ 分割，每个头分别计算 single self-attention，因为权重矩阵 $W_{i}^{Q},W_{i}^{K},W_{i}^{V}$ 不相同，$QW_i^Q,KW_i^K,VW_i^V$ 的结果各不相同，因此我们说每个头的关注点各有侧重。最后，将每个头计算出的 single self-attention 进行 concat，通过总的权重矩阵 $W^O$ 决定对每个头的关注程度，从而能够做到在不同语境下对相同句子进行不同理解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Attention 是将 Query 和 Key 映射到同一高维空间中去计算相似度，而对应的 Multi-head Attention 把 Query 和 Key 映射到高维空间 $\alpha$ 的不同子空间 $(\alpha_1,\alpha_2,\dots, \alpha_h)$ 中去计算相似度。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;position-wise-feed-forward&#34;&gt;Position-wise Feed Forward&lt;/h3&gt;
&lt;p&gt;$$\text{FFN}(x)=\max(0,xW_1+b_1)W_2+b_2$$&lt;/p&gt;
&lt;p&gt;每一层经过 Attention 之后，还会有一个 FFN，这个 FFN 的作用就是&lt;strong&gt;空间变换&lt;/strong&gt;。FFN 包含了 2 层 Linear Transformation 层，中间的激活函数是 ReLU。&lt;/p&gt;
&lt;p&gt;Attention 层的 output 最后会和 $W^O$ 相乘，为什么这里又要增加一个 2 层的 FFN 网络？其实，FFN 的加入&lt;strong&gt;引入了非线性(ReLu激活函数)，变换了 Attention Output 的空间, 从而增加了模型的表现能力&lt;/strong&gt;。把 FFN 去掉模型也是可以用的，但是效果差了很多。&lt;/p&gt;
&lt;h3 id=&#34;layer-normalization&#34;&gt;Layer Normalization&lt;/h3&gt;
&lt;p&gt;在每个 block 中，最后出现的是 Layer Normalization，其作用是规范优化空间，加速收敛。&lt;/p&gt;
&lt;p&gt;$$\text{LN}(x_i)=\alpha\frac{x_i-\mu_i}{\sqrt{\sigma^2+\xi}}+\beta$$&lt;/p&gt;
&lt;p&gt;当我们使用梯度下降算法做优化时，我们可能会对输入数据进行归一化，但是经过网络层作用后，我们的数据已经不是归一化的了。随着网络层数的增加，数据分布不断发生变化，偏差越来越大，导致我们不得不使用&lt;strong&gt;更小的学习率&lt;/strong&gt;来稳定梯度。Layer Normalization 的作用就是&lt;strong&gt;保证数据特征分布的稳定性&lt;/strong&gt;，将数据标准化到 ReLU 激活函数的作用区域，可以使得激活函数更好的发挥作用&lt;/p&gt;
&lt;h3 id=&#34;positional-encoding&#34;&gt;Positional Encoding&lt;/h3&gt;
&lt;p&gt;位置信息编码位于 Encoder 和 Decoder 的 Embedding 之后，每个 block 之前。它非常重要，没有这部分模型就无法运行。Positional Encoding 是 Transformer 的特有机制，弥补了 Attention 机制无法捕捉 sequence 中 token 位置信息的缺点。&lt;/p&gt;
&lt;p&gt;$$
PE_{(pos, 2i)}=\sin\left(pos/10000^{2i/d_{\text{model}}}\right)
$$&lt;/p&gt;
&lt;p&gt;$$
PE_{(pos,2i+1)}=\cos\left(pos/10000^{2i/d_{\text{model}}}\right)
$$&lt;/p&gt;
&lt;p&gt;Positional Embedding 的成分直接叠加于 Embedding 之上，使得每个 token 的&lt;strong&gt;位置信息&lt;/strong&gt;和它的&lt;strong&gt;语义信息&lt;/strong&gt;(embedding)充分融合，并被传递到后续所有经过复杂变换的序列表达中去。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Transformer 中，模型输入 Encoder 的每个 token 向量由两部分加和而成：Position Encoding + Input Embedding。Transformer 的特性使得输入 Encoder 的向量之间完全平等（不存在 RNN 的 recurrent 结构），token 的实际位置于位置信息编码唯一绑定。Positional Encoding 的引入使得模型能够充分利用 token 在 sequence 中的位置信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;论文中使用的 Positional Encoding(PE) 是正余弦函数，位置(pos)越小，波长越长，每一个位置对应的 PE 都是唯一的。同时作者也提到，之所以选用正余弦函数作为 PE，是因为这可以使得模型学习到 token 之间的相对位置关系：因为对于任意的偏移量 $k$，$PE_{pos+k}$ 可以由 $PE_{pos}$ 的线性表示，也就是 $PE_{pos}$ 乘上某个线性变换矩阵就得到了 $PE_{pos+k}$。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
P E_{(p o s+k, 2 i)}=\sin \left((p o s+k) / 10000^{2 i / d_{\text {model }}}\right)
$$$$
P E_{(p o s+k, 2 i+1)}=\cos \left((p o s+k) / 10000^{2 i / d_{\text {model }}}\right)
$$&lt;/p&gt;
&lt;h3 id=&#34;mask&#34;&gt;Mask&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Mask&lt;/strong&gt;&lt;/em&gt; 表示掩码，它&lt;strong&gt;对某些值进行掩盖，使其在参数更新时不产生效果&lt;/strong&gt;。Transformer 模型里面涉及两种 Mask，分别是 Padding Mask 和 Sequence Mask。其中，Padding Mask 在所有的 scaled dot-product attention 里面都需要用到，而 Sequence Mask 只有在 Decoder 的 Self-Attention 里面用到。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Padding Mask&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;什么是 Padding mask 呢？因为每个批次输入序列长度是不一样的也就是说，我们要对输入序列进行对齐。具体来说，就是给在较短的序列后面填充 0。但是如果输入的序列太长，则是截取左边的内容，把多余的直接舍弃。因为这些填充的位置，其实是没什么意义的，所以我们的 Attention 机制不应该把注意力放在这些位置上，所以我们需要进行一些处理。&lt;/p&gt;
&lt;p&gt;具体的做法是，把这些位置的值加上一个非常大的负数(负无穷)，这样的话，经过 softmax，这些位置的概率就会接近0！&lt;/p&gt;
&lt;p&gt;而我们的 Padding mask 实际上是一个张量，每个值都是一个Boolean，值为 False 的地方就是我们要进行处理的地方。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Sequence mask&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Sequence Mask 是为了使得 Decoder 不能看见未来的信息。也就是对于一个序列，在 time_step 为 t 的时刻，我们的解码输出应该只能依赖于 t 时刻之前的输出，而不能依赖 t 之后的输出。因此我们需要想一个办法，把 t 之后的信息给隐藏起来。&lt;/p&gt;
&lt;p&gt;具体办法是：&lt;strong&gt;产生一个上三角矩阵，上三角的值全为 0。把这个矩阵作用在每一个序列上，就可以达到我们的目的。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于 Decoder 的 Self-Attention，里面使用到的 scaled dot-product attention，同时需要 Padding Mask 和 Sequence mask 作为 attn_mask，具体实现就是两个 Mask 相加作为 attn_mask。其他情况，attn_mask 一律等于 Padding mask。&lt;/p&gt;
&lt;h3 id=&#34;linear--softmax&#34;&gt;Linear &amp;amp; Softmax&lt;/h3&gt;
&lt;p&gt;Decoder 最后是一个线性变换和 Softmax 层。解码组件最后会输出一个实数向量。我们如何把浮点数变成一个单词？这便是线性变换层要做的工作，它之后就是 Softmax 层。&lt;/p&gt;
&lt;p&gt;线性变换层是一个简单的全连接神经网络，它可以&lt;strong&gt;把解码组件产生的向量投射到一个比它大得多的、被称作对数几率（logits）的向量里&lt;/strong&gt;。不妨假设我们的模型从训练集中学习一万个不同的英语单词（我们模型的“输出词表”）。因此对数几率向量为一万个单元格长度的向量——每个单元格对应某一个单词的分数（&lt;strong&gt;相当于做 vocaburary_size 大小的分类&lt;/strong&gt;）。接下来的 Softmax 层便会把那些分数变成概率（都为正数、上限 1.0）。&lt;strong&gt;概率最高的单元格被选中，并且它对应的单词被作为这个时间步的输出。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;整体运行效果图如下：&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/7wBRdlvJnzeVUL9&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/7wBRdlvJnzeVUL9.gif&#34; &gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/311156298&#34;&gt;Transformer - Attention is all you need&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Self-Attention</title>
      <link>https://preminstrel.github.io/blog/post/2022/01/26/self-attention/</link>
      <pubDate>Wed, 26 Jan 2022 16:36:51 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/01/26/self-attention/</guid>
      
      <description>&lt;blockquote&gt;
&lt;p&gt;Attention is all you need.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最近刚接触到 Transformer，感觉其模型比 CNNs 要复杂了不少，看了一些论文也仅仅是草草看过，不理解其原理，在网上读了一些 blog，本次来进行一次总结。首先便是 Self-Attention 的公式&lt;/p&gt;
&lt;p&gt;$$\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^T}{\sqrt{D_k}})V$$&lt;/p&gt;
&lt;h2 id=&#34;terminology&#34;&gt;Terminology&lt;/h2&gt;
&lt;p&gt;公式种出现的 $Q,K,V$ 分别是 Query、Key、Value的缩写，我们的表达式如下：&lt;/p&gt;
&lt;p&gt;$$X W^Q=Q$$
$$XW^K=K$$
$$XW^V=V$$&lt;/p&gt;
&lt;p&gt;文章中所谓的 $Q,K,V$ 矩阵来源于 $X$ 与矩阵的乘积，本质上是 $X$ 的一系列的线性变换。做线性变换是为了提升模型的拟合能力，矩阵 $W$ 都是可以训练的，起到一个缓冲的效果。&lt;/p&gt;
&lt;p&gt;我们假设 $Q,K$ 种元素的均值为 0，方差为 1，$A^T=Q^TK$ 的均值为 0，方程为 $D$。当 $D$ 变得很大时，$A$ 中的元素的方差也会变得很大，如果 $A$ 中的元素方差很大，那么 $A$ 的分布会趋于陡峭(分布的方差大，分布集中在绝对值大的区域)。我们可以将分布“陡峭”程度与 $D$ 解耦，从而使得训练过程中梯度值保持稳定。&lt;/p&gt;
&lt;p&gt;$$A\leftarrow \dfrac{A}{\sqrt{D_k}}$$&lt;/p&gt;
&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;公式中的 $QK^T$ 表示的是 $Q,K$ 的内积，也可以说是一方在另一方的&lt;strong&gt;投影&lt;/strong&gt;，其大小也可以表示其&lt;strong&gt;相关性&lt;/strong&gt;。Softmax 是为了将一系列的值&lt;strong&gt;归一化&lt;/strong&gt;而存在的。&lt;/p&gt;
&lt;p&gt;$$\text{softmax}(z_k)=\frac{e^{z_k}}{\sum_{i=1}^Ie^{z_i}}$$&lt;/p&gt;
&lt;p&gt;而随后与 $V$ 的乘积，代表的是&lt;strong&gt;向量经过注意力机制加权求和之后的结果&lt;/strong&gt;。也就是说，softmax 管的是一个相关度权值大小，与后面的 $V$ 相乘，得到的是通过相关度权值标准而重新计算得到的量。&lt;/p&gt;
&lt;p&gt;对 Self-Attention 来说，它跟每一个输入的向量都做 Attention，所以没有考虑到输入的顺序。更通俗来讲，大家可以发现我们前文的计算每一个词向量都与其他词向量计算内积，得到的结果丢失了我们原来文本的顺序信息。对比来说，LSTM 是对于文本顺序信息的解释是输出词向量的先后顺序，而我们上文的计算对 sequence 的顺序这一部分则完全没有提及，你打乱词向量的顺序，得到的结果仍然是相同的，此处便可以引出 Transformer 的位置编码部分。&lt;strong&gt;Query 与 Key 作用得到 Attention 的权值，之后这个权值作用在 Value 上得到 Attention值。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Attention 机制的实现&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;math&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; sqrt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch.nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;Self_Attention&lt;/span&gt;(nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# input : batch_size * seq_len * input_dim&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# q : batch_size * input_dim * dim_k&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# k : batch_size * input_dim * dim_k&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# v : batch_size * input_dim * dim_v&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __init__(self,input_dim,dim_k,dim_v):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f&#34;&gt;super&lt;/span&gt;(Self_Attention,self)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;__init__()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;q &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(input_dim,dim_k)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;k &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(input_dim,dim_k)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;v &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(input_dim,dim_v)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;_norm_fact &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;/&lt;/span&gt; sqrt(dim_k)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;forward&lt;/span&gt;(self,x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        Q &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;q(x) &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Q: batch_size * seq_len * dim_k&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        K &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;k(x) &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# K: batch_size * seq_len * dim_k&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        V &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;v(x) &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# V: batch_size * seq_len * dim_v&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        atten &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Softmax(dim&lt;span style=&#34;color:#666&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;)(torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;bmm(Q,K&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;permute(&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;))) &lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;_norm_fact &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Q * K.T() # batch_size * seq_len * seq_len&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        output &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;bmm(atten,V) &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Q * K.T() * V # batch_size * seq_len * dim_v&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; output
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/410776234&#34;&gt;超详细图解Self-Attention&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Arrhythmia Classifier Using CNN With ALQ</title>
      <link>https://preminstrel.github.io/blog/post/2021/10/17/arrhythmia-classifier-using-cnn-with-alq/</link>
      <pubDate>Sun, 17 Oct 2021 13:37:23 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2021/10/17/arrhythmia-classifier-using-cnn-with-alq/</guid>
      
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;在许多医疗保健方案中，患者被诊断出患有各种各样的疾病，包括心血管疾病（CVDs），这是一种普遍的致命疾病。 心电图描述了人的心电活动，对准确诊断有重要意义。 但在早期，有些心律失常症状不明显，持续时间短，难以识别，导致严重后果。 因此，部署在低功耗设备上的实时心率检测成为人们关注的焦点。&lt;/p&gt;
&lt;p&gt;神经网络通过模拟人脑的层次结构实现数据的层次特征表达，具有强大的信息处理能力，促进了心电分类方法算法和模型的发展。 虽然神经网络模型的检测和分类精度看起来相当可观，但其庞大的可训练网络参数消耗大量内存，需要更多的时间进行复杂的计算，难以部署在低功耗的硬件平台上。 为了解决这个问题，我们考虑了网络结构的设计和自适应性的量化压缩方法。采用自适应位宽量化方法对模型误差进行优化，可以降低典型量化方法的精度下降，甚至提高模型误差的精度。 简单来说，我们的贡献有三个方面:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出了一种自适应损失感知量化算法（ALQ），以降低一维卷积神经网络的内存和功耗，同时保持甚至提高分类精度。&lt;/li&gt;
&lt;li&gt;基于我们的压缩方法，进一步提出了一种基于长时程心电片段分析的17层卷积神经网络（CNN）结构用于心律失常（17类）检测，实现了心律失常检测的总体准确率为93.5%。&lt;/li&gt;
&lt;li&gt;最后，我们实现了量化方法，在存储压缩率达到了 23.4 倍的情况下，分类的准确率达到了95.84%，说明了所提出的量化方法相对于以往方法的优越性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;
&lt;p&gt;参考论文：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Zhongnan Qu, Zimu Zhou, Yun Cheng, Lothar Thiele. Adaptive Loss-Aware Quantization for Multi-Bit Networks. In &lt;em&gt;the IEEE/CVF Conference on Computer Vision and Pattern Recognition&lt;/em&gt; (CVPR), 2020, pp. 7988-7997&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我根据Qu的论文提出的&lt;strong&gt;自适应损失感知量化  (Adaptive Loss-aware Quantization,ALQ)&lt;/strong&gt; 算法对ECGNet进行了量化压缩。论文中实现了Conv2d的情况，我修改模型后得到Conv1d的模型。在经过ALQ压缩后，能够实现大部分Layers低于 2 位，少部分Layers低于1位的平均位宽（average bitwidth）， 而不会降低模型的精度。 甚至，在量化之后，模型的精度有可能得到提高，达到95%的准确率。（一般来说会降低，这里我也不清楚为什么会提高，猜测有可能是量化压缩提高了正则化）&lt;/p&gt;
&lt;p&gt;量化解决方案通过最小化误差以重建全精度权重来训练量化器不同， ALQ 直接最小化损失函数上的量化引起的误差， 既不涉及梯度近似（gradient approximation）也不涉及全精度维护（full precision maintenance）。 ALQ 还利用了包括自适应位宽、 平滑位宽减少、 和迭代训练的量化，以允许更小的网络规模而不会损失准确性。&lt;/p&gt;
&lt;h2 id=&#34;methodology&#34;&gt;Methodology&lt;/h2&gt;
&lt;p&gt;在本节中，我们首先介绍分类器的架构概述，并描述我们的一维 CNN 架构的细节。在本节的最后，讨论了ALQ策略和一些ALQ参数的选择。整个提出的框架可以分为两部分，如图所示。&lt;/p&gt;
&lt;p&gt;第一部分是心律失常分类神经网络体系结构，该体系结构基于基本块设计，确定神经网络的深度。对模型进行训练后，得到的ECGNet的精度达到93.5%。模型参数应被保存，以便进行量化压缩。&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/FCWKTZGctHsUDM5&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/FCWKTZGctHsUDM5.png&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;第二部分是ALQ策略（Adaptive Loss-aware quantification）。网络中每一层对量化的敏感度是不同的。因此，假设我们给出的总比特数不变，对量化较敏感的层位数获得的位宽应该较大，而对量化较不敏感的层位获得的位宽应该较小，以达到更好的精度。该方法通过对 $\alpha$ 域的最小有效坐标进行剪枝来降低平均位宽，并在正确选择 $n$ 等参数的基础上优化二值化的基底 $B_k$ 和坐标 $\alpha_k$ 。该部分实现了对神经网络有效的压缩，不同于现有方法，成功避免了精度下降可，以满足较低的资源需求。&lt;/p&gt;
&lt;h3 id=&#34;ecgnet-model&#34;&gt;ECGNet Model&lt;/h3&gt;
&lt;p&gt;我们原创的心律失常分类卷积神经网络如图所示。该网络由若干基本块和两个线性层组成。基本块层包括一维卷积层和最大池化层，它们之间的激活为 ReLU。基本块用于特征提取，线性层用于分类。&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/L9ym6FfDrJVEoYH&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/L9ym6FfDrJVEoYH.png&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;输入是原始的长时间心电信号，由3600个采样点组成，持续时间为10秒。该网络无需对原始信号进行人工特征提取、特征分割和数据处理，即可实现端到端检测并推断出分类输出。在设计网络结构时，我们在网络规模和精度之间进行了权衡。最后，我们决定基本块的数量应该是7，因为这样的深度可以产生相当多的输出。同时，它保留了很小的网络参数。因此，我们最后得到的卷积神经网络是17层的。具体网络设计结构如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Layer&lt;/th&gt;
&lt;th&gt;Layer Name&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Other Layer Params&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Kernel $\times$ Unit&lt;/th&gt;
&lt;th&gt;Params&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Activation = ReLU, Strides=2, Padding=7&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$16\times 8$&lt;/td&gt;
&lt;td&gt;136&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Stride=4&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$8$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Activation = ReLU, Strides=2, Padding=5&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$12\times 12$&lt;/td&gt;
&lt;td&gt;1,164&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;4&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Stride=2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$4$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Activation = ReLU, Strides=1, Padding=4&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$9\times 32$&lt;/td&gt;
&lt;td&gt;3,488&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Stride=2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$5$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;7&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Activation = ReLU, Strides=1, Padding=3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$7\times 64$&lt;/td&gt;
&lt;td&gt;14,400&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;8&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Stride=2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$4$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;9&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Activation = ReLU, Strides=1, Padding=2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$5\times 64$&lt;/td&gt;
&lt;td&gt;20,544&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;10&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Stride=2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$2$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;11&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Activation = ReLU, Strides=1, Padding=1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$3\times 64$&lt;/td&gt;
&lt;td&gt;12,352&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;12&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Strides=2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$2$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;13&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Activation = ReLU, Strides=1, Padding=1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$3\times 72$&lt;/td&gt;
&lt;td&gt;13,896&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;14&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Strides=2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$2$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;15&lt;/td&gt;
&lt;td&gt;Flatten&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;16&lt;/td&gt;
&lt;td&gt;Linear&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Activation = ReLU, Dropout Rate=0.1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$1\times 216$&lt;/td&gt;
&lt;td&gt;13,888&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;17&lt;/td&gt;
&lt;td&gt;Linear&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Activation = ReLU&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$1\times 17$&lt;/td&gt;
&lt;td&gt;1,105&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Total params&lt;/strong&gt;: 80,973&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Params size&lt;/strong&gt;: 316.3KB&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;:  93.5%&lt;/p&gt;
&lt;h3 id=&#34;alq-algorithm&#34;&gt;ALQ Algorithm&lt;/h3&gt;
&lt;p&gt;尽管所提出的网络架构深度极小，但由于权值的位宽较大，心律失常检测网络仍然存在内存和功耗问题。由于不同层的重要性不同，采用自适应位宽对不同层进行量化是合理的，可以显著降低网络的平均位宽。我们采用自适应一维损耗多比特网络（MBNs）量化方法来帮助我们实现对原来提出的网络的压缩。&lt;/p&gt;
&lt;p&gt;在模型压缩中，通常通过   pruning ,  quantization,  distillation 等方法来压缩预训练模型。在 ECGNet 的压缩中，我们利用了量化压缩。我们通过将深度神经网络的 weights 和 activations 量化为 multi-bit networks (MBNs) 来实现模型的压缩。&lt;/p&gt;
&lt;p&gt;与将误差最小化的量化方法重建全精度权值不同，一维ALQ使损失函数的量化误差最小化。在此过程中，并不涉及梯度近似。在我们训练全精度ECGNet后，量化过程就可以开始了。为了提高压缩速度，引入了并行计算。对于向量化的权值 $w∈R^{N×1}$，将 $w$ 划分为 $m$ 个不相交的组。每组权重用 $w_k∈R^{n×1}$ 表示，其中 $N = n × m$，在二进制基础上可以表示量化的权重。&lt;/p&gt;
&lt;p&gt;$$\omega_k=\sum_{i=1}^{I_k}\alpha_i \beta_i=B_k\alpha_k,\quad \beta_i\in{-1,1}^{n\times 1}$$&lt;/p&gt;
&lt;p&gt;我们用 $I_k$ 来表示第 k 组的位宽，于是我们可以定义平均位宽为：&lt;/p&gt;
&lt;p&gt;$$\bar{I}=\frac{1}{m}\sum_{k=1}^m I_k$$&lt;/p&gt;
&lt;p&gt;我们的优化方案如下：&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/NY4k58hUmXreZdf&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/NY4k58hUmXreZdf.png&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 1 Full precision ECGNet&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这一步就是在本文第一部分中，对ECGNet进行全精度的训练。得到的数据需要进行保存，会用在后面两步之中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2 Pruning in $\alpha$ Domain&lt;/strong&gt;
在这一步中， 我们通过修剪最不重要的（w.r.t the loss） $\alpha$ 逐步减少Layer的平均位宽 $\bar{I}$  。   在这一步中， 我们只设置了一些元素 $\alpha$  为零。这一步会导致模型准确率的下降，但是我们会在Step 2中重新提高回来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 3: Optimizing Binary Bases $B_g$ and Coordinates $\alpha _g$&lt;/strong&gt;
在这一步中， 我们重新训练剩余的   binary bases 和 coordinates 来恢复因为Step 1中减少位宽引起的准确率的下降。在这个步骤中，我们首先固定 coordinates 来对搜索binary bases 进行最优搜索，然后再固定 binary bases 对coordinates进行搜索。经过优化之后，准确率重新提高了。&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result&lt;/h2&gt;
&lt;p&gt;ALQ量化压缩后七个卷积层和两个全连接层的平均位宽结果如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Layer&lt;/th&gt;
&lt;th&gt;Average Bitwidth&lt;/th&gt;
&lt;th&gt;Params&lt;/th&gt;
&lt;th&gt;Size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Conv1d_1&lt;/td&gt;
&lt;td&gt;1.2500&lt;/td&gt;
&lt;td&gt;136&lt;/td&gt;
&lt;td&gt;170 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Conv1d_2&lt;/td&gt;
&lt;td&gt;1.9896&lt;/td&gt;
&lt;td&gt;1,164&lt;/td&gt;
&lt;td&gt;2,316 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Conv1d_3&lt;/td&gt;
&lt;td&gt;1.7005&lt;/td&gt;
&lt;td&gt;3,488&lt;/td&gt;
&lt;td&gt;5,921 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Conv1d_4&lt;/td&gt;
&lt;td&gt;1.7095&lt;/td&gt;
&lt;td&gt;14,400&lt;/td&gt;
&lt;td&gt;24,617 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Conv1d_5&lt;/td&gt;
&lt;td&gt;1.4133&lt;/td&gt;
&lt;td&gt;20,544&lt;/td&gt;
&lt;td&gt;29,035 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Conv1d_6&lt;/td&gt;
&lt;td&gt;0.8545&lt;/td&gt;
&lt;td&gt;12,352&lt;/td&gt;
&lt;td&gt;10,555 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Conv1d_7&lt;/td&gt;
&lt;td&gt;0.8550&lt;/td&gt;
&lt;td&gt;13,896&lt;/td&gt;
&lt;td&gt;11,881 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Linear_1&lt;/td&gt;
&lt;td&gt;1.7422&lt;/td&gt;
&lt;td&gt;13,888&lt;/td&gt;
&lt;td&gt;24,196 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Linear_2&lt;/td&gt;
&lt;td&gt;2.0000&lt;/td&gt;
&lt;td&gt;1,105&lt;/td&gt;
&lt;td&gt;2210 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ALL&lt;/td&gt;
&lt;td&gt;1.3696&lt;/td&gt;
&lt;td&gt;80973&lt;/td&gt;
&lt;td&gt;110901 bit= 13.538 KB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;可以看到，316.3KB的模型经过压缩后变成了13.538KB，平均位宽为1.3696。压缩率为23.36x。&lt;/p&gt;
&lt;p&gt;准确率上，甚至还上升了，达到了95%，上升了1.5%。&lt;/p&gt;
&lt;p&gt;归一化后的混淆矩阵如下图：&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/vUbhQkWmIeusolR&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/vUbhQkWmIeusolR.png&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
</description>
      
    </item>
    
    <item>
      <title>Quantization Compression</title>
      <link>https://preminstrel.github.io/blog/post/2021/10/17/quantization-compression/</link>
      <pubDate>Sun, 17 Oct 2021 10:48:26 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2021/10/17/quantization-compression/</guid>
      
      <description>&lt;p&gt;本文参考&lt;a href=&#34;https://jackwish.net/2019/neural-network-quantization-introduction-chn.html&#34;&gt;此博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;量化有若干相似的术语。&lt;strong&gt;低精度&lt;/strong&gt;（Low precision）可能是最通用的概念。常规精度一般使用 FP32（32位浮点，单精度）存储模型权重；低精度则表示 FP16（半精度浮点），INT8（8位的定点整数）等等数值格式。不过目前低精度往往指代 INT8。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;量化&lt;/strong&gt;一般指 INT8 。不过，根据存储一个权重元素所需的位数，还可以包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1602.02830&#34;&gt;二值神经网络&lt;/a&gt;：在运行时权重和激活只取两种值（例如 +1，-1）的神经网络，以及在训练时计算参数的梯度。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1605.04711&#34;&gt;三元权重网络&lt;/a&gt;：权重约束为+1,0和-1的神经网络。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1603.05279&#34;&gt;XNOR网络&lt;/a&gt;：过滤器和卷积层的输入是二进制的。 XNOR 网络主要使用二进制运算来近似卷积。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;工业界最终选择了 INT8 量化—— FP32 在推理（inference）期间被 INT8 取代，而训练（training）仍然是 FP32。&lt;a href=&#34;http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf&#34;&gt;TensorRT&lt;/a&gt;，&lt;a href=&#34;https://www.tensorflow.org/lite/performance/post_training_quantization&#34;&gt;TensorFlow&lt;/a&gt;，&lt;a href=&#34;https://github.com/pytorch/glow/blob/master/docs/Quantization.md&#34;&gt;PyTorch&lt;/a&gt;，&lt;a href=&#34;https://github.com/apache/incubator%20-mxnet/blob/master/python/mxnet/contrib/quantization.py&#34;&gt;MxNet&lt;/a&gt; 和许多其他深度学习软件都已启用（或正在启用）量化。&lt;/p&gt;
&lt;p&gt;通常，可以根据 FP32 和 INT8 的转换机制对解决方案进行分类。一些框架简单地引入了 &lt;code&gt;Quantize&lt;/code&gt; 和 &lt;code&gt;Dequantize&lt;/code&gt; 层，当从卷积或全链接层送入或取出时，它将 FP32 转换为 INT8 或相反。在这种情况下，如图的上半部分所示，模型本身和输入/输出采用 FP32 格式。深度学习框架加载模型，重写网络以插入&lt;code&gt;Quantize&lt;/code&gt; 和 &lt;code&gt;Dequantize&lt;/code&gt; 层，并将权重转换为 INT8 格式。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/Mfj8QXZxsqUSRna&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/Mfj8QXZxsqUSRna.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其他一些框架将网络整体转换为 INT8 格式，因此在推理期间没有格式转换，如图的下半部分。该方法要求算子（Operator）都支持量化，因为运算符之间的数据流是INT8。对于尚未支持的那些，它可能会回落到 Quantize/Dequantize 方案。下文的讨论都基于这种方式。&lt;/p&gt;
&lt;p&gt;由于 INT8 使用的比特数只有 FP32 的 25% ，在 INT8 和 FP32 之间转换数值的方法非常重要，因为它会显着影响预测精度。&lt;/p&gt;
&lt;h2 id=&#34;量化的算术&#34;&gt;量化的算术&lt;/h2&gt;
&lt;p&gt;量化过程可以分为两部分：&lt;strong&gt;将模型从 FP32 转换为 INT8，以及使用 INT8 进行推理&lt;/strong&gt;。本节说明这两部分背后的&lt;strong&gt;算术原理&lt;/strong&gt;。如果不了解基础算术原理，在考虑量化细节时通常会感到困惑。&lt;/p&gt;
&lt;h3 id=&#34;定点和浮点&#34;&gt;定点和浮点&lt;/h3&gt;
&lt;p&gt;从事计算机科学的人很少了解算术运算的执行方式。由于量化桥接了固定点（fixed point）和浮点（floating point），在接触相关研究和解决方案之前，有必要先了解它们的基础知识。&lt;/p&gt;
&lt;p&gt;定点和浮点都是数值的表示（representation），它们区别在于，将整数（integer）部分和小数（fractional）部分分开的点，点在哪里。 &lt;strong&gt;定点保留特定位数整数和小数，而浮点保留特定位数的有效数字（significand）和指数（exponent）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/Xli9bQO3GjZmzwI&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/Xli9bQO3GjZmzwI.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上图给出了定点和浮点表示的格式和示例。对于定点，II 表示整数，FF 表示 IIIII.FFFFF中的分数。对于浮点数，base分别为二进制、十进制和十六进制格式的 2、10 和 16 。定点和浮点的数值示例在图中是一一对应的。&lt;/p&gt;
&lt;p&gt;在指令集（Instruction Set Architecture）的内置数据类型中，&lt;strong&gt;定点是整数，浮点是二进制格式&lt;/strong&gt;。一般来说，指令集层面的定点是连续的，因为它是整数，且两个邻近的可表示数字的间隙是 1 。另一方面，浮点代表实数，其数值间隙由指数确定，因而具有非常宽的值域（32 位数值最大整数是 $2^{31}−1$，而浮点值域为 $(2−2^{-23})×2^{127}$），值越接近零就越准确。一个观察结果是，在给定指数时，浮点在不同范围内拥有数值数量相同数量，如下图。例如，$[1,2)$中浮点值的数量与 $[0.5,1)、[2,4]、[4,8]$等相同。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/8CBADo39zfO5FPR&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/8CBADo39zfO5FPR.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;浮点运算可以由整数运算组成，在计算机发展的早期，浮点计算都是用软件在定点硬件上模拟的。下面的等式展示了如何将浮点乘法用定点乘法和加法表示。加法的表示方法要复杂得多，这里不做进一步讨论，有需求的可以参考计算机体系结构相关资料。&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
z &amp;amp;=x \times y \\
z_{\text {significand }} \times b a s e^{z_{\text {exponent }}} &amp;amp;=\left(x_{\text {significand }} \times \text { base }^{x_{exponent }}\right) \times\left(y_{\text {significand }} \times \text { base }^{y_{{exponent }}}\right) \\
&amp;amp;=\left(x_{\text {significand }} \times y_{\text {significand }}\right) \times\left(\text { base }^{x_{exponent }} \times \text { base }^{y_{exponent}}\right) \\
&amp;amp;=\left(x_{\text {significand }} \times y_{\text {significand }}\right) \times \text { base }^{x_{exponent}+y_{exponent }}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;实际上，在上面有效数字的整数乘法之后，当乘法结果相对于表示范围太大时，通常需要&lt;strong&gt;重新缩放&lt;/strong&gt;，如下图。&lt;strong&gt;重新缩放移动将有效数字结果的一部分转移到指数&lt;/strong&gt;，并以最近舍入方法舍入剩余的有效数字。图的右半部分是一个例子。&lt;strong&gt;由于部分数字被舍弃，浮点乘法会丢失一些信息&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;量化浮点&#34;&gt;量化浮点&lt;/h3&gt;
&lt;p&gt;神经网络由浮点运算构成。如&lt;a href=&#34;https://jackwish.net/2019/%EF%BC%83fixed-point-and-floating-point&#34;&gt;定点与浮点&lt;/a&gt;所述，FP32 和 INT8 的值域是$[(2−2^{-23})×2^{127},(2^{23}-2)×2^{127}]$ 和 $[−128,127]$，而取值数量大约分别为 $2^{32}$ 和 $2^8$ 。因此，&lt;strong&gt;将网络从 FP32 转换为 INT8 并不像数据类型转换截断那样简单&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;幸运的是，&lt;strong&gt;神经网络权重的值分布范围很窄，非常接近零&lt;/strong&gt;。下图给出了 MobileNetV1 中十层（拥有最多值的层）的权重分布。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/ECAOkrn1HR7TBLa&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/ECAOkrn1HR7TBLa.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当值落在 $(−1,1)$ 中，量化浮点使用类似$x_{float}=x_{scale}\times x_{quantized}$ 的方法将 FP32 映射到 INT8，其中 $x_{float}$ 表示 FP32 权重，$x_{quantized}$ 表示量化的 INT8 权重，$x_{scale}$ 是映射因子（缩放因子）。有时我们不希望将 FP32 零映射到 INT8 零，即&lt;a href=&#34;https://en.wikipedia.org/wiki/Digital_signal_processing&#34;&gt;数字信号处理&lt;/a&gt;中的&lt;a href=&#34;https://en.wikipedia.org/wiki/Quantization_(signal_processing)&#34;&gt;均一量化&lt;/a&gt;和如下等式 。&lt;/p&gt;
&lt;p&gt;$$x_{float}=x_{scale}\times (x_{quantized}−x_{zero\_point})$$&lt;/p&gt;
&lt;p&gt;大多数情况下量化选用无符号整数，那么 INT8 值域为 $[0,255]$ 。zero_point 在这种情况下更有意义。具体而言，如下面的 等式所示，量化浮点值可以分为两个步骤&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过在权重张量（Tensor）中找到 &lt;em&gt;min&lt;/em&gt; 和 &lt;em&gt;max&lt;/em&gt; 值从而确定 $x_{scale}$ 和$x_{zero_point}$。&lt;/li&gt;
&lt;li&gt;将权重张量的每个值从 FP32 转换为 INT8 。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\begin{aligned}
x_{\text {float }} &amp;amp; \in\left[x_{\text {float }}^{\min }, x_{\text {float }}^{\max }\right] \\
x_{\text {scale } &amp;amp;=\frac{x_{\text {float }}^{\max }-x_{\text {float }}^{\text {min }}}{x_{\text {quantized }}^{\max }-x_{\text {quantized }}^{\min }} \\
x_{\text {zero_point }} &amp;amp;=x_{\text {quantized }}^{\max }-x_{\text {float }}^{\max } \div x_{\text {scale }} \\
x_{\text {quantized }} &amp;amp;=x_{\text {float }} \div x_{\text {scale }}+x_{\text {zero_point }}
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意，当浮点运算结果不等于整数时，需要额外的舍入步骤&lt;/strong&gt;。例如将 FP32 值域 $[−1,1]$ 映射到 INT8 值域 $[0,255]$，有 $x_{scale}=\frac{2}{255}$，而$x_{zero_point}=255−\frac{255}{2}\approx 127$。&lt;/p&gt;
&lt;p&gt;量化过程中存在误差是不可避免的，就像数字信号处理中量化一样。下图显示了数字信号处理的&lt;a href=&#34;https://en.wikipedia.org/wiki/Quantization_(signal_processing)#Quantization_error_models&#34;&gt;量化和误差&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/8CBADo39zfO5FPR&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/8CBADo39zfO5FPR.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;
&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;
&lt;p&gt;量化并不是什么新知识，我们在对图像做预处理时就用到了量化。回想一下，我们通常会将一张 uint8 类型、数值范围在 0~255 的图片归一成 float32 类型、数值范围在 0.0~1.0 的张量，这个过程就是反量化。类似地，我们经常将网络输出的范围在 0.0~1.0 之间的张量调整成数值为 0~255、uint8 类型的图片数据，这个过程就是量化。所以量化本质上只是对数值范围的重新调整，可以「粗略」理解为是一种线性映射。(之所以加「粗略」二字，是因为有些论文会用非线性量化，但目前在工业界落地的还都是线性量化，所以本文只讨论线性量化的方案)。&lt;/p&gt;
&lt;p&gt;不过，可以明显看出，反量化一般没有信息损失，而量化一般都会有精度损失。这也非常好理解，float32 能保存的数值范围本身就比 uint8 多，因此必定有大量数值无法用 uint8 表示，只能四舍五入成 uint8 型的数值。量化模型和全精度模型的误差也来自四舍五入的 clip 操作。&lt;/p&gt;
&lt;p&gt;我们用 $r$  表示&lt;strong&gt;浮点实数&lt;/strong&gt;，$q$  表示&lt;strong&gt;量化后的定点整数&lt;/strong&gt;。&lt;strong&gt;浮点和整型之间的换算公式&lt;/strong&gt;为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$$r=S(q-Z)$$
$$q=round(\frac{r}{S}+Z)$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其中，$S$ 是 &lt;em&gt;scale&lt;/em&gt;，表示&lt;strong&gt;实数和整数之间的比例关系&lt;/strong&gt;，$Z$  是 &lt;em&gt;zero point&lt;/em&gt;，表示&lt;strong&gt;实数中的 0 经过量化后对应的整数&lt;/strong&gt;，它们的计算方法为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$$S=\frac{r_{max}-r_{min}}{q_{max}-q_{min}}$$
$$Z = round(q_{max}-\frac{r_{max}}{S})$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$r_{max}, r_{min}$ 分别是 $r$ 的最大值和最小值；$q_{min}, q_{max}$ 同理。需要强调的一点是，定点整数的 zero point 就代表浮点实数的 0，二者之间的换算不存在精度损失。 这么做的目的是为了在 padding 时保证浮点数值的 0 和定点整数的 zero point 完全等价，保证定点和浮点之间的表征能够一致。&lt;/p&gt;
&lt;h3 id=&#34;矩阵运算的量化&#34;&gt;矩阵运算的量化&lt;/h3&gt;
&lt;p&gt;由于卷积网络中的卷积层和全连接层本质上都是一堆矩阵乘法，因此我们先看如何将&lt;strong&gt;浮点运算上的矩阵转换为定点运算&lt;/strong&gt;。
假设 $r_1,r_2$ 是浮点实数上的两个 $N\times N$ 的矩阵，$r_3$ 是 $r_1,r_2$ 相乘后的矩阵
$$r_3^{i,k}=\sum_{j=1}^N r_1^{i,j}r_2^{j,k}$$
假设  $S_1,Z_1$ 是 $r_1$ 矩阵对应的 scale 和 zero point，$S_2,Z_2,S_3,Z_3$ 同理，那么可以推出：
$$S_3(q_3^{i,k}-Z_3)=\sum_{j=1}^NS_1(q_1^{i,k}-Z_1)S_2(q_2^{i,k}-Z_2)$$
整理得到 $$q_3^{i,k}=\frac{S_1S_2}{S_3}\sum_{j=1}^N (q^{i,j}_1-Z_1)(q^{i,j}_2-Z_2)+Z_3$$&lt;/p&gt;
&lt;p&gt;除了 $\frac{S_1S_2}{S_3}$ ，其他都是定点整数运算。那如何把  $\frac{S_1S_2}{S_3}$ 也变成定点运算呢？这里要用到一个 &lt;em&gt;trick&lt;/em&gt;。假设 $M=\frac{S_1S_2}{S_3}$  ，由于 $M$ 通常都是 $(0, 1)$之间的实数 (这是通过大量实验统计出来的)，因此可以表示成 $M=2^{-n}M_0$，其中 $M_0$  是一个定点实数。注意，定点数并不一定是整数，所谓定点，指的是小数点的位置是固定的，即小数位数是固定的。因此，如果存在 $M=2^{-n}M_0$，那我们就可以通过 $M_0$ 的 bit 位移操作实现 $M=2^{-n}M_0$ ，这样整个过程就都在定点上计算了。&lt;/p&gt;
&lt;p&gt;很多刚接触量化的同学对这一点比较疑惑，下面我就用一个简单的示例说明这一点。我们把 $M=\frac{S_1S_2}{S_3}$  代入可以得到：$$q_3^{i,j}=M\sum_{j=1}^N (q_1^{i,j}-Z_1)(q_2^{i,j}-Z_2)+Z_3=MP+Z_3$$&lt;/p&gt;
&lt;p&gt;这里面 $P$  是一个在&lt;strong&gt;定点域上计算好的整数&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;假设 $P = 7091,M = 0.0072474273418460$  ($M$ 可以通过 $S$ 事先计算得到)，那下面我们就是要找到一个 $M_0$ 和 $n$ ，使得 $M P =2^{-n}M_0 P$ 成立。我们可以用一段代码来找到这两个数：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;M &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0.0072474273418460&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;P &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;7091&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;multiply&lt;/span&gt;(n, M, P):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    result &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; M &lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt; P
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Mo &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;int&lt;/span&gt;(&lt;span style=&#34;color:#a2f&#34;&gt;round&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;**&lt;/span&gt; n &lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt; M)) &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 这里不一定要四舍五入截断，因为python定点数不好表示才这样处理&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    approx_result &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; (Mo &lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt; P) &lt;span style=&#34;color:#666&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; n
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#34;n=&lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;, Mo=&lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;, approx=&lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%f&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;, error=&lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%f&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;%&lt;/span&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          (n, Mo, approx_result, result&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;approx_result))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; n &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;16&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    multiply(n, M, P)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，在 $n=11、M_0=15$ 的时候，误差就已经在 1 以内了。因此，只要 $M_0P$ 的数值范围在 21(32-11) 个 bit 内，就可以通过对 $M_0P$ 右移 $n$ 个 bit 来近似 $MP$ 了，而这个误差本身在可以接受的范围内。这样一来，就可以完全通过定点运算来计算，即我们实现了&lt;strong&gt;浮点矩阵乘法的量化&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;卷积网络的量化&#34;&gt;卷积网络的量化&lt;/h3&gt;
&lt;p&gt;有了上面矩阵乘法的量化，我们就可以进一步尝试对卷积网络的量化。假设一个这样的网络：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://preminstrel.github.io/blog/img/20210916190953.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这个网络只有三个模块，现在需要把 &lt;em&gt;conv、fc、relu&lt;/em&gt; 量化。&lt;/p&gt;
&lt;p&gt;假设输入为 $x$，可以事先统计样本的最大值和最小值，然后计算出 $S_x$ (scale) 和 $Z_x$ (zero point)。
同样地，假设 &lt;em&gt;conv、fc&lt;/em&gt; 的参数为 $w_1, w_2$，以及 scale 和 zero point 为 $S_{w1},Z_{w1},S_{w2},Z_{w2}$ 。中间层的 feature map 为 $a_1,a_2$ ，事先统计出它们的 scale 和 zero point 为 $S_{a1},Z_{a1},S_{s2},Z_{a2}$。&lt;/p&gt;
&lt;p&gt;卷积运算和全连接层的本质都是矩阵运算，因此我们可以把卷积运算表示成 (这里先忽略加 bias 的操作，这一步同样可以量化，不过中间有一些 trick，我们在之后的文章再仔细研究)：
$$a_1^{i,k}=\sum_{j=1}^N x^{i,j}w_1^{i,j}$$
$$q_{a1}^{i,k}=M\sum_{j=1}^N (q_x^{i,j}-Z_x)(q_{w1}^{i,j}-Z_{w1})+Z_{a1}$$
其中 $M=\dfrac{S_{w1}S_{x}}{S_{a1}}$。得到 conv 的输出后，不用反量化回  $a_1$ ，直接用  $q_{a1}$ 继续后面的计算即可。&lt;/p&gt;
&lt;p&gt;对于量化的 RuLU 来说，计算公式不再是 $q_{a2}=max(q_{a1},0)$，而是 $q_{a2}=max(q_{a1},Z_{a1})$，并且 $S_{a1}=S_{a2},Z_{a1}=Z_{a2}$。在部署的时候，ReLU 或者 BN 通常是会整合到 conv 中一起计算的。&lt;/p&gt;
&lt;p&gt;得到 $q_{a2}$ 之后，我们可以计算 fc 层。假设网络输出为 $y$ ，对应的 scale 和zero_point 为 $S_y,Z_y$ ，则量化之后的  fc 层可以用如下公式来计算：
$$
q_{y}^{i, k}=M \sum_{j=1}^{N}\left(q_{a 2}^{i, j}-Z_{a 2}\right)\left(q_{w 2}^{j, k}-Z_{w 2}\right)+Z_{y}
$$&lt;/p&gt;
&lt;p&gt;然后通过公式 $y=S_y(q_y-Z_y)$ 把结果反量化回去，就可以得到近似原来全精度模型的输出了。&lt;/p&gt;
&lt;p&gt;可以看到，上面整个流程都是用定点运算实现的。我们在得到全精度的模型后，可以事先统计出 weight 以及中间各个 feature map 的 min、max，并以此计算出 scale 和 zero point，然后把 weight 量化成 int8/int16 型的整数后，整个网络便完成了量化，然后就可以依据上面的流程做量化推理了。&lt;/p&gt;
&lt;h2 id=&#34;model-size&#34;&gt;Model Size&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;网络的大小取决于Parameter的数量，如果是float32，就是$Parameters\times 4$&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Pytorch Basics</title>
      <link>https://preminstrel.github.io/blog/post/2021/10/17/pytorch-basics/</link>
      <pubDate>Sun, 17 Oct 2021 00:25:41 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2021/10/17/pytorch-basics/</guid>
      
      <description>&lt;h2 id=&#34;01-overview&#34;&gt;01. Overview&lt;/h2&gt;
&lt;h3 id=&#34;dl--ml&#34;&gt;DL &amp;amp; ML&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/waqHslfANR42hpy&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/waqHslfANR42hpy.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维度诅咒：维度越高，需要的训练集越大&lt;/li&gt;
&lt;li&gt;深度学习和机器学习的区别：多了一层用来提取特征的层。传统的机器学习中（无标签），Feature是单独做训练的，后面的Mapping from features和它是分开的。但是在深度学习中，这个是统一的。所以深度学习也称为 &lt;strong&gt;End to End&lt;/strong&gt; 的学习方式。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;route&#34;&gt;Route&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/sBkG98xylAX3SLv&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/sBkG98xylAX3SLv.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;gradient-descent&#34;&gt;Gradient Descent&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;6&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;w&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;forward&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; x&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;w
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;loss&lt;/span&gt;(xs,ys):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; x,y &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;zip&lt;/span&gt;(xs,ys):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y_pred &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; forward(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        loss &lt;span style=&#34;color:#666&#34;&gt;+=&lt;/span&gt; (y_pred&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;y)&lt;span style=&#34;color:#666&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; loss&lt;span style=&#34;color:#666&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;len&lt;/span&gt;(xs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;gradient&lt;/span&gt;(xs,ys):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    grad&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; x,y &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;zip&lt;/span&gt;(xs,ys):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        grad &lt;span style=&#34;color:#666&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;x&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;(x&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;w&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;y)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; grad&lt;span style=&#34;color:#666&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;len&lt;/span&gt;(xs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;Predict(before training)&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt;, forward(&lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    loss_val &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; loss(x_data, y_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    grad_val &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; gradient(x_data, y_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    w &lt;span style=&#34;color:#666&#34;&gt;-=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0.01&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;grad_val
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;Epoch:&amp;#39;&lt;/span&gt;, epoch, &lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;w=&amp;#39;&lt;/span&gt;,w,&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;loss=&amp;#39;&lt;/span&gt;,loss_val)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;Predict(After training)&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt;, forward(&lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/eRJhsuFPBN6EmpS&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/eRJhsuFPBN6EmpS.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;随机梯度下降的计算无法并行，计算中是有依赖的&lt;/li&gt;
&lt;li&gt;随机梯度下降的性能更好，但是无法并行，所以速度比较慢&lt;/li&gt;
&lt;li&gt;所以我们用&lt;strong&gt;mini-batch&lt;/strong&gt;，批量随机梯度下降，这是一种折中的方法&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;前向传播和反向传播&#34;&gt;前向传播和反向传播&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/L7qQ6NhfiS8WOKt&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/L7qQ6NhfiS8WOKt.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;02-linear-model&#34;&gt;02. Linear Model&lt;/h2&gt;
&lt;h3 id=&#34;tensor--linear-model&#34;&gt;Tensor &amp;amp; Linear Model&lt;/h3&gt;
&lt;p&gt;In PyTorch, Tensor is the important component in &lt;strong&gt;constructing dynamic
computational graph&lt;/strong&gt;. It contains &lt;strong&gt;data and grad&lt;/strong&gt;, which storage the value of node and gradient w.r.t loss respectively.
如下代码是在构造计算图，在Pytorch中我们需要这样看待它。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;6&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;w &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Tensor([&lt;span style=&#34;color:#666&#34;&gt;1.0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;w&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;requires_grad &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;forward&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; x &lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt; w
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;loss&lt;/span&gt;(x,y):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y_pred &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; forward(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; (y_pred&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;y) &lt;span style=&#34;color:#666&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;训练过程&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;sum&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; x, y &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;zip&lt;/span&gt;(x_data, y_data): &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 抽取样本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        l &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; loss(x, y)     &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 前馈：计算loss，计算完释放&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        l&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;backward()                 &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 反馈&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;grad:&amp;#39;&lt;/span&gt;, x, y, w&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;grad&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item())  &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;#item是一个标量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        w&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; w&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;data &lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0.01&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt; w&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;grad&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;data  &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 注意此时grad要取到data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f&#34;&gt;sum&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;+=&lt;/span&gt; l&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item()              &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 计算损失和&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        w&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;grad&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;zero_()             &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 清零梯度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#34;progress:&amp;#34;&lt;/span&gt;, epoch, l&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item())
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;NOTICE&lt;/strong&gt;:
The grad computed by &lt;code&gt;.backward()&lt;/code&gt; will be accumulated. So after update, &lt;strong&gt;remember set the grad to ZERO!!&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.data&lt;/code&gt;返回的是一个Tensor，而&lt;code&gt;.item()&lt;/code&gt;返回的是具体的数值（非Tensor数据类型）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;framework&#34;&gt;Framework&lt;/h3&gt;
&lt;p&gt;4个步骤：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prepare dataset&lt;/strong&gt; : we shall talk about this later&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Design model using Class&lt;/strong&gt;: inherit from nn.Module&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Construct loss and optimizer&lt;/strong&gt;: using PyTorch API&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Training cycle&lt;/strong&gt;: forward, backward, update&lt;/p&gt;
&lt;h4 id=&#34;prepare-dataset&#34;&gt;Prepare dataset&lt;/h4&gt;
&lt;p&gt;In PyTorch, the computational graph is in mini-batch fashion, so X and Y are $3 \times 1$ Tensors.&lt;/p&gt;
&lt;p&gt;$$\hat{y}=w\cdot x+b$$
$$\left[\begin{aligned}&amp;amp;y_{pred}^{(1)}\\ &amp;amp;y_{pred}^{(2)} \\ &amp;amp;y_{pred}^{(3)} \end{aligned}\right]=w\cdot \left[\begin{aligned}&amp;amp;x^{(1)}\\ &amp;amp;x^{(2)} \\ &amp;amp;x^{(3)}\end{aligned}\right]+b$$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Tensor([[&lt;span style=&#34;color:#666&#34;&gt;1.0&lt;/span&gt;], [&lt;span style=&#34;color:#666&#34;&gt;2.0&lt;/span&gt;], [&lt;span style=&#34;color:#666&#34;&gt;3.0&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Tensor([[&lt;span style=&#34;color:#666&#34;&gt;2.0&lt;/span&gt;], [&lt;span style=&#34;color:#666&#34;&gt;4.0&lt;/span&gt;], [&lt;span style=&#34;color:#666&#34;&gt;6.0&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;design-model&#34;&gt;Design Model&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;LinearModel&lt;/span&gt;(torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __init__(self):     &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 构造函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f&#34;&gt;super&lt;/span&gt;(LinearModel, self)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;__init__()  &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 调用父类的构造&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;)     &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 构造对象&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;forward&lt;/span&gt;(self, x):    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 必须有forward传播函数的定义&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y_pred &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; y_pred
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; LinearModel()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nn.Linear&lt;/code&gt; contain two member Tensors: &lt;strong&gt;weight&lt;/strong&gt; and &lt;strong&gt;bias&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;torch&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(in_features, out_features, bias &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Applies a linear transformation $y=Ax+b$
Parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in_features: the size of each input sample&lt;/li&gt;
&lt;li&gt;out_features: the size of each output sample&lt;/li&gt;
&lt;li&gt;bias: Default: True&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;实际上，在运算过程中是&lt;strong&gt;做转置的&lt;/strong&gt;
$$y=x\cdot w+b$$
$$y = w^{T}\cdot x+b$$&lt;/p&gt;
&lt;h4 id=&#34;construct-loss-and-optimizer&#34;&gt;Construct Loss and Optimizer&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;criterion &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;MSELoss(size_average&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;optimizer &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;optim&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;SGD(model&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parameters(), lr&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;0.01&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;torch&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;MSELoss(size_average, reduce &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;求均方根值 $l(x,y)=L={l_1,\cdots,l_N}^{T},\quad l_n=(x_n-y_n)^2$
其中，N是batch size。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;torch&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;optim&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;SGD(params, lr&lt;span style=&#34;color:#666&#34;&gt;=&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;object&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;object&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;&amp;gt;&lt;/span&gt;, momentum &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;, dampening &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;, weight_decay &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;, nesterov &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Implements stochastic gradient descent (optionally with momentum)&lt;/p&gt;
&lt;h4 id=&#34;training-cycle&#34;&gt;Training Cycle&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y_pred &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; model(x_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; criterion(y_pred, y_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(epoch, loss)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;zero_grad()  &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 注意梯度清零&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;backward()        &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 反向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;step()       &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;#Update&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;test-model&#34;&gt;Test Model&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Output weight and bias&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;w=&amp;#39;&lt;/span&gt;, model&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;weight&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;b=&amp;#39;&lt;/span&gt;, model&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;bias&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Test Model&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x_test &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Tensor([&lt;span style=&#34;color:#666&#34;&gt;4.0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y_test &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; model(x_test)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;y_pred=&amp;#39;&lt;/span&gt;, y_test&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;data)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;03-logistic-regression&#34;&gt;03. Logistic Regression&lt;/h2&gt;
&lt;h3 id=&#34;one-dimension&#34;&gt;One Dimension&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/RfLNkZoim74CDsu&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/RfLNkZoim74CDsu.png&#34; &gt;&lt;/a&gt;
Logistic function can guarantee that the output is in $[0,1]$, and loss function is $$loss=-(y\log \hat{y}+(1-y)\log (1-\hat{y}))$$
此时误差计算的是分布的差异 &lt;strong&gt;(BCE)&lt;/strong&gt;，而不是几何上的距离。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Mini-Batch Loss Function for Binary Classification
$$loss=-\frac{1}{N}\sum^N_{n=1}(y_n\log \hat{y}_n+(1-y_n)\log (1-\hat{y}_n))$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;流程和之前的差不多，代码如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;#---------------------Prepare dataset--------------------------#&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Tensor([[&lt;span style=&#34;color:#666&#34;&gt;1.0&lt;/span&gt;], [&lt;span style=&#34;color:#666&#34;&gt;2.0&lt;/span&gt;], [&lt;span style=&#34;color:#666&#34;&gt;3.0&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Tensor([[&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;], [&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;], [&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;#-----------------Design model using Class---------------------#&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;LogisticRegressionModel&lt;/span&gt;(torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __init__(self):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f&#34;&gt;super&lt;/span&gt;(LogisticRegressionModel, self)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;__init__()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;forward&lt;/span&gt;(self, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y_pred &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; F&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sigmoid(self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear(x))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; y_pred
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; LogisticRegressionModel()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;#----------------Construct loss and optimizer------------------#&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;criterion &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;BCELoss(size_average&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;optimizer &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;optim&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;SGD(model&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parameters(), lr&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;0.01&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;#----------------------Training cycle--------------------------#&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;1000&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y_pred &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; model(x_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; criterion(y_pred, y_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(epoch, loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;zero_grad()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;step()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;multi-dimension&#34;&gt;Multi Dimension&lt;/h3&gt;
&lt;p&gt;二维数据中，一般来说列对应的是feature，行对应的是sample，一行为一条record&lt;/p&gt;
&lt;h4 id=&#34;mini-batchn-samples&#34;&gt;Mini-Batch（N samples）&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/5xqKyhOoinIVuHl&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/5xqKyhOoinIVuHl.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;Model&lt;/span&gt;(torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __init__(self):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f&#34;&gt;super&lt;/span&gt;(Model, self)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;__init__()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sigmoid &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Sigmoid()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;forward&lt;/span&gt;(self, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sigmoid(self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear(x))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; Model()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;prepare-dataset-1&#34;&gt;Prepare Dataset&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;numpy&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;np&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;xy &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;loadtxt(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;diabetes.csv.gz&amp;#39;&lt;/span&gt;, delimiter&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;,&amp;#39;&lt;/span&gt;, dtype&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;float32)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;from_numpy(xy[:,:&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;]) &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 除了最后一行都要&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;from_numpy(xy[:, [&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;define-model&#34;&gt;Define Model&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;Model&lt;/span&gt;(torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __init__(self):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f&#34;&gt;super&lt;/span&gt;(Model, self)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;__init__()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear1 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;6&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear2 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear3 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sigmoid &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Sigmoid()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;forward&lt;/span&gt;(self, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sigmoid(self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear1(x))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sigmoid(self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear2(x))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sigmoid(self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;linear3(x))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; Model()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;construct-loss-and-optimizer-1&#34;&gt;Construct Loss and Optimizer&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;criterion &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;BCELoss(size_average&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;optimizer &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;optim&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;SGD(model&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parameters(), lr&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;0.1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;training-cycle-1&#34;&gt;Training Cycle&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Forward&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y_pred &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; model(x_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; criterion(y_pred, y_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(epoch, loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Backward&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;zero_grad()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Update&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;step()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;04-dataset-and-dataloader&#34;&gt;04. Dataset and DataLoader&lt;/h2&gt;
&lt;h3 id=&#34;use-all-of-the-data&#34;&gt;Use all of the data&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;xy &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;loadtxt(&lt;span style=&#34;&#34;&gt;‘&lt;/span&gt;diabetes&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;csv&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;gz&lt;span style=&#34;&#34;&gt;’&lt;/span&gt; , delimiter&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;&#34;&gt;‘&lt;/span&gt;,&lt;span style=&#34;&#34;&gt;’&lt;/span&gt; , dtype&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;float32)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;from_numpy(xy[:,:&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;from_numpy(xy[:, [&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;……&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 1. Forward&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y_pred &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; model(x_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; criterion(y_pred, y_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(epoch, loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 2. Backward&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;zero_grad()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 3. Update&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;step()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;terminology&#34;&gt;Terminology&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Training cycle&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(training_epochs):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Loop over all batches&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(total_batch):
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Epoch&lt;/strong&gt;
One forward pass and one backward pass of &lt;strong&gt;all the training examples&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Batch-Size&lt;/strong&gt;
The &lt;strong&gt;number of training examples&lt;/strong&gt; in one forward backward pass.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Iteration&lt;/strong&gt;
Number of passes, each pass using &lt;strong&gt;batch size&lt;/strong&gt; number of examples.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;比如，1000个样本，我们分成10个Batch，Batch-Size=100，Iteration=10&lt;/p&gt;
&lt;h3 id=&#34;dataloader&#34;&gt;DataLoader&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/gvSpaB4MeVfuDrs&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/gvSpaB4MeVfuDrs.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Define Dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dataset 是一个抽象类，不可以实例化；而 DataLoader 是可以实例化的&lt;/li&gt;
&lt;li&gt;number workers 指的是多线程并行的个数，好像 Windows 上必须是0，建议在 Linux 使用&lt;/li&gt;
&lt;li&gt;getitem 是当数据比较大，需要通过读取文件名来 get 相应的 item 进行处理&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch.utils.data&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; Dataset
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch.utils.data&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; DataLoader
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;DiabetesDataset&lt;/span&gt;(Dataset):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __init__(self):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __getitem__(self, index):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __len__(self):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; DiabetesDataset()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;train_loader &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; DataLoader(dataset&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;dataset,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          batch_size&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;32&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          shuffle&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;True&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          num_workers&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; i, data &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;enumerate&lt;/span&gt;(train_loader, &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;&#34;&gt;……&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;example-diabetes-dataset&#34;&gt;Example: Diabetes Dataset&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;DiabetesDataset&lt;/span&gt;(Dataset):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __init__(self, filepath):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        xy &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;loadtxt(filepath, delimiter&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;,&amp;#39;&lt;/span&gt;, dtype&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;float32)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;len &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; xy&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 取第0元素：长度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;x_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;from_numpy(xy[:, :&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;y_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;from_numpy(xy[:, [&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __getitem__(self, index):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;x_data[index], self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;y_data[index] &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 返回对应样本即可&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __len__(self):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;len
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; DiabetesDataset(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;diabetes.csv.gz&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;train_loader &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; DataLoader(dataset&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;dataset,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          batch_size&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;32&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          shuffle&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;True&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          num_workers&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; i, data &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;enumerate&lt;/span&gt;(train_loader, &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 1. Prepare data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        inputs, labels &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; data
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 2. Forward&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y_pred &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; model(inputs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; criterion(y_pred, labels)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(epoch, i, loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 3. Backward&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;zero_grad()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# 4. Update&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;step()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;i代表的是第几组数据，表示每次拿的是 $x[i],y[i]$&lt;/li&gt;
&lt;li&gt;train_loader 拿出来的是一个元组 $(X,Y)$，是 getitem 传过来的&lt;/li&gt;
&lt;li&gt;0代表是从第0个开始枚举&lt;/li&gt;
&lt;li&gt;inputs代表 x，labels代表y。或者我们可以将data改为 (input,labels)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;05-softmax&#34;&gt;05. Softmax&lt;/h2&gt;
&lt;h3 id=&#34;softmax概念&#34;&gt;Softmax概念&lt;/h3&gt;
&lt;p&gt;对于多输出，我们要对输出进行进一步的&lt;strong&gt;规格化&lt;/strong&gt;
$$P(y=i)\ge 0\qquad \sum_{i=0}^9 P(y=i)=1$$
Suppose $𝑍^𝑙 ∈ ℝ^𝐾$ is the output of the last linear layer, the* Softmax function*:
$$P(y=i)=\frac{e^{z_i}}{\sum_{j=0}^{K-1} e^{z_j}},\quad i\in {0,\cdots ,K-1}$$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;criterion &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;CrossEntropyLoss()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Y &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;LongTensor([&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Y_pred1 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Tensor([[&lt;span style=&#34;color:#666&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.9&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        [&lt;span style=&#34;color:#666&#34;&gt;1.1&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.2&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        [&lt;span style=&#34;color:#666&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;2.1&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.1&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Y_pred2 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Tensor([[&lt;span style=&#34;color:#666&#34;&gt;0.8&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.3&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        [&lt;span style=&#34;color:#666&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.5&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        [&lt;span style=&#34;color:#666&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;0.5&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;l1 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; criterion(Y_pred1, Y)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;l2 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; criterion(Y_pred2, Y)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#34;Batch Loss1 = &amp;#34;&lt;/span&gt;, l1&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;data, &lt;span style=&#34;color:#b44&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;Batch Loss2=&amp;#34;&lt;/span&gt;, l2&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;data)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;crossentropyloss-vs-nulloss&#34;&gt;CrossEntropyLoss vs NULLoss&lt;/h3&gt;
&lt;h3 id=&#34;implementation&#34;&gt;Implementation&lt;/h3&gt;
&lt;h4 id=&#34;package&#34;&gt;Package&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torchvision&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; transforms
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torchvision&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; datasets
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch.utils.data&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; DataLoader
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch.nn.functional&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;F&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch.optim&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;optim&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;transform&lt;/code&gt;: 对数据集进行处理&lt;/li&gt;
&lt;li&gt;&lt;code&gt;F&lt;/code&gt;: For using function relu()&lt;/li&gt;
&lt;li&gt;&lt;code&gt;optim&lt;/code&gt;: For constructing Optimizer&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;prepare-dataset-2&#34;&gt;Prepare Dataset&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;batch_size &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;64&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;transform &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; transforms&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Compose([
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transforms&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;ToTensor(),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transforms&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Normalize((&lt;span style=&#34;color:#666&#34;&gt;0.1307&lt;/span&gt;, ), (&lt;span style=&#34;color:#666&#34;&gt;0.3081&lt;/span&gt;, ))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;train_dataset &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;MNIST(root&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;../dataset/mnist/&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               train&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;True&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               download&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;True&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               transform&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;transform)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;train_loader &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; DataLoader(train_dataset,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          shuffle&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;True&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          batch_size&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;batch_size)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;test_dataset &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;MNIST(root&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;../dataset/mnist/&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                              train&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;False&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                              download&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;True&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                              transform&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;transform)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;test_loader &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; DataLoader(test_dataset,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                         shuffle&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;False&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                         batch_size&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;batch_size)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;transform是为了Normalization数据，0.1307是均值，0.3081是标准差。这是MNIST数据集经过计算所得到的均值和标准差。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;design-model-1&#34;&gt;Design Model&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;Net&lt;/span&gt;(torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __init__(self):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f&#34;&gt;super&lt;/span&gt;(Net, self)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;__init__()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;l1 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;784&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;512&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;l2 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;512&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;256&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;l3 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;256&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;128&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;l4 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;64&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;l5 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#666&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;10&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;forward&lt;/span&gt;(self, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;view(&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;784&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; F&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;relu(self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;l1(x))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; F&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;relu(self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;l2(x))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; F&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;relu(self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;l3(x))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; F&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;relu(self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;l4(x))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;l5(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; Net()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;construct-loss-and-optimizer-2&#34;&gt;Construct Loss and Optimizer&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;criterion &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;CrossEntropyLoss()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;optimizer &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; optim&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;SGD(model&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parameters(), lr&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;0.01&lt;/span&gt;, momentum&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;0.5&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;train-and-test&#34;&gt;Train and Test&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;train&lt;/span&gt;(epoch):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    running_loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; batch_idx, data &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;enumerate&lt;/span&gt;(train_loader, &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        inputs, target &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; data
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;zero_grad()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# forward + backward + update&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        outputs &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; model(inputs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; criterion(outputs, target)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;step()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        running_loss &lt;span style=&#34;color:#666&#34;&gt;+=&lt;/span&gt; loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;if&lt;/span&gt; batch_idx &lt;span style=&#34;color:#666&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;300&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;299&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;[&lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;, &lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%5d&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;] loss: &lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%.3f&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;%&lt;/span&gt; (epoch &lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;, batch_idx &lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;, running_loss &lt;span style=&#34;color:#666&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;300&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            running_loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;test&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    correct &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    total &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;with&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;no_grad():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; data &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; test_loader:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            images, labels &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; data
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            outputs &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; model(images)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            _, predicted &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;max(outputs&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;data, dim&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            total &lt;span style=&#34;color:#666&#34;&gt;+=&lt;/span&gt; labels&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;size(&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            correct &lt;span style=&#34;color:#666&#34;&gt;+=&lt;/span&gt; (predicted &lt;span style=&#34;color:#666&#34;&gt;==&lt;/span&gt; labels)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sum()&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;Accuracy on test set: &lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%%&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;%&lt;/span&gt; (&lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt; correct &lt;span style=&#34;color:#666&#34;&gt;/&lt;/span&gt; total))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;10&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    train(epoch)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    test()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;mention&#34;&gt;MENTION&lt;/h4&gt;
&lt;p&gt;我们在打标签的时候需要从0开始，否则是有问题的。&lt;/p&gt;
&lt;h2 id=&#34;06-cnn&#34;&gt;06. CNN&lt;/h2&gt;
&lt;p&gt;卷积神经网络可以做到保留原始的空间信息，而全连接层是展开成一个，无法保留空间信息。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/wXULltfeIF5RNpQ&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/wXULltfeIF5RNpQ.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;in_channels, out_channels&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;width, height &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kernel_size &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;batch_size &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;input&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;randn(batch_size,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    in_channels,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    width,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    height)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conv_layer &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Conv2d(in_channels,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                             out_channels,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                             kernel_size&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;kernel_size)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;output &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; conv_layer(&lt;span style=&#34;color:#a2f&#34;&gt;input&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#a2f&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;shape)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(output&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;shape)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(conv_layer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;weight&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;shape)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;输出为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Size([&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Size([&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;98&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;98&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Size([&lt;span style=&#34;color:#666&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;mnist-example&#34;&gt;MNIST Example&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/i7NS3OYJl5tIupf&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/i7NS3OYJl5tIupf.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;move-model-to-gpu&#34;&gt;Move Model to GPU&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;device &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;device(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#34;cuda:0&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;if&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;cuda&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;is_available() &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#b44&#34;&gt;&amp;#34;cpu&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;to(device)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;train&lt;/span&gt;(epoch):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    running_loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; batch_idx, data &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;enumerate&lt;/span&gt;(train_loader, &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        inputs, target &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; data
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        inputs, target &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; inputs&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;to(device), target&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;to(device)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;zero_grad()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# forward + backward + update&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        outputs &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; model(inputs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; criterion(outputs, target)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        optimizer&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;step()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        running_loss &lt;span style=&#34;color:#666&#34;&gt;+=&lt;/span&gt; loss&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;if&lt;/span&gt; batch_idx &lt;span style=&#34;color:#666&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;300&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;299&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;[&lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;, &lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%5d&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;] loss: &lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%.3f&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;%&lt;/span&gt; (epoch &lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;, batch_idx &lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;, running_loss &lt;span style=&#34;color:#666&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2000&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            running_loss &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;test&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    correct &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    total &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;with&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;no_grad():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;for&lt;/span&gt; data &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; test_loader:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            inputs, target &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; data
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            inputs, target &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; inputs&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;to(device), target&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;to(device)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            outputs &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; model(inputs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            _, predicted &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;max(outputs&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;data, dim&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            total &lt;span style=&#34;color:#666&#34;&gt;+=&lt;/span&gt; target&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;size(&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            correct &lt;span style=&#34;color:#666&#34;&gt;+=&lt;/span&gt; (predicted &lt;span style=&#34;color:#666&#34;&gt;==&lt;/span&gt; target)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sum()&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;item()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#39;Accuracy on test set: &lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%%&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt; [&lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#b68;font-weight:bold&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#b44&#34;&gt;]&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;%&lt;/span&gt; (&lt;span style=&#34;color:#666&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt; correct &lt;span style=&#34;color:#666&#34;&gt;/&lt;/span&gt; total, correct, total))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;inception-module&#34;&gt;Inception Module&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/yC6RYmPA4qFVi3g&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/yC6RYmPA4qFVi3g.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;1x1-convolution&#34;&gt;1x1 convolution&lt;/h4&gt;
&lt;p&gt;可以&lt;strong&gt;改变通道数量&lt;/strong&gt;，可以跨越不同通道相同像素的值，做到了信息融合的目的。
卷积核的数量就代表了通道的数量。
作用：降低运算量&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/OJaXnTPIi29pxBZ&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/OJaXnTPIi29pxBZ.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
