<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publication on Blog de Preminstrel</title>
    <link>https://preminstrel.github.io/blog/tags/publication/</link>
    <description>Recent content in Publication on Blog de Preminstrel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>preminstrel@gmail.com (Hanshi Sun)</managingEditor>
    <webMaster>preminstrel@gmail.com (Hanshi Sun)</webMaster>
    <lastBuildDate>Sun, 17 Oct 2021 13:37:23 +0800</lastBuildDate><atom:link href="https://preminstrel.github.io/blog/tags/publication/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Arrhythmia Classifier Using CNN With ALQ</title>
      <link>https://preminstrel.github.io/blog/post/2021/10/17/arrhythmia-classifier-using-cnn-with-alq/</link>
      <pubDate>Sun, 17 Oct 2021 13:37:23 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2021/10/17/arrhythmia-classifier-using-cnn-with-alq/</guid>
      
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;在许多医疗保健方案中，患者被诊断出患有各种各样的疾病，包括心血管疾病（CVDs），这是一种普遍的致命疾病。 心电图描述了人的心电活动，对准确诊断有重要意义。 但在早期，有些心律失常症状不明显，持续时间短，难以识别，导致严重后果。 因此，部署在低功耗设备上的实时心率检测成为人们关注的焦点。&lt;/p&gt;
&lt;p&gt;神经网络通过模拟人脑的层次结构实现数据的层次特征表达，具有强大的信息处理能力，促进了心电分类方法算法和模型的发展。 虽然神经网络模型的检测和分类精度看起来相当可观，但其庞大的可训练网络参数消耗大量内存，需要更多的时间进行复杂的计算，难以部署在低功耗的硬件平台上。 为了解决这个问题，我们考虑了网络结构的设计和自适应性的量化压缩方法。采用自适应位宽量化方法对模型误差进行优化，可以降低典型量化方法的精度下降，甚至提高模型误差的精度。 简单来说，我们的贡献有三个方面:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出了一种自适应损失感知量化算法（ALQ），以降低一维卷积神经网络的内存和功耗，同时保持甚至提高分类精度。&lt;/li&gt;
&lt;li&gt;基于我们的压缩方法，进一步提出了一种基于长时程心电片段分析的17层卷积神经网络（CNN）结构用于心律失常（17类）检测，实现了心律失常检测的总体准确率为93.5%。&lt;/li&gt;
&lt;li&gt;最后，我们实现了量化方法，在存储压缩率达到了 23.4 倍的情况下，分类的准确率达到了95.84%，说明了所提出的量化方法相对于以往方法的优越性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;参考论文：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Zhongnan Qu, Zimu Zhou, Yun Cheng, Lothar Thiele. Adaptive Loss-Aware Quantization for Multi-Bit Networks. In &lt;em&gt;the IEEE/CVF Conference on Computer Vision and Pattern Recognition&lt;/em&gt; (CVPR), 2020, pp. 7988-7997&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我根据Qu的论文提出的&lt;strong&gt;自适应损失感知量化  (Adaptive Loss-aware Quantization,ALQ)&lt;/strong&gt; 算法对ECGNet进行了量化压缩。论文中实现了Conv2d的情况，我修改模型后得到Conv1d的模型。在经过ALQ压缩后，能够实现大部分Layers低于 2 位，少部分Layers低于1位的平均位宽（average bitwidth）， 而不会降低模型的精度。 甚至，在量化之后，模型的精度有可能得到提高，达到95%的准确率。（一般来说会降低，这里我也不清楚为什么会提高，猜测有可能是量化压缩提高了正则化）&lt;/p&gt;
&lt;p&gt;量化解决方案通过最小化误差以重建全精度权重来训练量化器不同， ALQ 直接最小化损失函数上的量化引起的误差， 既不涉及梯度近似（gradient approximation）也不涉及全精度维护（full precision maintenance）。 ALQ 还利用了包括自适应位宽、 平滑位宽减少、 和迭代训练的量化，以允许更小的网络规模而不会损失准确性。&lt;/p&gt;
&lt;h1 id=&#34;methodology&#34;&gt;METHODOLOGY&lt;/h1&gt;
&lt;p&gt;在本节中，我们首先介绍分类器的架构概述，并描述我们的一维 CNN 架构的细节。在本节的最后，讨论了ALQ策略和一些ALQ参数的选择。整个提出的框架可以分为两部分，如图所示。&lt;/p&gt;
&lt;p&gt;第一部分是心律失常分类神经网络体系结构，该体系结构基于基本块设计，确定神经网络的深度。对模型进行训练后，得到的ECGNet的精度达到93.5%。模型参数应被保存，以便进行量化压缩。&lt;/p&gt;
&lt;div align=center&gt;
&lt;img src=&#34;https://preminstrel.github.io/blog/img/frame-overview.png&#34; width=&#34;500px&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;第二部分是ALQ策略（Adaptive Loss-aware quantification）。网络中每一层对量化的敏感度是不同的。因此，假设我们给出的总比特数不变，对量化较敏感的层位数获得的位宽应该较大，而对量化较不敏感的层位获得的位宽应该较小，以达到更好的精度。该方法通过对 $\alpha$ 域的最小有效坐标进行剪枝来降低平均位宽，并在正确选择 $n$ 等参数的基础上优化二值化的基底 $B_k$ 和坐标 $\alpha_k$ 。该部分实现了对神经网络有效的压缩，不同于现有方法，成功避免了精度下降可，以满足较低的资源需求。&lt;/p&gt;
&lt;h2 id=&#34;ecgnet-model&#34;&gt;ECGNet Model&lt;/h2&gt;
&lt;p&gt;我们原创的心律失常分类卷积神经网络如图所示。该网络由若干基本块和两个线性层组成。基本块层包括一维卷积层和最大池化层，它们之间的激活为 ReLU。基本块用于特征提取，线性层用于分类。&lt;/p&gt;
&lt;div align=center&gt;
&lt;img src=&#34;https://preminstrel.github.io/blog/img/Net-arch.png&#34; width=&#34;500px&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;输入是原始的长时间心电信号，由3600个采样点组成，持续时间为10秒。该网络无需对原始信号进行人工特征提取、特征分割和数据处理，即可实现端到端检测并推断出分类输出。在设计网络结构时，我们在网络规模和精度之间进行了权衡。最后，我们决定基本块的数量应该是7，因为这样的深度可以产生相当多的输出。同时，它保留了很小的网络参数。因此，我们最后得到的卷积神经网络是17层的。具体网络设计结构如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Layer&lt;/th&gt;
&lt;th&gt;Layer Name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Other Layer Params&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Kernel $\times$ Unit&lt;/th&gt;
&lt;th&gt;Params&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Activation = ReLU, Strides=2, Padding=7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$16\times 8$&lt;/td&gt;
&lt;td&gt;136&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Stride=4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$8$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Activation = ReLU, Strides=2, Padding=5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$12\times 12$&lt;/td&gt;
&lt;td&gt;1,164&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Stride=2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$4$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Activation = ReLU, Strides=1, Padding=4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$9\times 32$&lt;/td&gt;
&lt;td&gt;3,488&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Stride=2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$5$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Activation = ReLU, Strides=1, Padding=3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$7\times 64$&lt;/td&gt;
&lt;td&gt;14,400&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Stride=2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$4$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Activation = ReLU, Strides=1, Padding=2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$5\times 64$&lt;/td&gt;
&lt;td&gt;20,544&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Stride=2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$2$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Activation = ReLU, Strides=1, Padding=1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$3\times 64$&lt;/td&gt;
&lt;td&gt;12,352&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Strides=2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$2$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;13&lt;/td&gt;
&lt;td&gt;Conv1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Activation = ReLU, Strides=1, Padding=1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$3\times 72$&lt;/td&gt;
&lt;td&gt;13,896&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td&gt;MaxPooling1D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Strides=2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$2$&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;15&lt;/td&gt;
&lt;td&gt;Flatten&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td&gt;Linear&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Activation = ReLU, Dropout Rate=0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$1\times 216$&lt;/td&gt;
&lt;td&gt;13,888&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;17&lt;/td&gt;
&lt;td&gt;Linear&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Activation = ReLU&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$1\times 17$&lt;/td&gt;
&lt;td&gt;1,105&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Total params&lt;/strong&gt;: 80,973&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Params size&lt;/strong&gt;: 316.3KB&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;:  93.5%&lt;/p&gt;
&lt;h2 id=&#34;alq-algorithm&#34;&gt;ALQ Algorithm&lt;/h2&gt;
&lt;p&gt;尽管所提出的网络架构深度极小，但由于权值的位宽较大，心律失常检测网络仍然存在内存和功耗问题。由于不同层的重要性不同，采用自适应位宽对不同层进行量化是合理的，可以显著降低网络的平均位宽。我们采用自适应一维损耗多比特网络（MBNs）量化方法来帮助我们实现对原来提出的网络的压缩。&lt;/p&gt;
&lt;p&gt;在模型压缩中，通常通过   pruning ,  quantization,  distillation 等方法来压缩预训练模型。在 ECGNet 的压缩中，我们利用了量化压缩。我们通过将深度神经网络的 weights 和 activations 量化为 multi-bit networks (MBNs) 来实现模型的压缩。&lt;/p&gt;
&lt;p&gt;与将误差最小化的量化方法重建全精度权值不同，一维ALQ使损失函数的量化误差最小化。在此过程中，并不涉及梯度近似。在我们训练全精度ECGNet后，量化过程就可以开始了。为了提高压缩速度，引入了并行计算。对于向量化的权值 $w∈R^{N×1}$，将 $w$ 划分为 $m$ 个不相交的组。每组权重用 $w_k∈R^{n×1}$ 表示，其中 $N = n × m$，在二进制基础上可以表示量化的权重。&lt;/p&gt;
&lt;p&gt;$$\omega_k=\sum_{i=1}^{I_k}\alpha_i \beta_i=B_k\alpha_k,\quad \beta_i\in{-1,1}^{n\times 1}$$&lt;/p&gt;
&lt;p&gt;我们用 $I_k$ 来表示第 k 组的位宽，于是我们可以定义平均位宽为：&lt;/p&gt;
&lt;p&gt;$$\bar{I}=\frac{1}{m}\sum_{k=1}^m I_k$$&lt;/p&gt;
&lt;p&gt;我们的优化方案如下：&lt;/p&gt;
&lt;div align=center&gt;
&lt;img src=&#34;https://preminstrel.github.io/blog/img/Algorithm.png&#34; width=&#34;500px&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 1 Full precision ECGNet&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这一步就是在本文第一部分中，对ECGNet进行全精度的训练。得到的数据需要进行保存，会用在后面两步之中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2 Pruning in $\alpha$ Domain&lt;/strong&gt;
在这一步中， 我们通过修剪最不重要的（w.r.t the loss） $\alpha$ 逐步减少Layer的平均位宽 $\bar{I}$  。   在这一步中， 我们只设置了一些元素 $\alpha$  为零。这一步会导致模型准确率的下降，但是我们会在Step 2中重新提高回来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 3: Optimizing Binary Bases $B_g$ and Coordinates $\alpha _g$&lt;/strong&gt;
在这一步中， 我们重新训练剩余的   binary bases 和 coordinates 来恢复因为Step 1中减少位宽引起的准确率的下降。在这个步骤中，我们首先固定 coordinates 来对搜索binary bases 进行最优搜索，然后再固定 binary bases 对coordinates进行搜索。经过优化之后，准确率重新提高了。&lt;/p&gt;
&lt;h1 id=&#34;result&#34;&gt;Result&lt;/h1&gt;
&lt;p&gt;ALQ量化压缩后七个卷积层和两个全连接层的平均位宽结果如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Layer&lt;/th&gt;
&lt;th&gt;Average Bitwidth&lt;/th&gt;
&lt;th&gt;Params&lt;/th&gt;
&lt;th&gt;Size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Conv1d_1&lt;/td&gt;
&lt;td&gt;1.2500&lt;/td&gt;
&lt;td&gt;136&lt;/td&gt;
&lt;td&gt;170 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Conv1d_2&lt;/td&gt;
&lt;td&gt;1.9896&lt;/td&gt;
&lt;td&gt;1,164&lt;/td&gt;
&lt;td&gt;2,316 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Conv1d_3&lt;/td&gt;
&lt;td&gt;1.7005&lt;/td&gt;
&lt;td&gt;3,488&lt;/td&gt;
&lt;td&gt;5,921 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Conv1d_4&lt;/td&gt;
&lt;td&gt;1.7095&lt;/td&gt;
&lt;td&gt;14,400&lt;/td&gt;
&lt;td&gt;24,617 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Conv1d_5&lt;/td&gt;
&lt;td&gt;1.4133&lt;/td&gt;
&lt;td&gt;20,544&lt;/td&gt;
&lt;td&gt;29,035 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Conv1d_6&lt;/td&gt;
&lt;td&gt;0.8545&lt;/td&gt;
&lt;td&gt;12,352&lt;/td&gt;
&lt;td&gt;10,555 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Conv1d_7&lt;/td&gt;
&lt;td&gt;0.8550&lt;/td&gt;
&lt;td&gt;13,896&lt;/td&gt;
&lt;td&gt;11,881 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Linear_1&lt;/td&gt;
&lt;td&gt;1.7422&lt;/td&gt;
&lt;td&gt;13,888&lt;/td&gt;
&lt;td&gt;24,196 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Linear_2&lt;/td&gt;
&lt;td&gt;2.0000&lt;/td&gt;
&lt;td&gt;1,105&lt;/td&gt;
&lt;td&gt;2210 bit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ALL&lt;/td&gt;
&lt;td&gt;1.3696&lt;/td&gt;
&lt;td&gt;80973&lt;/td&gt;
&lt;td&gt;110901 bit= 13.538 KB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;可以看到，316.3KB的模型经过压缩后变成了13.538KB，平均位宽为1.3696。压缩率为23.36x。&lt;/p&gt;
&lt;p&gt;准确率上，甚至还上升了，达到了95%，上升了1.5%。&lt;/p&gt;
&lt;p&gt;归一化后的混淆矩阵如下图：&lt;/p&gt;
&lt;div align=center&gt;
&lt;img src=&#34;https://preminstrel.github.io/blog/img/Confusion-matrix.png&#34; width=&#34;500px&#34; /&gt;
&lt;/div&gt;
</description>
      
    </item>
    
  </channel>
</rss>
