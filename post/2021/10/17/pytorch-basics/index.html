<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">

  
  <meta name="author" content="Hanshi Sun">

  
  
  <meta name="description" content="01. Overview DL &amp; ML ç»´åº¦è¯…å’’ï¼šç»´åº¦è¶Šé«˜ï¼Œéœ€è¦çš„è®­ç»ƒé›†è¶Šå¤§ æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„åŒºåˆ«ï¼šå¤šäº†ä¸€å±‚ç”¨æ¥æå–ç‰¹å¾çš„å±‚ã€‚ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ ä¸­ï¼ˆæ— æ ‡ç­¾ï¼‰ï¼ŒFeature">
  

  
  <link rel="icon" href="https://preminstrel.github.io/blog/favicon.ico">

  
  
  <meta name="keywords" content=" hugo  latex  theme ">
  

  
  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css"
  integrity="sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
  integrity="sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js"
  integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '\\[', right: '\\]', display: true },
        { left: '$', right: '$', display: false },
        { left: '\\(', right: '\\)', display: false }
      ],
      ignoredTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code', 'option'],
      throwOnError: false
    });
  });
</script>


  

  
  <meta property="og:title" content="Pytorch Basics" />
<meta property="og:description" content="01. Overview DL &amp; ML ç»´åº¦è¯…å’’ï¼šç»´åº¦è¶Šé«˜ï¼Œéœ€è¦çš„è®­ç»ƒé›†è¶Šå¤§ æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„åŒºåˆ«ï¼šå¤šäº†ä¸€å±‚ç”¨æ¥æå–ç‰¹å¾çš„å±‚ã€‚ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ ä¸­ï¼ˆæ— æ ‡ç­¾ï¼‰ï¼ŒFeature" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://preminstrel.github.io/blog/post/2021/10/17/pytorch-basics/" />
<meta property="article:published_time" content="2021-10-17T00:25:41+08:00" />
<meta property="article:modified_time" content="2021-10-17T00:25:41+08:00" />


  
  <link rel="canonical" href="https://preminstrel.github.io/blog/post/2021/10/17/pytorch-basics/">

  
  
  <meta itemprop="name" content="Pytorch Basics">
<meta itemprop="description" content="01. Overview DL &amp; ML ç»´åº¦è¯…å’’ï¼šç»´åº¦è¶Šé«˜ï¼Œéœ€è¦çš„è®­ç»ƒé›†è¶Šå¤§ æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„åŒºåˆ«ï¼šå¤šäº†ä¸€å±‚ç”¨æ¥æå–ç‰¹å¾çš„å±‚ã€‚ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ ä¸­ï¼ˆæ— æ ‡ç­¾ï¼‰ï¼ŒFeature">
<meta itemprop="datePublished" content="2021-10-17T00:25:41&#43;08:00" />
<meta itemprop="dateModified" content="2021-10-17T00:25:41&#43;08:00" />
<meta itemprop="wordCount" content="2462">



<meta itemprop="keywords" content="Pytorch,Deep Learning," />

  
  <link media="screen" rel="stylesheet" href='https://preminstrel.github.io/blog/css/common.css'>
  <link media="screen" rel="stylesheet" href='https://preminstrel.github.io/blog/css/content.css'>

  
  
  <title>Pytorch Basics - Blog de Preminstrel</title>
  

  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Pytorch Basics"/>
<meta name="twitter:description" content="01. Overview DL &amp; ML ç»´åº¦è¯…å’’ï¼šç»´åº¦è¶Šé«˜ï¼Œéœ€è¦çš„è®­ç»ƒé›†è¶Šå¤§ æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„åŒºåˆ«ï¼šå¤šäº†ä¸€å±‚ç”¨æ¥æå–ç‰¹å¾çš„å±‚ã€‚ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ ä¸­ï¼ˆæ— æ ‡ç­¾ï¼‰ï¼ŒFeature"/>


  
<link rel="stylesheet" href='https://preminstrel.github.io/blog/css/single.css'>

</head>

<body>
  <div id="wrapper">
    <header id="header">
  <h1>
    <a href="https://preminstrel.github.io/blog/">Blog de Preminstrel</a>
  </h1>

  <nav>
    
    <span class="nav-bar-item">
      <a class="link" href="/blog/">Post</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/blog/post/">Archives</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/blog/about/">About</a>
    </span>
    
  </nav>
</header>

    
<main id="main" class="post">
  
  
  <h1>Pytorch Basics</h1>
  
  <div>
    <b>Keywords: </b>
    
    <a class="link" href='https://preminstrel.github.io/blog/tags/pytorch'>#Pytorch</a>
    
    <a class="link" href='https://preminstrel.github.io/blog/tags/deep-learning'>#Deep Learning</a>
    
  </div>
  
  
  <article class="content">
    
    <h2 id="01-overview">01. Overview</h2>
<h3 id="dl--ml">DL &amp; ML</h3>
<p><img src="/img/20210913192607.png" alt=""></p>
<ul>
<li>ç»´åº¦è¯…å’’ï¼šç»´åº¦è¶Šé«˜ï¼Œéœ€è¦çš„è®­ç»ƒé›†è¶Šå¤§</li>
<li>æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„åŒºåˆ«ï¼šå¤šäº†ä¸€å±‚ç”¨æ¥æå–ç‰¹å¾çš„å±‚ã€‚ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ ä¸­ï¼ˆæ— æ ‡ç­¾ï¼‰ï¼ŒFeatureæ˜¯å•ç‹¬åšè®­ç»ƒçš„ï¼Œåé¢çš„Mapping from featureså’Œå®ƒæ˜¯åˆ†å¼€çš„ã€‚ä½†æ˜¯åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œè¿™ä¸ªæ˜¯ç»Ÿä¸€çš„ã€‚æ‰€ä»¥æ·±åº¦å­¦ä¹ ä¹Ÿç§°ä¸º <strong>End to End</strong> çš„å­¦ä¹ æ–¹å¼ã€‚</li>
</ul>
<h3 id="route">Route</h3>
<p><img src="/img/20210913193312.png" alt=""></p>
<h3 id="gradient-descent">Gradient Descent</h3>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x_data <span style="color:#666">=</span> [<span style="color:#666">1</span>,<span style="color:#666">2</span>,<span style="color:#666">3</span>]
y_data <span style="color:#666">=</span> [<span style="color:#666">2</span>,<span style="color:#666">4</span>,<span style="color:#666">6</span>]
w<span style="color:#666">=</span><span style="color:#666">1</span>

<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward</span>(x):
    <span style="color:#a2f;font-weight:bold">return</span> x<span style="color:#666">*</span>w

<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">loss</span>(xs,ys):
    loss <span style="color:#666">=</span> <span style="color:#666">0</span>
    <span style="color:#a2f;font-weight:bold">for</span> x,y <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">zip</span>(xs,ys):
        y_pred <span style="color:#666">=</span> forward(x)
        loss <span style="color:#666">+=</span> (y_pred<span style="color:#666">-</span>y)<span style="color:#666">**</span><span style="color:#666">2</span>
    <span style="color:#a2f;font-weight:bold">return</span> loss<span style="color:#666">/</span><span style="color:#a2f">len</span>(xs)

<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">gradient</span>(xs,ys):
    grad<span style="color:#666">=</span><span style="color:#666">0</span>
    <span style="color:#a2f;font-weight:bold">for</span> x,y <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">zip</span>(xs,ys):
        grad <span style="color:#666">+=</span> <span style="color:#666">2</span><span style="color:#666">*</span>x<span style="color:#666">*</span>(x<span style="color:#666">*</span>w<span style="color:#666">-</span>y)
    <span style="color:#a2f;font-weight:bold">return</span> grad<span style="color:#666">/</span><span style="color:#a2f">len</span>(xs)

<span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;Predict(before training)&#39;</span>,<span style="color:#666">4</span>, forward(<span style="color:#666">4</span>))
<span style="color:#a2f;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(<span style="color:#666">100</span>):
    loss_val <span style="color:#666">=</span> loss(x_data, y_data)
    grad_val <span style="color:#666">=</span> gradient(x_data, y_data)
    w <span style="color:#666">-=</span> <span style="color:#666">0.01</span><span style="color:#666">*</span>grad_val
    <span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;Epoch:&#39;</span>, epoch, <span style="color:#b44">&#39;w=&#39;</span>,w,<span style="color:#b44">&#39;loss=&#39;</span>,loss_val)
<span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;Predict(After training)&#39;</span>,<span style="color:#666">4</span>, forward(<span style="color:#666">4</span>))
</code></pre></div><p><img src="/img/20210913203403.png" alt=""></p>
<ul>
<li>éšæœºæ¢¯åº¦ä¸‹é™çš„è®¡ç®—æ— æ³•å¹¶è¡Œï¼Œè®¡ç®—ä¸­æ˜¯æœ‰ä¾èµ–çš„</li>
<li>éšæœºæ¢¯åº¦ä¸‹é™çš„æ€§èƒ½æ›´å¥½ï¼Œä½†æ˜¯æ— æ³•å¹¶è¡Œï¼Œæ‰€ä»¥é€Ÿåº¦æ¯”è¾ƒæ…¢</li>
<li>æ‰€ä»¥æˆ‘ä»¬ç”¨<strong>mini-batch</strong>ï¼Œæ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™ï¼Œè¿™æ˜¯ä¸€ç§æŠ˜ä¸­çš„æ–¹æ³•</li>
</ul>
<h3 id="å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­">å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­</h3>
<p><img src="/img/20210913220248.png" alt=""></p>
<h2 id="02-linear-model">02. Linear Model</h2>
<h3 id="tensor--linear-model">Tensor &amp; Linear Model</h3>
<p>In PyTorch, Tensor is the important component in <strong>constructing dynamic
computational graph</strong>. It contains <strong>data and grad</strong>, which storage the value of node and gradient w.r.t loss respectively.
å¦‚ä¸‹ä»£ç æ˜¯åœ¨æ„é€ è®¡ç®—å›¾ï¼Œåœ¨Pytorchä¸­æˆ‘ä»¬éœ€è¦è¿™æ ·çœ‹å¾…å®ƒã€‚</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch</span>
x_data <span style="color:#666">=</span> [<span style="color:#666">1</span>,<span style="color:#666">2</span>,<span style="color:#666">3</span>]
y_data <span style="color:#666">=</span> [<span style="color:#666">2</span>,<span style="color:#666">4</span>,<span style="color:#666">6</span>]
w <span style="color:#666">=</span> torch<span style="color:#666">.</span>Tensor([<span style="color:#666">1.0</span>])
w<span style="color:#666">.</span>requires_grad <span style="color:#666">=</span> True

<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward</span>(x):
    <span style="color:#a2f;font-weight:bold">return</span> x <span style="color:#666">*</span> w
<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">loss</span>(x,y):
    y_pred <span style="color:#666">=</span> forward(x)
    <span style="color:#a2f;font-weight:bold">return</span> (y_pred<span style="color:#666">-</span>y) <span style="color:#666">**</span> <span style="color:#666">2</span>
</code></pre></div><p>è®­ç»ƒè¿‡ç¨‹</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f">sum</span> <span style="color:#666">=</span> <span style="color:#666">0</span>
<span style="color:#a2f;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(<span style="color:#666">100</span>):
    <span style="color:#a2f;font-weight:bold">for</span> x, y <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">zip</span>(x_data, y_data): <span style="color:#080;font-style:italic"># æŠ½å–æ ·æœ¬</span>
        l <span style="color:#666">=</span> loss(x, y)     <span style="color:#080;font-style:italic"># å‰é¦ˆï¼šè®¡ç®—lossï¼Œè®¡ç®—å®Œé‡Šæ”¾</span>
        l<span style="color:#666">.</span>backward()                 <span style="color:#080;font-style:italic"># åé¦ˆ</span>
        <span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;</span><span style="color:#b62;font-weight:bold">\t</span><span style="color:#b44">grad:&#39;</span>, x, y, w<span style="color:#666">.</span>grad<span style="color:#666">.</span>item())  <span style="color:#080;font-style:italic">#itemæ˜¯ä¸€ä¸ªæ ‡é‡</span>
        w<span style="color:#666">.</span>data <span style="color:#666">=</span> w<span style="color:#666">.</span>data <span style="color:#666">-</span> <span style="color:#666">0.01</span> <span style="color:#666">*</span> w<span style="color:#666">.</span>grad<span style="color:#666">.</span>data  <span style="color:#080;font-style:italic"># æ³¨æ„æ­¤æ—¶gradè¦å–åˆ°data</span>
        <span style="color:#a2f">sum</span> <span style="color:#666">+=</span> l<span style="color:#666">.</span>item()              <span style="color:#080;font-style:italic"># è®¡ç®—æŸå¤±å’Œ</span>
        w<span style="color:#666">.</span>grad<span style="color:#666">.</span>data<span style="color:#666">.</span>zero_()             <span style="color:#080;font-style:italic"># æ¸…é›¶æ¢¯åº¦</span>
        
    <span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#34;progress:&#34;</span>, epoch, l<span style="color:#666">.</span>item())
</code></pre></div><p><strong>NOTICE</strong>:
The grad computed by <code>.backward()</code> will be accumulated. So after update, <strong>remember set the grad to ZERO!!</strong></p>
<ul>
<li><code>.data</code>è¿”å›çš„æ˜¯ä¸€ä¸ªTensorï¼Œè€Œ<code>.item()</code>è¿”å›çš„æ˜¯å…·ä½“çš„æ•°å€¼ï¼ˆéTensoræ•°æ®ç±»å‹ï¼‰ã€‚</li>
</ul>
<h3 id="framework">Framework</h3>
<p>4ä¸ªæ­¥éª¤ï¼š</p>
<p><strong>Prepare dataset</strong> : we shall talk about this later</p>
<p><strong>Design model using Class</strong>: inherit from nn.Module</p>
<p><strong>Construct loss and optimizer</strong>: using PyTorch API</p>
<p><strong>Training cycle</strong>: forward, backward, update</p>
<h4 id="prepare-dataset">Prepare dataset</h4>
<p>In PyTorch, the computational graph is in mini-batch fashion, so X and Y are $3 \times 1$ Tensors.</p>
<p>$$\hat{y}=w\cdot x+b$$
$$\left[\begin{aligned}&amp;y_{pred}^{(1)}\\ &amp;y_{pred}^{(2)} \\ &amp;y_{pred}^{(3)} \end{aligned}\right]=w\cdot \left[\begin{aligned}&amp;x^{(1)}\\ &amp;x^{(2)} \\ &amp;x^{(3)}\end{aligned}\right]+b$$</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch</span>
x_data <span style="color:#666">=</span> torch<span style="color:#666">.</span>Tensor([[<span style="color:#666">1.0</span>], [<span style="color:#666">2.0</span>], [<span style="color:#666">3.0</span>]])
y_data <span style="color:#666">=</span> torch<span style="color:#666">.</span>Tensor([[<span style="color:#666">2.0</span>], [<span style="color:#666">4.0</span>], [<span style="color:#666">6.0</span>]])
</code></pre></div><h4 id="design-model">Design Model</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">LinearModel</span>(torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Module):
    <span style="color:#a2f;font-weight:bold">def</span> __init__(self):     <span style="color:#080;font-style:italic"># æ„é€ å‡½æ•°</span>
        <span style="color:#a2f">super</span>(LinearModel, self)<span style="color:#666">.</span>__init__()  <span style="color:#080;font-style:italic"># è°ƒç”¨çˆ¶ç±»çš„æ„é€ </span>
        self<span style="color:#666">.</span>linear <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">1</span>,<span style="color:#666">1</span>)     <span style="color:#080;font-style:italic"># æ„é€ å¯¹è±¡</span>
    <span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward</span>(self, x):    <span style="color:#080;font-style:italic"># å¿…é¡»æœ‰forwardä¼ æ’­å‡½æ•°çš„å®šä¹‰</span>
        y_pred <span style="color:#666">=</span> self<span style="color:#666">.</span>linear(x)
        <span style="color:#a2f;font-weight:bold">return</span> y_pred

model <span style="color:#666">=</span> LinearModel()
</code></pre></div><ul>
<li><code>nn.Linear</code> contain two member Tensors: <strong>weight</strong> and <strong>bias</strong></li>
</ul>
<blockquote>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">torch</span><span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(in_features, out_features, bias <span style="color:#666">=</span> True)
</code></pre></div><p>Applies a linear transformation $y=Ax+b$
Parameters:</p>
<ul>
<li>in_features: the size of each input sample</li>
<li>out_features: the size of each output sample</li>
<li>bias: Default: True</li>
</ul>
</blockquote>
<p>å®é™…ä¸Šï¼Œåœ¨è¿ç®—è¿‡ç¨‹ä¸­æ˜¯<strong class=chinese>åšè½¬ç½®çš„</strong>
$$y=x\cdot w+b$$
$$y = w^{T}\cdot x+b$$</p>
<h4 id="construct-loss-and-optimizer">Construct Loss and Optimizer</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">criterion <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>MSELoss(size_average<span style="color:#666">=</span>False)
optimizer <span style="color:#666">=</span> torch<span style="color:#666">.</span>optim<span style="color:#666">.</span>SGD(model<span style="color:#666">.</span>parameters(), lr<span style="color:#666">=</span><span style="color:#666">0.01</span>)
</code></pre></div><blockquote>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">torch</span><span style="color:#666">.</span>nn<span style="color:#666">.</span>MSELoss(size_average, <span style="color:#a2f">reduce</span> <span style="color:#666">=</span> True)
</code></pre></div><p>æ±‚å‡æ–¹æ ¹å€¼ $l(x,y)=L={l_1,\cdots,l_N}^{T},\quad l_n=(x_n-y_n)^2$
å…¶ä¸­ï¼ŒNæ˜¯batch sizeã€‚</p>
</blockquote>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">torch</span><span style="color:#666">.</span>optim<span style="color:#666">.</span>SGD(params, lr<span style="color:#666">=&lt;</span><span style="color:#a2f">object</span> <span style="color:#a2f">object</span><span style="color:#666">&gt;</span>, momentum <span style="color:#666">=</span> <span style="color:#666">0</span>, dampening <span style="color:#666">=</span> <span style="color:#666">0</span>, weight_decay <span style="color:#666">=</span> <span style="color:#666">0</span>, nesterov <span style="color:#666">=</span> False)
</code></pre></div><p>Implements stochastic gradient descent (optionally with momentum)</p>
<h4 id="training-cycle">Training Cycle</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(<span style="color:#666">100</span>):
    y_pred <span style="color:#666">=</span> model(x_data)
    loss <span style="color:#666">=</span> criterion(y_pred, y_data)
    <span style="color:#a2f;font-weight:bold">print</span>(epoch, loss)
    
    optimizer<span style="color:#666">.</span>zero_grad()  <span style="color:#080;font-style:italic"># æ³¨æ„æ¢¯åº¦æ¸…é›¶</span>
    loss<span style="color:#666">.</span>backward()        <span style="color:#080;font-style:italic"># åå‘ä¼ æ’­</span>
    optimizer<span style="color:#666">.</span>step()       <span style="color:#080;font-style:italic">#Update</span>
</code></pre></div><h4 id="test-model">Test Model</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-style:italic"># Output weight and bias</span>
<span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;w=&#39;</span>, model<span style="color:#666">.</span>linear<span style="color:#666">.</span>weight<span style="color:#666">.</span>item())
<span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;b=&#39;</span>, model<span style="color:#666">.</span>linear<span style="color:#666">.</span>bias<span style="color:#666">.</span>item())

<span style="color:#080;font-style:italic"># Test Model</span>
x_test <span style="color:#666">=</span> torch<span style="color:#666">.</span>Tensor([<span style="color:#666">4.0</span>])
y_test <span style="color:#666">=</span> model(x_test)
<span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;y_pred=&#39;</span>, y_test<span style="color:#666">.</span>data)
</code></pre></div><h2 id="03-logistic-regression">03. Logistic Regression</h2>
<h3 id="one-dimension">One Dimension</h3>
<p><img src="/img/20210914162303.png" alt="">
Logistic function can guarantee that the output is in $[0,1]$, and loss function is $$loss=-(y\log \hat{y}+(1-y)\log (1-\hat{y}))$$
æ­¤æ—¶è¯¯å·®è®¡ç®—çš„æ˜¯åˆ†å¸ƒçš„å·®å¼‚ <strong>(BCE)</strong>ï¼Œè€Œä¸æ˜¯å‡ ä½•ä¸Šçš„è·ç¦»ã€‚</p>
<blockquote>
<p>Mini-Batch Loss Function for Binary Classification
$$loss=-\frac{1}{N}\sum^N_{n=1}(y_n\log \hat{y}_n+(1-y_n)\log (1-\hat{y}_n))$$</p>
</blockquote>
<p>æµç¨‹å’Œä¹‹å‰çš„å·®ä¸å¤šï¼Œä»£ç å¦‚ä¸‹ï¼š</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-style:italic">#---------------------Prepare dataset--------------------------#</span>
x_data <span style="color:#666">=</span> torch<span style="color:#666">.</span>Tensor([[<span style="color:#666">1.0</span>], [<span style="color:#666">2.0</span>], [<span style="color:#666">3.0</span>]])
y_data <span style="color:#666">=</span> torch<span style="color:#666">.</span>Tensor([[<span style="color:#666">0</span>], [<span style="color:#666">0</span>], [<span style="color:#666">1</span>]])

<span style="color:#080;font-style:italic">#-----------------Design model using Class---------------------#</span>
<span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">LogisticRegressionModel</span>(torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Module):
    <span style="color:#a2f;font-weight:bold">def</span> __init__(self):
        <span style="color:#a2f">super</span>(LogisticRegressionModel, self)<span style="color:#666">.</span>__init__()
        self<span style="color:#666">.</span>linear <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">1</span>, <span style="color:#666">1</span>)
    <span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward</span>(self, x):
        y_pred <span style="color:#666">=</span> F<span style="color:#666">.</span>sigmoid(self<span style="color:#666">.</span>linear(x))
        <span style="color:#a2f;font-weight:bold">return</span> y_pred
model <span style="color:#666">=</span> LogisticRegressionModel()

<span style="color:#080;font-style:italic">#----------------Construct loss and optimizer------------------#</span>
criterion <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>BCELoss(size_average<span style="color:#666">=</span>False)
optimizer <span style="color:#666">=</span> torch<span style="color:#666">.</span>optim<span style="color:#666">.</span>SGD(model<span style="color:#666">.</span>parameters(), lr<span style="color:#666">=</span><span style="color:#666">0.01</span>)

<span style="color:#080;font-style:italic">#----------------------Training cycle--------------------------#</span>
<span style="color:#a2f;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(<span style="color:#666">1000</span>):
    y_pred <span style="color:#666">=</span> model(x_data)
    loss <span style="color:#666">=</span> criterion(y_pred, y_data)
    <span style="color:#a2f;font-weight:bold">print</span>(epoch, loss<span style="color:#666">.</span>item())
    optimizer<span style="color:#666">.</span>zero_grad()
    loss<span style="color:#666">.</span>backward()
    optimizer<span style="color:#666">.</span>step()
</code></pre></div><h3 id="multi-dimension">Multi Dimension</h3>
<p>äºŒç»´æ•°æ®ä¸­ï¼Œä¸€èˆ¬æ¥è¯´åˆ—å¯¹åº”çš„æ˜¯featureï¼Œè¡Œå¯¹åº”çš„æ˜¯sampleï¼Œä¸€è¡Œä¸ºä¸€æ¡record</p>
<h4 id="mini-batchn-samples">Mini-Batchï¼ˆN samplesï¼‰</h4>
<p><img src="/img/20210914165040.png" alt=""></p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">Model</span>(torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Module):
    <span style="color:#a2f;font-weight:bold">def</span> __init__(self):
        <span style="color:#a2f">super</span>(Model, self)<span style="color:#666">.</span>__init__()
        self<span style="color:#666">.</span>linear <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">8</span>, <span style="color:#666">1</span>)
        self<span style="color:#666">.</span>sigmoid <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Sigmoid()
    <span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward</span>(self, x):
        x <span style="color:#666">=</span> self<span style="color:#666">.</span>sigmoid(self<span style="color:#666">.</span>linear(x))
        <span style="color:#a2f;font-weight:bold">return</span> x

model <span style="color:#666">=</span> Model()
</code></pre></div><h4 id="prepare-dataset-1">Prepare Dataset</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">numpy</span> <span style="color:#a2f;font-weight:bold">as</span> <span style="color:#00f;font-weight:bold">np</span>
xy <span style="color:#666">=</span> np<span style="color:#666">.</span>loadtxt(<span style="color:#b44">&#39;diabetes.csv.gz&#39;</span>, delimiter<span style="color:#666">=</span><span style="color:#b44">&#39;,&#39;</span>, dtype<span style="color:#666">=</span>np<span style="color:#666">.</span>float32)
x_data <span style="color:#666">=</span> torch<span style="color:#666">.</span>from_numpy(xy[:,:<span style="color:#666">-</span><span style="color:#666">1</span>]) <span style="color:#080;font-style:italic"># é™¤äº†æœ€åä¸€è¡Œéƒ½è¦</span>
y_data <span style="color:#666">=</span> torch<span style="color:#666">.</span>from_numpy(xy[:, [<span style="color:#666">-</span><span style="color:#666">1</span>]])
</code></pre></div><h4 id="define-model">Define Model</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch</span>
<span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">Model</span>(torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Module):
    <span style="color:#a2f;font-weight:bold">def</span> __init__(self):
        <span style="color:#a2f">super</span>(Model, self)<span style="color:#666">.</span>__init__()
        self<span style="color:#666">.</span>linear1 <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">8</span>, <span style="color:#666">6</span>)
        self<span style="color:#666">.</span>linear2 <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">6</span>, <span style="color:#666">4</span>)
        self<span style="color:#666">.</span>linear3 <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">4</span>, <span style="color:#666">1</span>)
        self<span style="color:#666">.</span>sigmoid <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Sigmoid()
    <span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward</span>(self, x):
        x <span style="color:#666">=</span> self<span style="color:#666">.</span>sigmoid(self<span style="color:#666">.</span>linear1(x))
        x <span style="color:#666">=</span> self<span style="color:#666">.</span>sigmoid(self<span style="color:#666">.</span>linear2(x))
        x <span style="color:#666">=</span> self<span style="color:#666">.</span>sigmoid(self<span style="color:#666">.</span>linear3(x))
        <span style="color:#a2f;font-weight:bold">return</span> x
    
model <span style="color:#666">=</span> Model()

</code></pre></div><h4 id="construct-loss-and-optimizer-1">Construct Loss and Optimizer</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">criterion <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>BCELoss(size_average<span style="color:#666">=</span>True)
optimizer <span style="color:#666">=</span> torch<span style="color:#666">.</span>optim<span style="color:#666">.</span>SGD(model<span style="color:#666">.</span>parameters(), lr<span style="color:#666">=</span><span style="color:#666">0.1</span>)
</code></pre></div><h4 id="training-cycle-1">Training Cycle</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(<span style="color:#666">100</span>):
    <span style="color:#080;font-style:italic"># Forward</span>
    y_pred <span style="color:#666">=</span> model(x_data)
    loss <span style="color:#666">=</span> criterion(y_pred, y_data)
    <span style="color:#a2f;font-weight:bold">print</span>(epoch, loss<span style="color:#666">.</span>item())

    <span style="color:#080;font-style:italic"># Backward</span>
    optimizer<span style="color:#666">.</span>zero_grad()
    loss<span style="color:#666">.</span>backward()

    <span style="color:#080;font-style:italic"># Update</span>
    optimizer<span style="color:#666">.</span>step()
</code></pre></div><h2 id="04-dataset-and-dataloader">04. Dataset and DataLoader</h2>
<h3 id="use-all-of-the-data">Use all of the data</h3>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">xy <span style="color:#666">=</span> np<span style="color:#666">.</span>loadtxt(<span style="">â€˜</span>diabetes<span style="color:#666">.</span>csv<span style="color:#666">.</span>gz<span style="">â€™</span> , delimiter<span style="color:#666">=</span><span style="">â€˜</span>,<span style="">â€™</span> , dtype<span style="color:#666">=</span>np<span style="color:#666">.</span>float32)
x_data <span style="color:#666">=</span> torch<span style="color:#666">.</span>from_numpy(xy[:,:<span style="color:#666">-</span><span style="color:#666">1</span>])
y_data <span style="color:#666">=</span> torch<span style="color:#666">.</span>from_numpy(xy[:, [<span style="color:#666">-</span><span style="color:#666">1</span>]])
<span style="">â€¦â€¦</span>
<span style="color:#a2f;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(<span style="color:#666">100</span>):
    <span style="color:#080;font-style:italic"># 1. Forward</span>
    y_pred <span style="color:#666">=</span> model(x_data)
    loss <span style="color:#666">=</span> criterion(y_pred, y_data)
    <span style="color:#a2f;font-weight:bold">print</span>(epoch, loss<span style="color:#666">.</span>item())
    <span style="color:#080;font-style:italic"># 2. Backward</span>
    optimizer<span style="color:#666">.</span>zero_grad()
    loss<span style="color:#666">.</span>backward()
    <span style="color:#080;font-style:italic"># 3. Update</span>
    optimizer<span style="color:#666">.</span>step()
</code></pre></div><h3 id="terminology">Terminology</h3>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-style:italic"># Training cycle</span>
<span style="color:#a2f;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(training_epochs):
    <span style="color:#080;font-style:italic"># Loop over all batches</span>
    <span style="color:#a2f;font-weight:bold">for</span> i <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(total_batch):
</code></pre></div><ul>
<li><strong>Epoch</strong>
One forward pass and one backward pass of <strong>all the training examples</strong>.</li>
<li><strong>Batch-Size</strong>
The <strong>number of training examples</strong> in one forward backward pass.</li>
<li><strong>Iteration</strong>
Number of passes, each pass using <strong>batch size</strong> number of examples.</li>
</ul>
<p>æ¯”å¦‚ï¼Œ1000ä¸ªæ ·æœ¬ï¼Œæˆ‘ä»¬åˆ†æˆ10ä¸ªBatchï¼ŒBatch-Size=100ï¼ŒIteration=10</p>
<h3 id="dataloader">DataLoader</h3>
<p><img src="/img/20210914182044.png" alt=""></p>
<p><strong>Define Dataset</strong></p>
<ul>
<li>Dataset æ˜¯ä¸€ä¸ªæŠ½è±¡ç±»ï¼Œä¸å¯ä»¥å®ä¾‹åŒ–ï¼›è€Œ DataLoader æ˜¯å¯ä»¥å®ä¾‹åŒ–çš„</li>
<li>number workers æŒ‡çš„æ˜¯å¤šçº¿ç¨‹å¹¶è¡Œçš„ä¸ªæ•°ï¼Œå¥½åƒ Windows ä¸Šå¿…é¡»æ˜¯0ï¼Œå»ºè®®åœ¨ Linux ä½¿ç”¨</li>
<li>getitem æ˜¯å½“æ•°æ®æ¯”è¾ƒå¤§ï¼Œéœ€è¦é€šè¿‡è¯»å–æ–‡ä»¶åæ¥ get ç›¸åº”çš„ item è¿›è¡Œå¤„ç†</li>
</ul>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch</span>
<span style="color:#a2f;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">torch.utils.data</span> <span style="color:#a2f;font-weight:bold">import</span> Dataset
<span style="color:#a2f;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">torch.utils.data</span> <span style="color:#a2f;font-weight:bold">import</span> DataLoader
<span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">DiabetesDataset</span>(Dataset):
    <span style="color:#a2f;font-weight:bold">def</span> __init__(self):
        <span style="color:#a2f;font-weight:bold">pass</span>
    <span style="color:#a2f;font-weight:bold">def</span> __getitem__(self, index):
        <span style="color:#a2f;font-weight:bold">pass</span>
    <span style="color:#a2f;font-weight:bold">def</span> __len__(self):
        <span style="color:#a2f;font-weight:bold">pass</span>
dataset <span style="color:#666">=</span> DiabetesDataset()
train_loader <span style="color:#666">=</span> DataLoader(dataset<span style="color:#666">=</span>dataset,
                          batch_size<span style="color:#666">=</span><span style="color:#666">32</span>,
                          shuffle<span style="color:#666">=</span>True,
                          num_workers<span style="color:#666">=</span><span style="color:#666">2</span>)
<span style="color:#a2f;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(<span style="color:#666">100</span>):
    <span style="color:#a2f;font-weight:bold">for</span> i, data <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">enumerate</span>(train_loader, <span style="color:#666">0</span>):
        <span style="">â€¦â€¦</span>
</code></pre></div><h4 id="example-diabetes-dataset">Example: Diabetes Dataset</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">DiabetesDataset</span>(Dataset):
    <span style="color:#a2f;font-weight:bold">def</span> __init__(self, filepath):
        xy <span style="color:#666">=</span> np<span style="color:#666">.</span>loadtxt(filepath, delimiter<span style="color:#666">=</span><span style="color:#b44">&#39;,&#39;</span>, dtype<span style="color:#666">=</span>np<span style="color:#666">.</span>float32)
        self<span style="color:#666">.</span>len <span style="color:#666">=</span> xy<span style="color:#666">.</span>shape[<span style="color:#666">0</span>] <span style="color:#080;font-style:italic"># å–ç¬¬0å…ƒç´ ï¼šé•¿åº¦</span>
        self<span style="color:#666">.</span>x_data <span style="color:#666">=</span> torch<span style="color:#666">.</span>from_numpy(xy[:, :<span style="color:#666">-</span><span style="color:#666">1</span>])
        self<span style="color:#666">.</span>y_data <span style="color:#666">=</span> torch<span style="color:#666">.</span>from_numpy(xy[:, [<span style="color:#666">-</span><span style="color:#666">1</span>]])
    <span style="color:#a2f;font-weight:bold">def</span> __getitem__(self, index):
        <span style="color:#a2f;font-weight:bold">return</span> self<span style="color:#666">.</span>x_data[index], self<span style="color:#666">.</span>y_data[index] <span style="color:#080;font-style:italic"># è¿”å›å¯¹åº”æ ·æœ¬å³å¯</span>
    <span style="color:#a2f;font-weight:bold">def</span> __len__(self):
        <span style="color:#a2f;font-weight:bold">return</span> self<span style="color:#666">.</span>len

dataset <span style="color:#666">=</span> DiabetesDataset(<span style="color:#b44">&#39;diabetes.csv.gz&#39;</span>)
train_loader <span style="color:#666">=</span> DataLoader(dataset<span style="color:#666">=</span>dataset,
                          batch_size<span style="color:#666">=</span><span style="color:#666">32</span>,
                          shuffle<span style="color:#666">=</span>True,
                          num_workers<span style="color:#666">=</span><span style="color:#666">2</span>)

<span style="color:#a2f;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(<span style="color:#666">100</span>):
    <span style="color:#a2f;font-weight:bold">for</span> i, data <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">enumerate</span>(train_loader, <span style="color:#666">0</span>):
        <span style="color:#080;font-style:italic"># 1. Prepare data</span>
        inputs, labels <span style="color:#666">=</span> data
        <span style="color:#080;font-style:italic"># 2. Forward</span>
        y_pred <span style="color:#666">=</span> model(inputs)
        loss <span style="color:#666">=</span> criterion(y_pred, labels)
        <span style="color:#a2f;font-weight:bold">print</span>(epoch, i, loss<span style="color:#666">.</span>item())
        <span style="color:#080;font-style:italic"># 3. Backward</span>
        optimizer<span style="color:#666">.</span>zero_grad()
        loss<span style="color:#666">.</span>backward()
        <span style="color:#080;font-style:italic"># 4. Update</span>
        optimizer<span style="color:#666">.</span>step()
</code></pre></div><ul>
<li>iä»£è¡¨çš„æ˜¯ç¬¬å‡ ç»„æ•°æ®ï¼Œè¡¨ç¤ºæ¯æ¬¡æ‹¿çš„æ˜¯ $x[i],y[i]$</li>
<li>train_loader æ‹¿å‡ºæ¥çš„æ˜¯ä¸€ä¸ªå…ƒç»„ $(X,Y)$ï¼Œæ˜¯ getitem ä¼ è¿‡æ¥çš„</li>
<li>0ä»£è¡¨æ˜¯ä»ç¬¬0ä¸ªå¼€å§‹æšä¸¾</li>
<li>inputsä»£è¡¨ xï¼Œlabelsä»£è¡¨yã€‚æˆ–è€…æˆ‘ä»¬å¯ä»¥å°†dataæ”¹ä¸º (input,labels)</li>
</ul>
<h2 id="05-softmax">05. Softmax</h2>
<h3 id="softmaxæ¦‚å¿µ">Softmaxæ¦‚å¿µ</h3>
<p>å¯¹äºå¤šè¾“å‡ºï¼Œæˆ‘ä»¬è¦å¯¹è¾“å‡ºè¿›è¡Œè¿›ä¸€æ­¥çš„<strong class=chinese>è§„æ ¼åŒ–</strong>
$$P(y=i)\ge 0\qquad \sum_{i=0}^9 P(y=i)=1$$
Suppose $ğ‘^ğ‘™ âˆˆ â„^ğ¾$ is the output of the last linear layer, the* Softmax function*:
$$P(y=i)=\frac{e^{z_i}}{\sum_{j=0}^{K-1} e^{z_j}},\quad i\in {0,\cdots ,K-1}$$</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch</span>
criterion <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>CrossEntropyLoss()
Y <span style="color:#666">=</span> torch<span style="color:#666">.</span>LongTensor([<span style="color:#666">2</span>, <span style="color:#666">0</span>, <span style="color:#666">1</span>])

Y_pred1 <span style="color:#666">=</span> torch<span style="color:#666">.</span>Tensor([[<span style="color:#666">0.1</span>, <span style="color:#666">0.2</span>, <span style="color:#666">0.9</span>],
                        [<span style="color:#666">1.1</span>, <span style="color:#666">0.1</span>, <span style="color:#666">0.2</span>],
                        [<span style="color:#666">0.2</span>, <span style="color:#666">2.1</span>, <span style="color:#666">0.1</span>]])
Y_pred2 <span style="color:#666">=</span> torch<span style="color:#666">.</span>Tensor([[<span style="color:#666">0.8</span>, <span style="color:#666">0.2</span>, <span style="color:#666">0.3</span>],
                        [<span style="color:#666">0.2</span>, <span style="color:#666">0.3</span>, <span style="color:#666">0.5</span>],
                        [<span style="color:#666">0.2</span>, <span style="color:#666">0.2</span>, <span style="color:#666">0.5</span>]])

l1 <span style="color:#666">=</span> criterion(Y_pred1, Y)
l2 <span style="color:#666">=</span> criterion(Y_pred2, Y)
<span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#34;Batch Loss1 = &#34;</span>, l1<span style="color:#666">.</span>data, <span style="color:#b44">&#34;</span><span style="color:#b62;font-weight:bold">\n</span><span style="color:#b44">Batch Loss2=&#34;</span>, l2<span style="color:#666">.</span>data)
</code></pre></div><h3 id="crossentropyloss-vs-nulloss">CrossEntropyLoss vs NULLoss</h3>
<h3 id="implementation">Implementation</h3>
<h4 id="package">Package</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch</span>
<span style="color:#a2f;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">torchvision</span> <span style="color:#a2f;font-weight:bold">import</span> transforms
<span style="color:#a2f;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">torchvision</span> <span style="color:#a2f;font-weight:bold">import</span> datasets
<span style="color:#a2f;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">torch.utils.data</span> <span style="color:#a2f;font-weight:bold">import</span> DataLoader
<span style="color:#a2f;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch.nn.functional</span> <span style="color:#a2f;font-weight:bold">as</span> <span style="color:#00f;font-weight:bold">F</span>
<span style="color:#a2f;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch.optim</span> <span style="color:#a2f;font-weight:bold">as</span> <span style="color:#00f;font-weight:bold">optim</span>
</code></pre></div><ul>
<li><code>transform</code>: å¯¹æ•°æ®é›†è¿›è¡Œå¤„ç†</li>
<li><code>F</code>: For using function relu()</li>
<li><code>optim</code>: For constructing Optimizer</li>
</ul>
<h4 id="prepare-dataset-2">Prepare Dataset</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">batch_size <span style="color:#666">=</span> <span style="color:#666">64</span>
transform <span style="color:#666">=</span> transforms<span style="color:#666">.</span>Compose([
    transforms<span style="color:#666">.</span>ToTensor(),
    transforms<span style="color:#666">.</span>Normalize((<span style="color:#666">0.1307</span>, ), (<span style="color:#666">0.3081</span>, ))
])

train_dataset <span style="color:#666">=</span> datasets<span style="color:#666">.</span>MNIST(root<span style="color:#666">=</span><span style="color:#b44">&#39;../dataset/mnist/&#39;</span>,
                               train<span style="color:#666">=</span>True,
                               download<span style="color:#666">=</span>True,
                               transform<span style="color:#666">=</span>transform)
train_loader <span style="color:#666">=</span> DataLoader(train_dataset,
                          shuffle<span style="color:#666">=</span>True,
                          batch_size<span style="color:#666">=</span>batch_size)

test_dataset <span style="color:#666">=</span> datasets<span style="color:#666">.</span>MNIST(root<span style="color:#666">=</span><span style="color:#b44">&#39;../dataset/mnist/&#39;</span>,
                              train<span style="color:#666">=</span>False,
                              download<span style="color:#666">=</span>True,
                              transform<span style="color:#666">=</span>transform)
test_loader <span style="color:#666">=</span> DataLoader(test_dataset,
                         shuffle<span style="color:#666">=</span>False,
                         batch_size<span style="color:#666">=</span>batch_size)
</code></pre></div><ul>
<li>transformæ˜¯ä¸ºäº†Normalizationæ•°æ®ï¼Œ0.1307æ˜¯å‡å€¼ï¼Œ0.3081æ˜¯æ ‡å‡†å·®ã€‚è¿™æ˜¯MNISTæ•°æ®é›†ç»è¿‡è®¡ç®—æ‰€å¾—åˆ°çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚</li>
</ul>
<h4 id="design-model-1">Design Model</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">Net</span>(torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Module):
    <span style="color:#a2f;font-weight:bold">def</span> __init__(self):
        <span style="color:#a2f">super</span>(Net, self)<span style="color:#666">.</span>__init__()
        self<span style="color:#666">.</span>l1 <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">784</span>, <span style="color:#666">512</span>)
        self<span style="color:#666">.</span>l2 <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">512</span>, <span style="color:#666">256</span>)
        self<span style="color:#666">.</span>l3 <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">256</span>, <span style="color:#666">128</span>)
        self<span style="color:#666">.</span>l4 <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">128</span>, <span style="color:#666">64</span>)
        self<span style="color:#666">.</span>l5 <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Linear(<span style="color:#666">64</span>, <span style="color:#666">10</span>)
    <span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward</span>(self, x):
        x <span style="color:#666">=</span> x<span style="color:#666">.</span>view(<span style="color:#666">-</span><span style="color:#666">1</span>, <span style="color:#666">784</span>)
        x <span style="color:#666">=</span> F<span style="color:#666">.</span>relu(self<span style="color:#666">.</span>l1(x))
        x <span style="color:#666">=</span> F<span style="color:#666">.</span>relu(self<span style="color:#666">.</span>l2(x))
        x <span style="color:#666">=</span> F<span style="color:#666">.</span>relu(self<span style="color:#666">.</span>l3(x))
        x <span style="color:#666">=</span> F<span style="color:#666">.</span>relu(self<span style="color:#666">.</span>l4(x))
        <span style="color:#a2f;font-weight:bold">return</span> self<span style="color:#666">.</span>l5(x)

model <span style="color:#666">=</span> Net()
</code></pre></div><h4 id="construct-loss-and-optimizer-2">Construct Loss and Optimizer</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">criterion <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>CrossEntropyLoss()
optimizer <span style="color:#666">=</span> optim<span style="color:#666">.</span>SGD(model<span style="color:#666">.</span>parameters(), lr<span style="color:#666">=</span><span style="color:#666">0.01</span>, momentum<span style="color:#666">=</span><span style="color:#666">0.5</span>)
</code></pre></div><h4 id="train-and-test">Train and Test</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">train</span>(epoch):
    running_loss <span style="color:#666">=</span> <span style="color:#666">0.0</span>
    <span style="color:#a2f;font-weight:bold">for</span> batch_idx, data <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">enumerate</span>(train_loader, <span style="color:#666">0</span>):
        inputs, target <span style="color:#666">=</span> data
        optimizer<span style="color:#666">.</span>zero_grad()
        <span style="color:#080;font-style:italic"># forward + backward + update</span>
        outputs <span style="color:#666">=</span> model(inputs)
        loss <span style="color:#666">=</span> criterion(outputs, target)
        loss<span style="color:#666">.</span>backward()
        optimizer<span style="color:#666">.</span>step()
        running_loss <span style="color:#666">+=</span> loss<span style="color:#666">.</span>item()
        <span style="color:#a2f;font-weight:bold">if</span> batch_idx <span style="color:#666">%</span> <span style="color:#666">300</span> <span style="color:#666">==</span> <span style="color:#666">299</span>:
            <span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;[</span><span style="color:#b68;font-weight:bold">%d</span><span style="color:#b44">, </span><span style="color:#b68;font-weight:bold">%5d</span><span style="color:#b44">] loss: </span><span style="color:#b68;font-weight:bold">%.3f</span><span style="color:#b44">&#39;</span> <span style="color:#666">%</span> (epoch <span style="color:#666">+</span> <span style="color:#666">1</span>, batch_idx <span style="color:#666">+</span> <span style="color:#666">1</span>, running_loss <span style="color:#666">/</span> <span style="color:#666">300</span>))
            running_loss <span style="color:#666">=</span> <span style="color:#666">0.0</span>
</code></pre></div><div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">test</span>():
    correct <span style="color:#666">=</span> <span style="color:#666">0</span>
    total <span style="color:#666">=</span> <span style="color:#666">0</span>
    <span style="color:#a2f;font-weight:bold">with</span> torch<span style="color:#666">.</span>no_grad():
        <span style="color:#a2f;font-weight:bold">for</span> data <span style="color:#a2f;font-weight:bold">in</span> test_loader:
            images, labels <span style="color:#666">=</span> data
            outputs <span style="color:#666">=</span> model(images)
            _, predicted <span style="color:#666">=</span> torch<span style="color:#666">.</span>max(outputs<span style="color:#666">.</span>data, dim<span style="color:#666">=</span><span style="color:#666">1</span>)
            total <span style="color:#666">+=</span> labels<span style="color:#666">.</span>size(<span style="color:#666">0</span>)
            correct <span style="color:#666">+=</span> (predicted <span style="color:#666">==</span> labels)<span style="color:#666">.</span>sum()<span style="color:#666">.</span>item()
    <span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;Accuracy on test set: </span><span style="color:#b68;font-weight:bold">%d</span><span style="color:#b44"> </span><span style="color:#b68;font-weight:bold">%%</span><span style="color:#b44">&#39;</span> <span style="color:#666">%</span> (<span style="color:#666">100</span> <span style="color:#666">*</span> correct <span style="color:#666">/</span> total))
</code></pre></div><div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">range</span>(<span style="color:#666">10</span>):
    train(epoch)
    test()
</code></pre></div><h4 id="mention">MENTION</h4>
<p>æˆ‘ä»¬åœ¨æ‰“æ ‡ç­¾çš„æ—¶å€™éœ€è¦ä»0å¼€å§‹ï¼Œå¦åˆ™æ˜¯æœ‰é—®é¢˜çš„ã€‚</p>
<h2 id="06-cnn">06. CNN</h2>
<p>å·ç§¯ç¥ç»ç½‘ç»œå¯ä»¥åšåˆ°ä¿ç•™åŸå§‹çš„ç©ºé—´ä¿¡æ¯ï¼Œè€Œå…¨è¿æ¥å±‚æ˜¯å±•å¼€æˆä¸€ä¸ªï¼Œæ— æ³•ä¿ç•™ç©ºé—´ä¿¡æ¯ã€‚</p>
<p><img src="/img/20210915121409.png" alt=""></p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch</span>
in_channels, out_channels<span style="color:#666">=</span> <span style="color:#666">5</span>, <span style="color:#666">10</span>
width, height <span style="color:#666">=</span> <span style="color:#666">100</span>, <span style="color:#666">100</span>
kernel_size <span style="color:#666">=</span> <span style="color:#666">3</span>
batch_size <span style="color:#666">=</span> <span style="color:#666">1</span>

<span style="color:#a2f">input</span> <span style="color:#666">=</span> torch<span style="color:#666">.</span>randn(batch_size,
                    in_channels,
                    width,
                    height)

conv_layer <span style="color:#666">=</span> torch<span style="color:#666">.</span>nn<span style="color:#666">.</span>Conv2d(in_channels,
                             out_channels,
                             kernel_size<span style="color:#666">=</span>kernel_size)

output <span style="color:#666">=</span> conv_layer(<span style="color:#a2f">input</span>)

<span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#a2f">input</span><span style="color:#666">.</span>shape)
<span style="color:#a2f;font-weight:bold">print</span>(output<span style="color:#666">.</span>shape)
<span style="color:#a2f;font-weight:bold">print</span>(conv_layer<span style="color:#666">.</span>weight<span style="color:#666">.</span>shape)
</code></pre></div><p>è¾“å‡ºä¸ºï¼š</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">torch<span style="color:#666">.</span>Size([<span style="color:#666">1</span>, <span style="color:#666">5</span>, <span style="color:#666">100</span>, <span style="color:#666">100</span>])
torch<span style="color:#666">.</span>Size([<span style="color:#666">1</span>, <span style="color:#666">10</span>, <span style="color:#666">98</span>, <span style="color:#666">98</span>])
torch<span style="color:#666">.</span>Size([<span style="color:#666">10</span>, <span style="color:#666">5</span>, <span style="color:#666">3</span>, <span style="color:#666">3</span>])
</code></pre></div><h3 id="mnist-example">MNIST Example</h3>
<p><img src="/img/20210915122114.png" alt=""></p>
<h4 id="move-model-to-gpu">Move Model to GPU</h4>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">device <span style="color:#666">=</span> torch<span style="color:#666">.</span>device(<span style="color:#b44">&#34;cuda:0&#34;</span> <span style="color:#a2f;font-weight:bold">if</span> torch<span style="color:#666">.</span>cuda<span style="color:#666">.</span>is_available() <span style="color:#a2f;font-weight:bold">else</span> <span style="color:#b44">&#34;cpu&#34;</span>)
model<span style="color:#666">.</span>to(device)

<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">train</span>(epoch):
    running_loss <span style="color:#666">=</span> <span style="color:#666">0.0</span>
    <span style="color:#a2f;font-weight:bold">for</span> batch_idx, data <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">enumerate</span>(train_loader, <span style="color:#666">0</span>):
        inputs, target <span style="color:#666">=</span> data
        inputs, target <span style="color:#666">=</span> inputs<span style="color:#666">.</span>to(device), target<span style="color:#666">.</span>to(device)
        optimizer<span style="color:#666">.</span>zero_grad()
        
        <span style="color:#080;font-style:italic"># forward + backward + update</span>
        outputs <span style="color:#666">=</span> model(inputs)
        loss <span style="color:#666">=</span> criterion(outputs, target)
        loss<span style="color:#666">.</span>backward()
        optimizer<span style="color:#666">.</span>step()
        running_loss <span style="color:#666">+=</span> loss<span style="color:#666">.</span>item()
        <span style="color:#a2f;font-weight:bold">if</span> batch_idx <span style="color:#666">%</span> <span style="color:#666">300</span> <span style="color:#666">==</span> <span style="color:#666">299</span>:
            <span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;[</span><span style="color:#b68;font-weight:bold">%d</span><span style="color:#b44">, </span><span style="color:#b68;font-weight:bold">%5d</span><span style="color:#b44">] loss: </span><span style="color:#b68;font-weight:bold">%.3f</span><span style="color:#b44">&#39;</span> <span style="color:#666">%</span> (epoch <span style="color:#666">+</span> <span style="color:#666">1</span>, batch_idx <span style="color:#666">+</span> <span style="color:#666">1</span>, running_loss <span style="color:#666">/</span> <span style="color:#666">2000</span>))
            running_loss <span style="color:#666">=</span> <span style="color:#666">0.0</span>
            
<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">test</span>():
    correct <span style="color:#666">=</span> <span style="color:#666">0</span>
    total <span style="color:#666">=</span> <span style="color:#666">0</span>
    <span style="color:#a2f;font-weight:bold">with</span> torch<span style="color:#666">.</span>no_grad():
        <span style="color:#a2f;font-weight:bold">for</span> data <span style="color:#a2f;font-weight:bold">in</span> test_loader:
            inputs, target <span style="color:#666">=</span> data
            inputs, target <span style="color:#666">=</span> inputs<span style="color:#666">.</span>to(device), target<span style="color:#666">.</span>to(device)
            outputs <span style="color:#666">=</span> model(inputs)
            _, predicted <span style="color:#666">=</span> torch<span style="color:#666">.</span>max(outputs<span style="color:#666">.</span>data, dim<span style="color:#666">=</span><span style="color:#666">1</span>)
            total <span style="color:#666">+=</span> target<span style="color:#666">.</span>size(<span style="color:#666">0</span>)
            correct <span style="color:#666">+=</span> (predicted <span style="color:#666">==</span> target)<span style="color:#666">.</span>sum()<span style="color:#666">.</span>item()
    <span style="color:#a2f;font-weight:bold">print</span>(<span style="color:#b44">&#39;Accuracy on test set: </span><span style="color:#b68;font-weight:bold">%d</span><span style="color:#b44"> </span><span style="color:#b68;font-weight:bold">%%</span><span style="color:#b44"> [</span><span style="color:#b68;font-weight:bold">%d</span><span style="color:#b44">/</span><span style="color:#b68;font-weight:bold">%d</span><span style="color:#b44">]&#39;</span> <span style="color:#666">%</span> (<span style="color:#666">100</span> <span style="color:#666">*</span> correct <span style="color:#666">/</span> total, correct, total))

</code></pre></div><h3 id="inception-module">Inception Module</h3>
<p><img src="/img/20210915173840.png" alt=""></p>
<h4 id="1x1-convolution">1x1 convolution</h4>
<p>å¯ä»¥<strong class=chinese>æ”¹å˜é€šé“æ•°é‡</strong>ï¼Œå¯ä»¥è·¨è¶Šä¸åŒé€šé“ç›¸åŒåƒç´ çš„å€¼ï¼Œåšåˆ°äº†ä¿¡æ¯èåˆçš„ç›®çš„ã€‚
å·ç§¯æ ¸çš„æ•°é‡å°±ä»£è¡¨äº†é€šé“çš„æ•°é‡ã€‚
ä½œç”¨ï¼šé™ä½è¿ç®—é‡</p>
<p><img src="/img/20210915175019.png" alt=""></p>

    
  </article>
  <div class="paginator">
    
    <a class="link" href="https://preminstrel.github.io/blog/post/2021/10/17/vim-basics/">â† prev</a>
    
    
    <a class="link" href="https://preminstrel.github.io/blog/post/2021/10/17/quantization-compression/">next â†’</a>
    
  </div>
  <div class="comment">
    
    
    
    
    
    
  </div>
  
</main>

    <footer id="footer">
  <div>
    <span>Â© 2021</span> - <span>2022</span>
  </div>

  <div>
    <span>Powered by </span>
    <a class="link" href="https://gohugo.io/">Hugo</a>
    <span> ğŸ¦ Theme </span>
    <a class="link" href="https://github.com/queensferryme/hugo-theme-texify">TeXify</a>
  </div>

  <div class="footnote">
    <span>Follow me on <a class=link href=https://github.com/preminstrel>GitHub</a>,
<a class=link href=https://twitter.com/preminstrel>Twitter</a> or
<a class=link href=/index.xml>RSS</a> |
<a class=link href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank rel=noopener>CC BY-NC-SA 4.0</a>
</span>
  </div>
</footer>

  </div>

  
  

  
  

  
  

</body>

</html>
