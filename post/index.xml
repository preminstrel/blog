<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Blog de Preminstrel</title>
    <link>https://preminstrel.github.io/blog/post/</link>
    <description>Recent content in Posts on Blog de Preminstrel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>preminstrel@gmail.com (Hanshi Sun)</managingEditor>
    <webMaster>preminstrel@gmail.com (Hanshi Sun)</webMaster>
    <lastBuildDate>Tue, 21 Mar 2023 19:46:54 +0800</lastBuildDate><atom:link href="https://preminstrel.github.io/blog/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>M.S.申请回忆录[未完待更]</title>
      <link>https://preminstrel.github.io/blog/post/2023/03/21/ms_app/</link>
      <pubDate>Tue, 21 Mar 2023 19:46:54 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2023/03/21/ms_app/</guid>
      
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“ My Heart is in the Work.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Andrew Carnegie, Founder November 15, 1900&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;之前听过一句话，&lt;strong&gt;大学的生活珍贵到无论如何度过，都觉得是虚度光阴&lt;/strong&gt;。2022可以说是我大学中的一个transition了，这一年发生了太多太多，从大三结束，到加拿大暑研，到Apple实习，到23Fall的申请季，再到疫情的放开。考完了最后的试，见了南长街，参了南禅寺，最后一顿二楼聚餐，120周年校庆的纪念版校园卡……在SEU的生活，差不多落下了一个句号。考完的那一天，看着夕阳，我失去了辨别天与海的能力。我知道，在这个校园内的生活屈指可数了。&lt;/p&gt;
&lt;p&gt;我本科是EE的，但是research基本做的都是ML/CV的东西，所以申请ECE方向带DS/ML的track，有一些转专业的意思，所以放弃了一些硬件EE项目。关于MS申请，前期也做了一些工作，和同学也讨论了很多次。&lt;a href=&#34;https://trinkle23897.github.io/posts/application&#34;&gt;n+e的这篇blog&lt;/a&gt; 给了我很多有用的信息，我准备这次写总结也差不多按照这位大佬的格式来。我申请所用到的材料大概包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;成绩单和在读证明 (中英文都要，&lt;del&gt;UMich得用scholaro计算GPA，我直接掉了0.14&lt;/del&gt;)，排名证明 (Optional，这个找教务开，但是学校的档案馆不给翻译，就在公证的地方找了一个英文翻译服务)，高中毕业证公证 (ETHz要求)&lt;/li&gt;
&lt;li&gt;TOEFL&amp;amp;GRE&lt;/li&gt;
&lt;li&gt;文书 (CV, SoP, PS/PHS, Diversity Statement)&lt;/li&gt;
&lt;li&gt;三封推荐信&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gpa&#34;&gt;GPA&lt;/h2&gt;
&lt;p&gt;首先是出身，本科是东南大学，感觉US对于985什么的都不太认识，除了头部的那几个，但是对于上海科技大学、南方科技大学等学校都很认可。&lt;/p&gt;
&lt;p&gt;我的GPA还是不错的，得益于SEU比较好的GPA评分机制，申请的时候3.98/4.0，均分94.04。我感觉SEU的GPA不是很难拿，专业课基本上把往年题刷一遍，课后题弄清楚了都可以90分左右。但是需要注意的是&lt;strong&gt;GPA的边际效益很不好，对于申请来说可能3.98和3.9，甚至和3.85的区别不是特别巨大的，然而，从3.9提升到3.98所花费的时间成本却远远高于所得到的好处&lt;/strong&gt;。有条件最好还是多分一些时间给软背景，我申请就是吃了这个亏，科研很弱，软背景不够强，Top项目很难申请。&lt;/p&gt;
&lt;p&gt;有条件的建议大三去交换，既可以轻松拿高绩点，而且可以白嫖学校的出国补助 (up to 120k)，更是可以拿到推荐信，建立海外connection。&lt;/p&gt;
&lt;h2 id=&#34;toeflgre&#34;&gt;TOEFL&amp;amp;GRE&lt;/h2&gt;
&lt;p&gt;对于TG，&lt;strong&gt;一定要早考，杜绝拖延症&lt;/strong&gt;。我就是因为之前一直没考上，拖到大三暑假在加拿大暑研的时候才考出TOEFL成绩，而且GRE也没时间考了，所幸今年的MS项目大多还是optional/not required，这个一定要提前check好各个项目的要求，同时注意best score用处不是很大。
TOEFL感觉最重要最难的是听力，最容易提升的是写作。还有一点是，多约几次多考几次，有的时候真的只是运气问题，我托福最后拿了115分 (30 | 30 | 27 | 28)，我感觉纯粹是运气使然，口语有的题目都没来得及说完。在国外考托福有一个福利就是很便宜，价格大概是国内的一半。
但是TOEFL其实不用过多看重，有时候中介和一些机构就是喜欢让你把语言和标化考的高起来 (e.g., 110+/105+)。实际上TOEFL也就是一个filter，过了那个线就无所谓了。对于大部分学校，100够用了；对于个别学校，要105；对于极其奇葩的项目，要很奇怪的分数，比如CMU一个项目要Speaking 28+。&lt;/p&gt;
&lt;h2 id=&#34;科研rl&#34;&gt;科研&amp;amp;RL&lt;/h2&gt;
&lt;p&gt;这一部分，我的失败，彻彻底底。我&lt;strong&gt;大学最失败的一点就是没有用卷GPA一半的时间出来做research&lt;/strong&gt;。所以我科研做的工作都比较水，对于研究领域也没有很强的insight；建议有Ph.D.理想的少发EI水会，真的用处不是很大，而且有时候会起反作用，让人觉得你水水的。当然，如果目标只是MS的话，其实还可以在简历上装点一下门面的，虽然作用也仅仅是装点门面了&amp;hellip;&lt;/p&gt;
&lt;p&gt;我的科研主要分为三段。第一段是校内的SRTP，一个省级项目，大二暑假写了一篇一作EI投了&lt;del&gt;现在看来我当时写的就是厕纸，做的work也很差&lt;/del&gt;。第二段是校内计算机实验室跟的一个老师，做的计算机视觉在Medical Imaging上的一些应用。虽然没有什么产出，但是感觉学的东西比第一段要多，申请的时候有一篇SCI四作，用处不是很大。第三段是Mitacs暑研去加拿大Alberta做的Unsupervised Learning for Anomaly Detection的项目，申请的时候有一篇二作在投。三篇推荐信也出自这三段科研中，其中加拿大暑研的老师是自己写自己交的推荐信，其他两位都是我自己的写了让学校老师签名的。&lt;/p&gt;
&lt;p&gt;加拿大supervisor人真的很nice，不仅自己写推荐信还帮我交的贼快，几乎我这里系统里刚一发invite；我申请了22个项目她都挨个交了，真的是人特别好特别好，很幸运能遇到这么好一个老师。当然，东大的老师人也非常nice，回复都很及时，遇到大家真的很幸运。学校里两个老师的推荐信我都让中介帮我拟稿了，有一点要注意的就是最好用不同的letter format和不同的口吻。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/BcsLpI7my9E2Ubx&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2023/03/21/BcsLpI7my9E2Ubx.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;关于Mitacs暑研，我感觉是一次很好的机会，因为它是带funding的，算是SEU平台难得的暑研（公费旅游）机会了。在克服了签证，机票，Covid PCR等一系列困难后，带着快一百斤的行李，坐了快一天一夜的飞机来到了Edmonton。Edmonton的夏天不冷不热，穿一件刚刚好。在UofA的校园里闲逛，一切都仿佛那么新奇。劝退的餐饮费让我自学了煎牛排，意大利面，通心粉，煮水饺，下鸡蛋面……认识了许多志同道合的小伙伴，同时也一定程度上锻炼了自己的口语（还一直是菜狗🐶）。Banff的Lake Louise很美，美的不那么真实，水质很像是电影中渲染的特效。在河边，我获得了全网统一的头像（笑。Banff之后，我便染上了Covid，拖着咳嗽剧痛的嗓子参加了托福首考，最后94分 (Speaking 20)。忘不了麦当劳的Poutine，忘不了Timms的平价咖啡，忘不了Botanic Garden，忘不了Southgate的Apple Store，忘不了Green Golden 的Alberta。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/puUPXQjnFI3qvLb&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2023/03/21/puUPXQjnFI3qvLb.jpg&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;实习&#34;&gt;实习&lt;/h2&gt;
&lt;p&gt;我在加拿大暑研的时候还顺便投了Apple R&amp;amp;D的intern岗位，具体经历在&lt;a href=&#34;https://zhuanlan.zhihu.com/p/603277820&#34;&gt;知乎上有过一篇文章&lt;/a&gt;，主要是因为感觉大四的时候应该比较清闲，而且简历上也没有professional experience这一section，所以想要找个internship做一下，顺便也想看看工业界和学术界的区别。由于抱着随便投投的心态，所以只投了比较喜欢的Apple（资深果粉XD）。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sm.ms/image/6UDe7WnAhGR3zi5&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2023/03/21/6UDe7WnAhGR3zi5.jpg&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2022.8 在Apple中国官网海投简历，附件为transcript，resume和一些link（LinkedIn，GitHub等）。&lt;/p&gt;
&lt;p&gt;2022.9 收到HR的电话（那时候我彻底把Apple这事情忘了，刚开始我还以为是骚扰电话，挂了很多次没接），HR简单问了一下我的基本情况和时间安排之后说尽快帮我安排面试。过了几天我收到了面试的邀请，用webex参加了面试。&lt;/p&gt;
&lt;p&gt;一面是team的manager，人很友善。首先让我自我介绍，并详细了解了我的那些research经历。面试本应是英文的，但是因为我当时人在加拿大做research intern，所以他说就不用考察我这部分能力了。基本情况了解后，便随便chat了一段时间，没有考察任何的题目和基础知识掌握程度，也没有code review。整个面试时间大概半个小时，聊的很开心。&lt;/p&gt;
&lt;p&gt;2022.10 过了一个月，这个月我又把这事情给忘了，这次接到面试的邀请的时候我刚从加拿大回来，在上海的隔离酒店。这次面试我的是一个未来会一起工作的同事，他首先讲了一下team做的事情和他正在做的project，让我有所了解。随后，他问了我的research experience中写到的一个anomaly detection算法如何应用于XXX，我简单讲了一下，然后挑了一篇论文的可视化heat map给他看。又chat了一会后，他问我愿意不愿意来帮他做这个project，我说挺好的，也挺感兴趣。整个面试时间大概也是半小时左右。&lt;/p&gt;
&lt;p&gt;2022.11 在家摸鱼的时候，接到了HR的电话说我被录了，可以开始走入职流程了，背景调查了两周之后我顺利拿到了offer。在这之后还收到了爱丁堡交流项学期交流项目的offer（因为本来准备去英国玩一阵子，没想着Apple能录），忍痛放弃了去旅游的机会。当月就入职了Apple，开始打工，合同签到了6.30，也就是我毕业的时候。&lt;/p&gt;
&lt;p&gt;有趣的是，在9月的时候，我还面了一个EPM岗（HR瞎给的面试，我一点相关经历没有，面试前十分钟才去查了一下EPM是啥…）。面试是全英文，刚聊五分钟我就想退出会议了，之后痛苦地尬聊了半小时，也没有后续了。&lt;/p&gt;
&lt;p&gt;关于薪资/津贴/房补和其他福利等就不讲了，对于实习来说感觉很满意。最近感觉Apple R&amp;amp;D在国内的坑位变多了，感兴趣的小伙伴可以投一下。感觉bar其实也还好，主要是看对眼。入职检查的时候查出来眼底有问题，眼压有点高，让我更加意识到了健康的重要性，sigh。&lt;/p&gt;
&lt;p&gt;在Apple干了也有几个月了，感觉还可以，同事都很nice，老板还想留我干到八月底。&lt;del&gt;虽然也经常摸鱼哈哈哈。&lt;/del&gt;&lt;/p&gt;
&lt;h2 id=&#34;选校&#34;&gt;选校&lt;/h2&gt;
&lt;p&gt;由于我科研比较弱，Paper都是水文章，所以我只能申请MS，Ph.D.只抽了一个UCSD (因为UCSD的MS要GRE&amp;hellip;)。选校我只分了三个level：Reach，Match和Safety (实际上Match里面还要细分一下，bar还是有很大区别的，有的分的也不是很合理)。主要申请美国，欧洲只申请了双E，因为有Mitacs的Graduate Fellowship所以加拿大随手申了两个。排名的话CS专业的话可以参考&lt;a href=&#34;https://csrankings.org/#/fromyear/2012/toyear/2023/index?all&amp;amp;us&#34;&gt;CS Ranking&lt;/a&gt;，但是要注意的是，faculty越多，分数也会越高，所以这个ranking也是有bias的。公认的四大一般是MIT、Stanford、Berkeley和CMU~~，其中CMU经常被开除Top4~~。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;彩票&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stanford EE，这个今年招了很多人耶，但是女生居多，是男生的好几倍，这种顶级项目某种程度上也很看运气&lt;/li&gt;
&lt;li&gt;Caltech EE，class size很小，某种程度上比Stanford还要难&lt;/li&gt;
&lt;li&gt;UCSD ECE PhD&lt;/li&gt;
&lt;li&gt;UIUC CS MS，因为ECE MS要GRE所以我只能申请CS送钱&lt;/li&gt;
&lt;li&gt;UMich CSE，这个bar对于我们这些本科EE的人来说还是很高的，所以放在了彩票，但是价值不一定能与前面四个媲美&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;主申&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CMU ECE/MSIN，这俩项目都是CMU工程学院的，所以也不用再交一次TOEFL；相比ECE，MSIN更加偏就业导向，甚至没有什么faculty。CMU是CS的四大，但是综合排名比较一般~~，计算机技校~~&lt;/li&gt;
&lt;li&gt;UT Austin ECE，这个项目的class size很小，DICE track基本不收人，我申请的是bioECE，好像也不咋收人，Austin的好处就是更好转PhD，学费便宜，可以RA/TA，基本可以cover很多花销~~，偷偷说一句，他们家的申请系统做的是真的烂啊，和UW的申请系统有的一比~~&lt;/li&gt;
&lt;li&gt;GaTech ECE，因为在黑人区所以治安有一些concern，招的人也不是特别多，价格相对便宜&lt;/li&gt;
&lt;li&gt;ETHz EEIT/EPFL EE，瑞士双E，国际排名很牛，今年ETHz要GRE，我没交。我们学校在ETHz是每年有一些quota的，电子信息专业的均分大于91的感觉都有希望。花费少，签证好过，风景好，排名牛，但是缺点就是读PhD要卷硕士GPA，research时间会比较少，而且和US的connection的不是那么多，有点曲线救国的意思&lt;/li&gt;
&lt;li&gt;UCLA ECE，地域较好，处于加州，学费也便宜，但是他家ECE偏Hardware一些，我申请的signal方向，并不太喜欢&lt;/li&gt;
&lt;li&gt;Duke ECE，我拿了offer之后才知道Duke ECE很贵，Duke的综排还可以US Top10，专排不行，这个项目也可以选成全软课&lt;/li&gt;
&lt;li&gt;NWU CS MS，今年NWU CS陆本拒麻了，这个学校和Duke一样，综排还可以，专排不行&lt;/li&gt;
&lt;li&gt;UofT CS MScAc，一个就业导向项目，8 months coursework+8 months applied research internship，多大的title在加拿大也挺好用的。这个项目interview是硬性要求，shortlist之后会慢慢发面试。面试是和项目的Administration聊大概45min，我是三月中旬收到interview invitation的，晚上十点聊的，感觉Claire人还是很好的，开始的时候就说会尽快结束，我说渴了可以随时喝点东西哈哈哈&lt;/li&gt;
&lt;li&gt;UBC ECE MSc，科研项目，没套瓷的话基本属于送钱，我套瓷套晚了，没收到答复&lt;/li&gt;
&lt;li&gt;Columbia CS MS，哥大的class size太大了不太好，申请单纯是为了CS title，尤其是哥大的EE~~，俗称点击就送，今年看见有人EE没交申请费没完成申请都被发了offer~~&lt;/li&gt;
&lt;li&gt;Berkeley EECS MEng，Berkeley的EECS很强，但是这个项目是MEng，项目的优势是title和加州的地理位置吧&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;保底&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cornell ECE MEng，这个项目其实难度不应该放在保底，应该是主申-保底的过渡，在我这里排名比较低是因为我有一些MEng的bias；康奈尔国内名气很不错&lt;/li&gt;
&lt;li&gt;USC CS，加州私立，不看推荐信，不看文书，只看三维，保底专用&lt;/li&gt;
&lt;li&gt;UPenn ESE，UPenn的bar也很低&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Program&lt;/th&gt;
&lt;th&gt;Level&lt;/th&gt;
&lt;th&gt;Decision&lt;/th&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Stanford EE MS&lt;/td&gt;
&lt;td&gt;Reach&lt;/td&gt;
&lt;td&gt;Rejected&lt;/td&gt;
&lt;td&gt;Feb 22, 2023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Caltech EE MS&lt;/td&gt;
&lt;td&gt;Reach&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UCSD ECE PhD&lt;/td&gt;
&lt;td&gt;Reach&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UIUC CS MS&lt;/td&gt;
&lt;td&gt;Reach&lt;/td&gt;
&lt;td&gt;Rejected&lt;/td&gt;
&lt;td&gt;Mar 16, 2023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UMich CSE MS&lt;/td&gt;
&lt;td&gt;Reach&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CMU ECE MS&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;Admitted&lt;/td&gt;
&lt;td&gt;Feb 17, 2023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CMU MSIN MS&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;Waitlist&lt;/td&gt;
&lt;td&gt;Mar 10, 2023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UT Austin ECE MS&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GaTech ECE MS&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ETHz EEIT MS&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EPFL EE MS&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;Rejected&lt;/td&gt;
&lt;td&gt;Mar 16, 2023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UCLA ECE MS&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Duke ECE MS&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;Admitted&lt;/td&gt;
&lt;td&gt;Feb 7, 2023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NWU CS MS&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;Rejected&lt;/td&gt;
&lt;td&gt;Feb 10, 2023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UofT CS MScAc&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UBC ECE MSc&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Columbia CS MS&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Berkeley EECS MEng&lt;/td&gt;
&lt;td&gt;Match&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cornell ECE MEng&lt;/td&gt;
&lt;td&gt;Safety&lt;/td&gt;
&lt;td&gt;Admitted&lt;/td&gt;
&lt;td&gt;Mar 9, 2023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;USC CS MS&lt;/td&gt;
&lt;td&gt;Safety&lt;/td&gt;
&lt;td&gt;Admitted&lt;/td&gt;
&lt;td&gt;Mar 14, 2023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UPenn ESE MSE&lt;/td&gt;
&lt;td&gt;Safety&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;文书&#34;&gt;文书&lt;/h2&gt;
&lt;p&gt;文书的重要性无法确定，但是我感觉凭&lt;strong&gt;先尽人事而以待天命&lt;/strong&gt;的态度，我也得把文书好好写了，不仅是为了申请，也是为了给自己大学三年一个交代。在反复修改PS的时候，也对未来的career plan有了一些清楚的认知。&lt;/p&gt;
&lt;h3 id=&#34;cv&#34;&gt;CV&lt;/h3&gt;
&lt;p&gt;我在大三申请Mitacs暑研的时候就写过了CV，申请季用了新的LaTeX template重构了一下，模版在&lt;a href=&#34;https://github.com/preminstrel/MS-Application/tree/master/CV&#34;&gt;这里&lt;/a&gt;。
PDF：&lt;a href=&#34;https://preminstrel.com/MS-Application/CV/resume.pdf&#34;&gt;https://preminstrel.com/MS-Application/CV/resume.pdf&lt;/a&gt;
html：&lt;a href=&#34;https://preminstrel.com&#34;&gt;https://preminstrel.com&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;页边距可以适当调整，但是不要太离谱&lt;/li&gt;
&lt;li&gt;注意一些格式，比如bullet point，时间格式等&lt;/li&gt;
&lt;li&gt;不要超过两页，除非特别牛，Pub很多那种；如果没有价值的东西太多，建议一页&lt;/li&gt;
&lt;li&gt;检查embedded link是否有效&lt;/li&gt;
&lt;li&gt;用Grammarly或GPT检查一下语法拼写&lt;/li&gt;
&lt;li&gt;不用写上了哪些课，除非真的没东西写了/大幅度转专业&lt;/li&gt;
&lt;li&gt;建议写的compact一些&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sop&#34;&gt;SoP&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://trinkle23897.github.io/posts/application&#34;&gt;n+e的这篇blog&lt;/a&gt; 讲的很好，我刚开始SoP也是CV的单纯流水账，什么都想塞进去，导致写得很烂还很长，SoP一般要求是两页，about 1k words。之后我痛改前非，几乎重构了第一版的SoP。到最后，大概修订了五个版本的样子。我还找了fiverr帮我改SoP，真的好贵。有几个点是我想说的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最好删除已经在简历中出现过的GPA，成绩，奖项，申请；SoP要展示的是你的motivation和experience，而不是重复成绩单上的东西&lt;/li&gt;
&lt;li&gt;Motivation，有意思的开头有深度的引子，讲出为什么喜欢这个专业&lt;/li&gt;
&lt;li&gt;Preparation/Qualification，体现了主观的motivation转向实践（详细），描写最重要的两个项目（精华），对专业的认识加深，体现了自己的客观capability，进一步激发了兴趣，并加强了你的信念，即很适合该课程的学习&lt;/li&gt;
&lt;li&gt;强调过程，不要设置一个问题并跳到解决方案。展示达成该解决方案的过程。给出方法和推理的细节。举一个之前看到的例子，&amp;ldquo;As a result of the in-depth exposure to networks I gained in the dormitory project, I was well prepared for the challenges that awaited me as the manager of Information Services at the Transportation Center at Northwestern University.&amp;quot;，只有在最后一句，才开始扩展到更广泛的教训&lt;/li&gt;
&lt;li&gt;提出了一个明确的、有意义的观点，与该段中提出的证据紧密相连。还必须谈到一些更广泛的意义，但是很多人很容易被冲昏头脑，写得太笼统，或者采取简单的方法用一些肤浅的东西来作为result。即套话是没有用的，这一点有点像托福写作，Do not be hollow。&lt;/li&gt;
&lt;li&gt;Career goals，写出你的3-5年的future plan和ultimate goal&lt;/li&gt;
&lt;li&gt;Why School，research部分可以提到到心仪faculty的名字，并表明对他们的工作有一些了解。这个需要去对每个学校你感兴趣的faculty进行调研，看看他们最近发的paper是干嘛的；课程部分也可以写，可以体现你的interest&lt;/li&gt;
&lt;li&gt;最好有整个文章的大目的，要有递进式，段与段之间要有比较自然的transition&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* Avoid the &amp;#34;what I did with my life&amp;#34; approach.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* Avoid the &amp;#34;I&amp;#39;ve always wanted to be a &amp;#34; approach.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* Avoid a catalog of achievements. This is only a list of what you have done, and tells nothing about you as a person. Normally, the statement is far more than a resume.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* Avoid lecturing the reader. For example, you should not write a statement such as &amp;#34;Communication skills are important in this field.&amp;#34; Any graduate admissions committee member knows that and is not trying to learn about the field from the applicant. Some statements do ask applicants about their understanding of the field.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* It should be objective, yet self-revelatory. Write directly and in a straightforward manner that tells about your experience and what it means to you. Do not use &amp;#34;academese.&amp;#34; This is not a research paper for a professor.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* It should form conclusions that explain the value and meaning of your experience, such as what you learned about yourself and your field, your future goals, and your career plans. Draw your conclusions from the evidence your life provides.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* It should be specific. Document your conclusions with specific instances, or draw your conclusions as the result of individual experience. See below a list of general words and phrases to avoid using without explanation.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* It should be an example of careful persuasive writing. Career Center Counselors can help you determine if this is so by reviewing your draft statement.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* It should get to the point early on and catch the attention of the reader.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* It often should be limited in length, no more than two pages or less. In some instances it may be longer, depending on the school&amp;#39;s instructions.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;psphsdiversity-statement&#34;&gt;PS/PHS/Diversity Statement&lt;/h3&gt;
&lt;p&gt;我是亚洲男性工科生，感觉没有任何的diversity，只能说是first generation这样的。我写了在加拿大暑研的经历，感受到了加拿大推行diversity，想要以后为这个field contribute什么的，感觉没一点用。这里挺推荐各位女同学抽一抽顶级项目的，感觉顶级项目还是很看diversity的，比如大S的EE，国内今年录取的女生是数倍于男生的。这里又得夸一夸&lt;a href=&#34;https://trinkle23897.github.io/posts/application&#34;&gt;n+e的这篇blog&lt;/a&gt; 里面的PHS了，他写的非常好，他在GitHub上有很多开源的贡献，可以从这个点出发。&lt;/p&gt;
&lt;h2 id=&#34;网申&#34;&gt;网申&lt;/h2&gt;
&lt;p&gt;用的outlook邮箱+gmail邮箱搞的，用国内邮箱怕offer/reject直接进trash。送分只送了托福，下面统计一下花费。
总共$2711.88，不到两万人民币：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TOEFL送分 $21x20，其中UCLA送了两次，EPFL没送&lt;/li&gt;
&lt;li&gt;Stanford $125&lt;/li&gt;
&lt;li&gt;Caltech $100&lt;/li&gt;
&lt;li&gt;UCSD $155&lt;/li&gt;
&lt;li&gt;UCLA $155&lt;/li&gt;
&lt;li&gt;UIUC $90&lt;/li&gt;
&lt;li&gt;CMU $75x2&lt;/li&gt;
&lt;li&gt;GaTech $85&lt;/li&gt;
&lt;li&gt;Duke $95&lt;/li&gt;
&lt;li&gt;UofT $91.31&lt;/li&gt;
&lt;li&gt;Cornell $105&lt;/li&gt;
&lt;li&gt;NWU $95&lt;/li&gt;
&lt;li&gt;USC $90&lt;/li&gt;
&lt;li&gt;UPenn $90&lt;/li&gt;
&lt;li&gt;UMich $90&lt;/li&gt;
&lt;li&gt;Columbia  $85&lt;/li&gt;
&lt;li&gt;UBC $122.91&lt;/li&gt;
&lt;li&gt;Berkeley $155&lt;/li&gt;
&lt;li&gt;ETHz $161.33&lt;/li&gt;
&lt;li&gt;EPFL $161.33&lt;/li&gt;
&lt;li&gt;UT Austin $90&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个小插曲，刚开始我还申了UW，但是UW的推荐信系统坏掉了推荐信没发出去，加上网申系统很烂，失去好感，后续没申请；ETHz刚开始一直收不到Xingyu的推荐信，之后联系了小蜜解决了。&lt;/p&gt;
&lt;h2 id=&#34;等拒信&#34;&gt;等拒信&lt;/h2&gt;
&lt;p&gt;这里主要是timeline，偷个懒，把知乎的回答粘贴过来。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;学校：中游工科 985
专业：EE
申请：ECE/CS
GPA：3.98/4.0, 均分94+, 小专业Rank1, TOEFL 115 (S27)，GRE没空学了就没考（菜狗不想努力了
科研：校内三段，mitacs加拿大暑研一段，水论文几篇
实习：Apple R&amp;amp;D一段 (Nov-present, base深圳)
推荐信：两封本校+一封海外暑研
其他：国奖x2, 其他小奖加起来不到2w (太碎了，很多都没想写到CV)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Dec 23: 交完了所有的申请，自此邮箱陷入长期沉默状态&lt;/p&gt;
&lt;p&gt;Feb 7: 1st AD ECE@Duke&lt;/p&gt;
&lt;p&gt;Feb 10: 1st REJ CS@NWU，NWU CS今年貌似不咋收陆本&lt;/p&gt;
&lt;p&gt;Feb 18：2nd AD ECE@CMU，有点想去&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://smms.app/image/Y7xthfnimgvRMp4&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2023/03/21/Y7xthfnimgvRMp4.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Feb 23：2nd REJ EE@Stanford，摸奖失败，今年好像扩招了，比往年收了更多人，女生居多&lt;/p&gt;
&lt;p&gt;Mar 9：3rd AD ECE MEng@Cornell，应该不会去，算集邮了&lt;/p&gt;
&lt;p&gt;Mar 10：1st WL MSIN@CMU，听说往年5月份Waitlist才可能转正，其实相当于REJ了&lt;/p&gt;
&lt;p&gt;Mar 14：4th AD CS37@USC，3rd REJ CS28@USC，还收到了UofT的interview邀请&lt;/p&gt;
&lt;p&gt;Mar 16：4th REJ CS@UIUC，5th REJ EE@EPFL&lt;/p&gt;
&lt;p&gt;Mar 18：晚上和UofT的老师interview，聊了45min&lt;/p&gt;
&lt;p&gt;咋感觉剩下想要知道结果的都要全聚德了。。&lt;/p&gt;
&lt;h2 id=&#34;miscfun-facts&#34;&gt;Misc/Fun Facts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ETHz有一个ESOP option，我还写了一个master thesis pre-proposal，实际上就是把本科毕业设计的任务书改了改加了点文献翻译一下交了过去，还装模作样地拟了一个timeline&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://smms.app/image/orPIGVeyFKL82u7&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2023/03/21/orPIGVeyFKL82u7.png&#34; &gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;fin&#34;&gt;Fin&lt;/h2&gt;
&lt;p&gt;此处还没开始写 XD
等申请季正式结束再重写一遍本文
PLACEHOLDER！&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Banff Trip</title>
      <link>https://preminstrel.github.io/blog/post/2022/07/20/banff_trip/</link>
      <pubDate>Wed, 20 Jul 2022 12:58:09 -0600</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/07/20/banff_trip/</guid>
      
      <description>&lt;p&gt;When I arrived Edmonton, I have signed up a trip to Banff. After I signed the waiver, I was on the bus to Banff on July 15th. I lived with two Indians and Ruiqi, who is from HUST, majoring in Mechanical Engineering. One of the Indians is called Simha, the name of Lion King, which sounds very ambitious. We have a night chat, and I got to know that universities in India employ the origin English textbooks and teach them in English, which is really a shock to me. Simha said that his major is computer science and he has some papers accepcted by top conference like CVPR and AAAI. His intern toppic is related to ECG diagnosis, extremely resembling my first topic. Just when we are sharing our viewpoint upon the projects, Ruiqi had taken a lot of photos of the sky with twinkling stars.&lt;/p&gt;
&lt;p&gt;On July 16th, we waked up pretty early and got a ride to Lake Louise, which I think is the best sencery during this trip. We took enormous photos and chose a very well-taken one as our avater in all social networking accounts. The most impressive thing is that I got the new avatar with Lake Louise.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/preminstrel/preminstrel.github.io/raw/master/assets/img/bio.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;After that, we had a boat floting tour around the moutains on the limpid water. To be frank, it is very cozy for me to enjoy the comfortable wind with tiny sway. We had a lunch at Banff Town and we selected a Chinese resturant for just some appetizers because the main dishes are so expensive that we cannot afford it.&lt;/p&gt;
&lt;p&gt;In the afternoon, we made the acquaintance of Kinh and Toya, who are from Vitnam and Japan respectly, and now we are Asian Five.&lt;/p&gt;
&lt;p&gt;I think the 17th trip is not as interesting as 16th, which is just like a dessert after main dishes. Therefore, I will demonstrate it in this blog.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Canada Entry</title>
      <link>https://preminstrel.github.io/blog/post/2022/07/09/canada-entry/</link>
      <pubDate>Sat, 09 Jul 2022 16:04:30 -0600</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/07/09/canada-entry/</guid>
      
      <description>&lt;p&gt;今年 7 月 6 号的时候，坐上了上海浦东 PVG 出发的 AC026 航班，前往加拿大温哥华 YVR 后转机至 YEG。在温哥华办理了入境手续，先取了行李，随后去 Immigration Office 办理了 Visitor Record，给我签到了 2022/10/31。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Canada Visa</title>
      <link>https://preminstrel.github.io/blog/post/2022/05/09/canada-visa/</link>
      <pubDate>Mon, 09 May 2022 16:15:25 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/05/09/canada-visa/</guid>
      
      <description>&lt;h2 id=&#34;application---march&#34;&gt;Application - March&lt;/h2&gt;
&lt;p&gt;参与 Mitacs 项目需要申请加拿大签证，这里进行一个申请的记录。这个项目让我们申请的是 TRV (Temporary Resident Visa)，通过 GSS (Global Skill Strategy) 在入境时申请 Work Exemption，也就是说，我申请的是 Visitor Visa V-1。但是实际上，目前很多人下的签都是 WX-1，是工签，有人是 MULTIPLE，也有人是 ONE。由于我还没贴签，所以不太清楚自己下的是什么。&lt;/p&gt;
&lt;p&gt;申请的时候，有两个通道，分别是 GCKey 和 IRCC Portal，前者是老通道，后者是疫情之后才开放的新通道。老通道是填表，同时要上传很多材料；新通道是类似于做问卷一样，填入一些信息，eye-friendly。我选择了 Portal 进行申报，在三月一号的时候完成了签证的申请。在缴费 $185 的时候，我发现用 Mastercard 付款失败了，但是用银联的信用卡反而成功了，群里也有人反应说借记卡也可以付款成功。指纹采集信当天就下来了，我预约了三月四号中午去上海的签证中心录指纹。&lt;/p&gt;
&lt;h2 id=&#34;biometrics---march&#34;&gt;Biometrics - March&lt;/h2&gt;
&lt;p&gt;三月四日，我坐动车去上海的加拿大签证中心进行生物信息采集 (Biometrics)，本想去一趟斌斌舅舅家玩，但是由于他有事还是算了。录指纹的时候要携带：护照、护照复印件、同意书、指纹采集信；在采集完之后会给你一个热敏打印一样的小贴纸，这个不能扔，要好好保管住了，在贴签的时候以及出入境都要查看。指纹有效期是十年，所以十年之内再申请加签是不用再录指纹的。录完指纹后，我在南京路逛了逛，中午吃了西餐，下午去了一趟外文书店看了看。随后改签了动车，早早就回无锡了。&lt;/p&gt;
&lt;h2 id=&#34;webform---april&#34;&gt;Webform - April&lt;/h2&gt;
&lt;p&gt;签证迟迟不下，我便利用 Webform 进行了催签，上海和北京和加拿大的都催了一下，收到了北京签证中心的回复，但是回复令人心寒，通篇的基调是 negative 的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Email from &lt;code&gt;beijing-immigration@international.gc.ca&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;Please be advised that your application is currently undergoing standard background checks and the processing time will be extended. Unfortunately, we are unable to advice at this time when a final decision might be made.&lt;/p&gt;
&lt;p&gt;Please note that all applications are considered on their own merits and there is no guarantee that a visa will be issued.  You will be advised if any further documentation or information is required.&lt;/p&gt;
&lt;p&gt;Should you wish to withdraw your application, please send signed a written request advising this office that you wish to withdraw your application to &lt;a href=&#34;mailto:beijing-immigration@international.gc.ca&#34;&gt;beijing-immigration@international.gc.ca&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;加拿大签证中心给的回复稍微中性一些，但是都是套话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Good day Hanshi Sun,&lt;/p&gt;
&lt;p&gt;Thank you for contacting Immigration, Refugees and Citizenship Canada (IRCC).&lt;/p&gt;
&lt;p&gt;We verified the information you provided and can confirm that your application is still in process.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;re-application---april&#34;&gt;Re-application - April&lt;/h2&gt;
&lt;p&gt;由于害怕自己被拒签，所以又在 GCKey 上申请了一次，多花了 $100，还申请了调档，花了 ￥100。GCKey申请后指纹自动同步了，这次没过几天就开始了 review。过了仅仅五个工作日，在 2022-04-29 的凌晨 02:00，我的邮箱先后收到了 IRCC Portal 的 Withdraw 和 GCKey 的 Original Passport Request，重新递交的效果显著！&lt;/p&gt;
&lt;p&gt;GCKey Timeline:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Subject&lt;/th&gt;
&lt;th&gt;Date sent&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Original Passport Request&lt;/td&gt;
&lt;td&gt;April 28, 2022&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Correspondence Letter&lt;/td&gt;
&lt;td&gt;April 28, 2022&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Submission Confirmation&lt;/td&gt;
&lt;td&gt;April 21, 2022&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Confirmation of Online Application Transmission&lt;/td&gt;
&lt;td&gt;April 21, 2022&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;申请材料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application for Visitor Visa (Temporary Resident Visa) Made Outside of Canada (IMM5257): &lt;code&gt;imm5257e.pdf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Offer of Employment: &lt;code&gt;invitation-letter + award-letter&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Proof of Work Permit Exemption: &lt;code&gt;award-letter.pdf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Family Information Form (IMM5707): &lt;code&gt;imm5707e.pdf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Travel History: &lt;code&gt;travel.pdf&lt;/code&gt; (概述去过的境外国家经历+目的+签证)&lt;/li&gt;
&lt;li&gt;Passport: &lt;code&gt;passport.pdf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;General Education and Employment Form: &lt;code&gt;imm0104e.pdf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Proof of Means of Financial Support: &lt;code&gt;invitation-letter + award-letter + 芝麻信用英文报告&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Digital photo: &lt;code&gt;photo.jpg&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Purpose of Travel - Other: 描述本次去的目的和行程，写一个文档，转成 PDF 上传&lt;/li&gt;
&lt;li&gt;Proof that you Meet the Requirements of the Job Being Offered： 成绩单 + invitation-letter + award-letter&lt;/li&gt;
&lt;li&gt;Schedule 1 - Application for a Temporary Resident Visa Made Outside Canada (IMM 5257): &lt;code&gt;imm5257b_1.pdf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当天将护照和相关材料用顺丰寄出，寄到北京加拿大签证申请中心，静候贴签的 tracking number。&lt;/p&gt;
&lt;h2 id=&#34;vfs---may&#34;&gt;VFS - May&lt;/h2&gt;
&lt;p&gt;五月四号，五一节之后的第一天，收到 VFS 邮件，&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tracking ID No. - 20220504CNBJPKT72344 - Your application has been dispatched from the Canada Visa Application Centre to the IRCC Office on Wed May 04 2022 for processing.&lt;/p&gt;
&lt;p&gt;Regards,&lt;/p&gt;
&lt;p&gt;VFS Global&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第二封：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tracking ID No. - 20220504CNBJPKT72344 - Your application has been received and is under process at the IRCC Office on Thu May 05 2022.&lt;/p&gt;
&lt;p&gt;Regards,&lt;/p&gt;
&lt;p&gt;VFS Global&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第三封（五月六日）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tracking ID No. - 20220504CNBJPKT72344 - The decision envelope for your application has been dispatched from the IRCC Office to the Canada Visa Application Centre.&lt;/p&gt;
&lt;p&gt;Regards,&lt;/p&gt;
&lt;p&gt;VFS Global&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第四封（五月六日）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tracking ID No. - 20220504CNBJPKT72344 - The decision envelope for your application has been received at the Canada Visa Application Centre on Fri May 06 2022 from the IRCC Office, and is ready for collection or further delivery by courier as per your option upon the submission of the application. For details of the VAC locations, please refer to our website at: &lt;a href=&#34;https://visa.vfsglobal.com/chn/en/can/attend-centre;&#34;&gt;https://visa.vfsglobal.com/chn/en/can/attend-centre;&lt;/a&gt; for the business hours of operation under the COVID impact, please refer to our website at: &lt;a href=&#34;https://visa.vfsglobal.com/chn/en/can/news/covid-update&#34;&gt;https://visa.vfsglobal.com/chn/en/can/news/covid-update&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Regards,&lt;/p&gt;
&lt;p&gt;VFS Global&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第五封（五月六日）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The decision envelope for your application, tracking ID No. 20220504CNBJPKT72344 has been couriered from the Canada Visa Application Centre, Canada Visa Application Centre, Beijing on Fri May 06 2022 via courier partner. Please use Tracking id. or the AWB number provided to track the shipment on the courier partners website after 24hrs.&lt;/p&gt;
&lt;p&gt;Regards,&lt;/p&gt;
&lt;p&gt;VFS Global&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;五月九日，收到了北京发来的 EMS，贴签结束。查看签证后，发现是 WX-1，有效期到 2029-07-08，还算满意了。但是申请签证的过程，堪称折磨。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Tales of Arise</title>
      <link>https://preminstrel.github.io/blog/post/2022/05/05/tales-of-arise/</link>
      <pubDate>Thu, 05 May 2022 22:18:01 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/05/05/tales-of-arise/</guid>
      
      <description>&lt;blockquote&gt;
&lt;p&gt;Keep the sentence, until everything is settled. &amp;mdash;&amp;mdash; Shionne&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Tales of Arise is the first video game of Tales Series I played. I am impressed by its remarkable landscape and typical characters. However, I think it should be a gap between it and Xenoblade Chronicles 2. The plot of TOA (Tales of Arise) is a little conservative that I can even predict the end. Moreover, the music exactly does not match the plot or scenes. Somehow, I regard it as pale.&lt;/p&gt;
&lt;h2 id=&#34;characters-and-plots&#34;&gt;Characters and Plots&lt;/h2&gt;
&lt;p&gt;The male protagonist is the typical JRPG role. And the emotional or love details of the male and female protagonists are adequately described, which is commendable. The heroine is born to be untouchable and the hero can touch her thanks to his sealed nervous system. Therefore, typically, it is a &amp;ldquo;boy meets girl&amp;rdquo; story. Immense quantity of little dialogues falshcards effectively contribute to the constructing the characters and its personalities. Maybe because of the shortage of budget or time limit, the last phase of the plot seems a little hash and does not provide enough time for me to enjoy and digest. Thanks to the kindness of &lt;a href=&#34;https://www.bandainamcostudios.com/en/&#34;&gt;BANDAI NAMCO Studios Inc.&lt;/a&gt;, the end is a satisfactory for me and most players. But, you know, cause the XB2 (Xenoblade Chronicles 2) made a great impact to me, such plots or characters are not that attractive.&lt;/p&gt;
&lt;h2 id=&#34;scenes&#34;&gt;Scenes&lt;/h2&gt;
&lt;p&gt;The scenes of TOA is really a big deal, which has made a milestone for JRPG area, proving that the scene of JRPG can be that impressvie. It could be the new game egnie or rendering method that makes such wonderful world and characters with exactly pragmatic consumption of GPU and CPU memory. It is a really advancement for Tales Series and JRPG! Congratulations!&lt;/p&gt;
&lt;h2 id=&#34;music&#34;&gt;Music&lt;/h2&gt;
&lt;p&gt;To be frank, expect for the two OP and ED, the music is terrible, especially the background music. I hope the BANDAI could be careful dealing with DLC sale strategy because I heard that the music can be improved by the DCL purchase. The OP and animation perfomance is really remarkable, but I have no more words for overall music. After all, I like the OP2: &lt;code&gt;Hello,Again～昔からある場所～&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;combat-system&#34;&gt;Combat System&lt;/h2&gt;
&lt;p&gt;I truly appreciate the clever artificial intelligence operation, which even is better than me. Thanks to the beatiful and impressive combat aniamtion, the system can be better than I think. The strategy can be set in advance, which is friendly. However, the quantity of boring side quests and repetitive monster battles is not that satisfying.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Although I don&amp;rsquo;t play a lot of JRPGs, I think a story can be very simple or very old-fashioned, but as long as the characters who accompany him on this journey for dozens of hours can continue to live happily in this game, and my own life is also empowered because of this, so all I can say is, it&amp;rsquo;s a good game.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plots: ★★★&lt;/li&gt;
&lt;li&gt;Characters:  ★★★&lt;/li&gt;
&lt;li&gt;Scenes: ★★★★★&lt;/li&gt;
&lt;li&gt;Music: ★★&lt;/li&gt;
&lt;li&gt;System: ★★★&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Mitacs Globalink Research Interns</title>
      <link>https://preminstrel.github.io/blog/post/2022/04/15/mitacs/</link>
      <pubDate>Fri, 15 Apr 2022 13:47:07 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/04/15/mitacs/</guid>
      
      <description>&lt;p&gt;去年八月份的时候，学校教务处官网发了申报 Mitacs 项目的相关申报流程。简单来说，这个项目是加拿大 Mitasc 和 CSC 的合作项目，每年选派 200 名本科生在大三暑假去加拿大各高校去进行 Research。这个项目和自己套的暑研比，优缺点也是比较明显的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pros&lt;/strong&gt;: 每个月国家提供经费 $1800，国家承担来回机票，报销签证费用；Mitacs 免费帮买保险，也有理由可以去进行课内的暑期短学期的学分替换，签证申请比较方便等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: 套到的项目和学校都不如自己套的好，项目匹配机制比较迷，周期很长，需要填很多材料，申请流程比较繁琐。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我最后是录到了 University of Alberta 的 ECE department 的一个华人老师 &lt;a href=&#34;https://www.ece.ualberta.ca/~xingyu/index.html&#34;&gt;Xingyu Li&lt;/a&gt; 的 Weak/self supervision for abnormal detection in medical image analysis 项目，下面我来简单谈谈申请流程。&lt;/p&gt;
&lt;h2 id=&#34;personal-background&#34;&gt;Personal Background&lt;/h2&gt;
&lt;p&gt;首先提供我申请时的背景。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本科 SEU，CGPA: 3.98/4, 93.8/100&lt;/li&gt;
&lt;li&gt;无语言成绩，无竞赛，有国奖等零碎的奖学金&lt;/li&gt;
&lt;li&gt;有一段相关科研和毫不相关的科研经历，有一篇 EI 水会并未在 CV 提及&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;timeline&#34;&gt;Timeline&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;2021-09-04&lt;/em&gt;   完成 Mitacs 网申，收到自动回复的邮件说 Application Complete&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2021-09-26&lt;/em&gt;   收到邮件说申请 portal 已关闭：2022 Globalink Research Internship applications now closed&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2021-11-07&lt;/em&gt;   陆续有人收到拒信&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2021-11-10&lt;/em&gt;   官网更新消息，CUC (Candidate under consideration)，也就是通过初审，进入项目匹配阶段。这一阶段大家可能会收到一些老师的面试和相关信息&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2021-11-18&lt;/em&gt;   收到第一个面试邮件，是我 Rank 7 UBC 的一位女老师。提出了以下面试细节：
&lt;ul&gt;
&lt;li&gt;5-10 min interview&lt;/li&gt;
&lt;li&gt;Zoom is required, with video if possible&lt;/li&gt;
&lt;li&gt;time restricted, on Friday Nov 19th, noon PDT (Vancouver time)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2021-11-20&lt;/em&gt;   凌晨四点，进入 Zoom 会议，面试的人有七个，我排在倒数第二个，我以为大概五点多到我，但是四点半就到我了。因为这个老师面试极快，先 30s 介绍了自己的项目，然后就问了我一个问题——介绍你以前的project，我讲之前，她问我你能不能在两分钟之内结束。我打开自己做的 Slides 开始讲，成功在两分钟之内讲完了。说好的 5-10 min 呢？我很快讲完之后，她直接说：OK，have a good day, you can leave the zoom room. 面完就感觉她挺急的，这个 rank 7 的项目估计是寄了，不过也不咋心疼&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2021-12-10&lt;/em&gt;   Portal 出 offer 了 是 Alberta 无面试录了。下午一点收到了 offer 邮件，说匹配成功，Congratulations&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2021-12-11&lt;/em&gt;   可以在 Portal 上 accept 了，接受之后会有一封感谢信发到邮箱&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2022-02-17&lt;/em&gt;   收到下一步的邮件，填写一些 agreement 和个人信息。关于疫情是否 on site，Mitacs 觉得是大概率 on site 的。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2022-03-01&lt;/em&gt;   在 IRCC Portal 申请了签证&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2022-03-04&lt;/em&gt;   去上海签证中心录生物信息，进入漫长的 Visa 审核流程&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2022-03-22&lt;/em&gt;   CSC 系统更新，发贺信，进行签约和一些银行卡开卡手续&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2022-04-15&lt;/em&gt;   最近上海爆发疫情，CSC 银行卡的寄送受到了影响，我们也封校了，签证还在审理中&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;application-detail&#34;&gt;Application Detail&lt;/h2&gt;
&lt;p&gt;这里说一说我认为的对成功申请和匹配的一些建议和细节。首先，匹配分两个阶段。第一阶段初审过后，会分为三类：CUC、Waitlist、Rej。CUC 代表经过初审，可以去和教授进行面试和 rerank 来匹配。匹配结束后，CUC 有可能没匹配上，进入 Waitlist。然后是第二轮匹配，这个时候第一轮的 Waitlist 有概率会被录取，但是可能性比较小。&lt;/p&gt;
&lt;h3 id=&#34;初审-rightarrow-cuc&#34;&gt;初审 $\rightarrow$ CUC&lt;/h3&gt;
&lt;p&gt;想要通过初审，那么 GPA 和 Resume 是最重要的。也可以看到，我没有任何竞赛和语言成绩，依旧通过了初审。所以 transcript 和 Resume 至关重要。GPA 这个也不好准备，大家都知道，基本上低于 85 分就没啥希望了。主要努力方向还是 Resume。Mitacs 官网会提供 Resume Template，但是我不建议用。个人写自己的 Resume 是要去突出自己的优势，稍微掩盖自己的劣势的。同时，Mitacs 给的模板比较粗糙，不好看。所以我建议用 LaTeX 进行写作，Overleaf 上也可以找到一些好看的模板，不会装 LaTeX 的可以用 Overleaf 在线编译下载 PDF（最好还是学一下 LaTeX，这个不会就去做 Research 也挺离谱的）。&lt;/p&gt;
&lt;h3 id=&#34;interview-rightarrow-offer&#34;&gt;Interview $\rightarrow$ Offer&lt;/h3&gt;
&lt;p&gt;这个阶段基本是最难熬的，可能会很焦虑。尤其是当你发现，自己一封邮件没收到，群里小伙伴有的都面完五六个老师的时候，心里会很不是滋味。这里我想说的是，无面试录取的可能性很大，尤其是 University of Alberta，好多都是没面试直接拿 Offer 的。如果你有幸被面试，那么一定要提前做好展示的 Slides，然后配置好网络环境（科学上网），最后面试完给老师发一封感谢信。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;这个项目总体来说，由于 Mitacs 的谜一般的匹配机制，所以也是比较看运气的。所以，如果没录不用觉得自己咋样，自己套往往是更好的。祝大家都能拿到 offer。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Transformer</title>
      <link>https://preminstrel.github.io/blog/post/2022/01/26/transformer/</link>
      <pubDate>Wed, 26 Jan 2022 17:47:40 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/01/26/transformer/</guid>
      
      <description>&lt;p&gt;《Attention Is All You Need》是 Google 团队在 2017 年提出的一篇论文。该论文以“attention”为核心，提出了 Transformer 模型。Transformer 基于 Encoder-Decoder，摒弃了 CNNs，完全由 Attention mechanism 实现。&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;p&gt;传统 seq2seq 最大的问题在于将 Encoder 端的所有信息&lt;strong&gt;压缩到一个固定长度的向量&lt;/strong&gt;中，并将其作为 Decoder 端首个隐藏状态的输入，来预测 Decoder 端第一个单词(token)的隐藏状态。在输入序列比较长的时候，这样做显然会损失 Encoder 端的很多信息，而且这样一股脑的把该固定向量送入 Decoder 端，Decoder 端不能够关注到其想要关注的信息。并且模型计算不可并行，计算隐层状态 $h_t$ 依赖于 $h_{t-1}$ 以及状态 $t$ 时刻的输入，因此需要耗费大量时间。&lt;/p&gt;
&lt;p&gt;Transformer 完全依赖于 Attention Mechanism，解决了输入输出的长期依赖问题，并且拥有并行计算的能力，大大减少了计算资源的消耗。Self-Attention模块，让源序列和目标序列首先“自关联”起来，这样的话，源序列和目标序列自身的 embedding 表示所蕴含的信息更加丰富，而且后续的 FFN 层也增强了模型的表达能力。Muti-Head Attention 模块使得 Encoder 端拥有并行计算的能力。&lt;/p&gt;
&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;h3 id=&#34;structure&#34;&gt;Structure&lt;/h3&gt;
&lt;p&gt;Transformer 采用 Encoder-Decoder 架构，如下图所示。Encoder 层和 Decoder 层分别由 6 个相同的 Encoder 和decoder堆叠而成，模型架构更加复杂。其中，Encoder 层引入了 &lt;em&gt;&lt;strong&gt;Multi-Head&lt;/strong&gt;&lt;/em&gt; 机制，可以并行计算，Decoder 层仍旧需要串行计算。&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/Ml7Wiqra8TdAZv2&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/Ml7Wiqra8TdAZv2.png&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;Encoder 层和 Decoder 层内部结构如下图所示。&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/rCmxoUspEFbhfSd&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/rCmxoUspEFbhfSd.png&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Encoder 具有两层结构，&lt;strong&gt;Self-Attention 和前馈神经网络&lt;/strong&gt;。Self-Attention 计算句子中的每个词都和其他词的关联，从而帮助模型更好地理解上下文语义，引入 Muti-Head Attention 后，每个头关注句子的不同位置，增强了Attention 机制关注句子内部单词之间作用的表达能力。前馈神经网络为 Encoder 引入非线性变换，增强了模型的拟合能力。&lt;/li&gt;
&lt;li&gt;Decoder 接受 output 输入的&lt;strong&gt;同时接受 Encoder 的输入&lt;/strong&gt;，帮助当前节点获取到需要重点关注的内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multi-head-attention&#34;&gt;Multi-Head Attention&lt;/h3&gt;
&lt;p&gt;Multi-Head Attention 计算过程如下图，在讲解Multi-Head Attention 之前，我们需要了解Self-Attention。&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/vuW2BzLpKig3lrV&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/vuW2BzLpKig3lrV.png&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Query 与 Key 作用得到 Attention 的权值，之后这个权值作用在 Value 上得到 Attention值。&lt;/strong&gt; 这种通过 Query 和 Key 的相似性程度来确定 value 的权重分布的方法被称为 &lt;em&gt;&lt;strong&gt;scaled dot-product attention&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;$$\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^T}{\sqrt{D_k}})V$$&lt;/p&gt;
&lt;p&gt;这里给出我在知乎上看到的一个很不错的帖子里面的图片解释 scaled dot-product attention：&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/1VaBDNAm4S2Yex9&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/1VaBDNAm4S2Yex9.jpg&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;但是，在 Transformer 模型中，作者使用了 Muti-Head 机制代替了 single self-attention。&lt;/p&gt;
&lt;p&gt;$$
\text{MultiHead}(Q,K,V) =\text{Concat}\left(\text {head}_1, \ldots, \text{head}_h \right) W^{O}
$$&lt;/p&gt;
&lt;p&gt;$$
\text{where head}_{\mathrm{i}} =\operatorname{Attention}\left(QW_i^Q, KW_i^K, VW_i^V \right)
$$&lt;/p&gt;
&lt;p&gt;Where the projections are parameter matrices $W_{i}^{Q} \in \mathbb{R}^{d_{model} \times d_{k}}, W_{i}^{K} \in \mathbb{R}^{d_{model} \times d_{k}}, W_{i}^{V} \in \mathbb{R}^{d_{model} \times d_{v}}$ and $W^{O} \in \mathbb{R}^{h d_{v} \times d_{model}}$.&lt;/p&gt;
&lt;p&gt;论文中采用 8 个头，$h=8,d_{k}=d_{v}=d_{model} / h=64$。通过权重矩阵 $W_{i}^{Q},W_{i}^{K},W_{i}^{V}$ 将 $Q,K,V$ 分割，每个头分别计算 single self-attention，因为权重矩阵 $W_{i}^{Q},W_{i}^{K},W_{i}^{V}$ 不相同，$QW_i^Q,KW_i^K,VW_i^V$ 的结果各不相同，因此我们说每个头的关注点各有侧重。最后，将每个头计算出的 single self-attention 进行 concat，通过总的权重矩阵 $W^O$ 决定对每个头的关注程度，从而能够做到在不同语境下对相同句子进行不同理解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Attention 是将 Query 和 Key 映射到同一高维空间中去计算相似度，而对应的 Multi-head Attention 把 Query 和 Key 映射到高维空间 $\alpha$ 的不同子空间 $(\alpha_1,\alpha_2,\dots, \alpha_h)$ 中去计算相似度。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;position-wise-feed-forward&#34;&gt;Position-wise Feed Forward&lt;/h3&gt;
&lt;p&gt;$$\text{FFN}(x)=\max(0,xW_1+b_1)W_2+b_2$$&lt;/p&gt;
&lt;p&gt;每一层经过 Attention 之后，还会有一个 FFN，这个 FFN 的作用就是&lt;strong&gt;空间变换&lt;/strong&gt;。FFN 包含了 2 层 Linear Transformation 层，中间的激活函数是 ReLU。&lt;/p&gt;
&lt;p&gt;Attention 层的 output 最后会和 $W^O$ 相乘，为什么这里又要增加一个 2 层的 FFN 网络？其实，FFN 的加入&lt;strong&gt;引入了非线性(ReLu激活函数)，变换了 Attention Output 的空间, 从而增加了模型的表现能力&lt;/strong&gt;。把 FFN 去掉模型也是可以用的，但是效果差了很多。&lt;/p&gt;
&lt;h3 id=&#34;layer-normalization&#34;&gt;Layer Normalization&lt;/h3&gt;
&lt;p&gt;在每个 block 中，最后出现的是 Layer Normalization，其作用是规范优化空间，加速收敛。&lt;/p&gt;
&lt;p&gt;$$\text{LN}(x_i)=\alpha\frac{x_i-\mu_i}{\sqrt{\sigma^2+\xi}}+\beta$$&lt;/p&gt;
&lt;p&gt;当我们使用梯度下降算法做优化时，我们可能会对输入数据进行归一化，但是经过网络层作用后，我们的数据已经不是归一化的了。随着网络层数的增加，数据分布不断发生变化，偏差越来越大，导致我们不得不使用&lt;strong&gt;更小的学习率&lt;/strong&gt;来稳定梯度。Layer Normalization 的作用就是&lt;strong&gt;保证数据特征分布的稳定性&lt;/strong&gt;，将数据标准化到 ReLU 激活函数的作用区域，可以使得激活函数更好的发挥作用&lt;/p&gt;
&lt;h3 id=&#34;positional-encoding&#34;&gt;Positional Encoding&lt;/h3&gt;
&lt;p&gt;位置信息编码位于 Encoder 和 Decoder 的 Embedding 之后，每个 block 之前。它非常重要，没有这部分模型就无法运行。Positional Encoding 是 Transformer 的特有机制，弥补了 Attention 机制无法捕捉 sequence 中 token 位置信息的缺点。&lt;/p&gt;
&lt;p&gt;$$
PE_{(pos, 2i)}=\sin\left(pos/10000^{2i/d_{\text{model}}}\right)
$$&lt;/p&gt;
&lt;p&gt;$$
PE_{(pos,2i+1)}=\cos\left(pos/10000^{2i/d_{\text{model}}}\right)
$$&lt;/p&gt;
&lt;p&gt;Positional Embedding 的成分直接叠加于 Embedding 之上，使得每个 token 的&lt;strong&gt;位置信息&lt;/strong&gt;和它的&lt;strong&gt;语义信息&lt;/strong&gt;(embedding)充分融合，并被传递到后续所有经过复杂变换的序列表达中去。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Transformer 中，模型输入 Encoder 的每个 token 向量由两部分加和而成：Position Encoding + Input Embedding。Transformer 的特性使得输入 Encoder 的向量之间完全平等（不存在 RNN 的 recurrent 结构），token 的实际位置于位置信息编码唯一绑定。Positional Encoding 的引入使得模型能够充分利用 token 在 sequence 中的位置信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;论文中使用的 Positional Encoding(PE) 是正余弦函数，位置(pos)越小，波长越长，每一个位置对应的 PE 都是唯一的。同时作者也提到，之所以选用正余弦函数作为 PE，是因为这可以使得模型学习到 token 之间的相对位置关系：因为对于任意的偏移量 $k$，$PE_{pos+k}$ 可以由 $PE_{pos}$ 的线性表示，也就是 $PE_{pos}$ 乘上某个线性变换矩阵就得到了 $PE_{pos+k}$。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
P E_{(p o s+k, 2 i)}=\sin \left((p o s+k) / 10000^{2 i / d_{\text {model }}}\right)
$$$$
P E_{(p o s+k, 2 i+1)}=\cos \left((p o s+k) / 10000^{2 i / d_{\text {model }}}\right)
$$&lt;/p&gt;
&lt;h3 id=&#34;mask&#34;&gt;Mask&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Mask&lt;/strong&gt;&lt;/em&gt; 表示掩码，它&lt;strong&gt;对某些值进行掩盖，使其在参数更新时不产生效果&lt;/strong&gt;。Transformer 模型里面涉及两种 Mask，分别是 Padding Mask 和 Sequence Mask。其中，Padding Mask 在所有的 scaled dot-product attention 里面都需要用到，而 Sequence Mask 只有在 Decoder 的 Self-Attention 里面用到。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Padding Mask&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;什么是 Padding mask 呢？因为每个批次输入序列长度是不一样的也就是说，我们要对输入序列进行对齐。具体来说，就是给在较短的序列后面填充 0。但是如果输入的序列太长，则是截取左边的内容，把多余的直接舍弃。因为这些填充的位置，其实是没什么意义的，所以我们的 Attention 机制不应该把注意力放在这些位置上，所以我们需要进行一些处理。&lt;/p&gt;
&lt;p&gt;具体的做法是，把这些位置的值加上一个非常大的负数(负无穷)，这样的话，经过 softmax，这些位置的概率就会接近0！&lt;/p&gt;
&lt;p&gt;而我们的 Padding mask 实际上是一个张量，每个值都是一个Boolean，值为 False 的地方就是我们要进行处理的地方。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Sequence mask&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Sequence Mask 是为了使得 Decoder 不能看见未来的信息。也就是对于一个序列，在 time_step 为 t 的时刻，我们的解码输出应该只能依赖于 t 时刻之前的输出，而不能依赖 t 之后的输出。因此我们需要想一个办法，把 t 之后的信息给隐藏起来。&lt;/p&gt;
&lt;p&gt;具体办法是：&lt;strong&gt;产生一个上三角矩阵，上三角的值全为 0。把这个矩阵作用在每一个序列上，就可以达到我们的目的。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于 Decoder 的 Self-Attention，里面使用到的 scaled dot-product attention，同时需要 Padding Mask 和 Sequence mask 作为 attn_mask，具体实现就是两个 Mask 相加作为 attn_mask。其他情况，attn_mask 一律等于 Padding mask。&lt;/p&gt;
&lt;h3 id=&#34;linear--softmax&#34;&gt;Linear &amp;amp; Softmax&lt;/h3&gt;
&lt;p&gt;Decoder 最后是一个线性变换和 Softmax 层。解码组件最后会输出一个实数向量。我们如何把浮点数变成一个单词？这便是线性变换层要做的工作，它之后就是 Softmax 层。&lt;/p&gt;
&lt;p&gt;线性变换层是一个简单的全连接神经网络，它可以&lt;strong&gt;把解码组件产生的向量投射到一个比它大得多的、被称作对数几率（logits）的向量里&lt;/strong&gt;。不妨假设我们的模型从训练集中学习一万个不同的英语单词（我们模型的“输出词表”）。因此对数几率向量为一万个单元格长度的向量——每个单元格对应某一个单词的分数（&lt;strong&gt;相当于做 vocaburary_size 大小的分类&lt;/strong&gt;）。接下来的 Softmax 层便会把那些分数变成概率（都为正数、上限 1.0）。&lt;strong&gt;概率最高的单元格被选中，并且它对应的单词被作为这个时间步的输出。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;整体运行效果图如下：&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/7wBRdlvJnzeVUL9&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/7wBRdlvJnzeVUL9.gif&#34; &gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/311156298&#34;&gt;Transformer - Attention is all you need&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Self-Attention</title>
      <link>https://preminstrel.github.io/blog/post/2022/01/26/self-attention/</link>
      <pubDate>Wed, 26 Jan 2022 16:36:51 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/01/26/self-attention/</guid>
      
      <description>&lt;blockquote&gt;
&lt;p&gt;Attention is all you need.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最近刚接触到 Transformer，感觉其模型比 CNNs 要复杂了不少，看了一些论文也仅仅是草草看过，不理解其原理，在网上读了一些 blog，本次来进行一次总结。首先便是 Self-Attention 的公式&lt;/p&gt;
&lt;p&gt;$$\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^T}{\sqrt{D_k}})V$$&lt;/p&gt;
&lt;h2 id=&#34;terminology&#34;&gt;Terminology&lt;/h2&gt;
&lt;p&gt;公式种出现的 $Q,K,V$ 分别是 Query、Key、Value的缩写，我们的表达式如下：&lt;/p&gt;
&lt;p&gt;$$X W^Q=Q$$
$$XW^K=K$$
$$XW^V=V$$&lt;/p&gt;
&lt;p&gt;文章中所谓的 $Q,K,V$ 矩阵来源于 $X$ 与矩阵的乘积，本质上是 $X$ 的一系列的线性变换。做线性变换是为了提升模型的拟合能力，矩阵 $W$ 都是可以训练的，起到一个缓冲的效果。&lt;/p&gt;
&lt;p&gt;我们假设 $Q,K$ 种元素的均值为 0，方差为 1，$A^T=Q^TK$ 的均值为 0，方程为 $D$。当 $D$ 变得很大时，$A$ 中的元素的方差也会变得很大，如果 $A$ 中的元素方差很大，那么 $A$ 的分布会趋于陡峭(分布的方差大，分布集中在绝对值大的区域)。我们可以将分布“陡峭”程度与 $D$ 解耦，从而使得训练过程中梯度值保持稳定。&lt;/p&gt;
&lt;p&gt;$$A\leftarrow \dfrac{A}{\sqrt{D_k}}$$&lt;/p&gt;
&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;公式中的 $QK^T$ 表示的是 $Q,K$ 的内积，也可以说是一方在另一方的&lt;strong&gt;投影&lt;/strong&gt;，其大小也可以表示其&lt;strong&gt;相关性&lt;/strong&gt;。Softmax 是为了将一系列的值&lt;strong&gt;归一化&lt;/strong&gt;而存在的。&lt;/p&gt;
&lt;p&gt;$$\text{softmax}(z_k)=\frac{e^{z_k}}{\sum_{i=1}^Ie^{z_i}}$$&lt;/p&gt;
&lt;p&gt;而随后与 $V$ 的乘积，代表的是&lt;strong&gt;向量经过注意力机制加权求和之后的结果&lt;/strong&gt;。也就是说，softmax 管的是一个相关度权值大小，与后面的 $V$ 相乘，得到的是通过相关度权值标准而重新计算得到的量。&lt;/p&gt;
&lt;p&gt;对 Self-Attention 来说，它跟每一个输入的向量都做 Attention，所以没有考虑到输入的顺序。更通俗来讲，大家可以发现我们前文的计算每一个词向量都与其他词向量计算内积，得到的结果丢失了我们原来文本的顺序信息。对比来说，LSTM 是对于文本顺序信息的解释是输出词向量的先后顺序，而我们上文的计算对 sequence 的顺序这一部分则完全没有提及，你打乱词向量的顺序，得到的结果仍然是相同的，此处便可以引出 Transformer 的位置编码部分。&lt;strong&gt;Query 与 Key 作用得到 Attention 的权值，之后这个权值作用在 Value 上得到 Attention值。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Attention 机制的实现&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;math&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; sqrt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;torch.nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;Self_Attention&lt;/span&gt;(nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# input : batch_size * seq_len * input_dim&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# q : batch_size * input_dim * dim_k&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# k : batch_size * input_dim * dim_k&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# v : batch_size * input_dim * dim_v&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; __init__(self,input_dim,dim_k,dim_v):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f&#34;&gt;super&lt;/span&gt;(Self_Attention,self)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;__init__()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;q &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(input_dim,dim_k)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;k &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(input_dim,dim_k)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;v &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Linear(input_dim,dim_v)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;_norm_fact &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;/&lt;/span&gt; sqrt(dim_k)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;forward&lt;/span&gt;(self,x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        Q &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;q(x) &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Q: batch_size * seq_len * dim_k&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        K &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;k(x) &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# K: batch_size * seq_len * dim_k&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        V &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;v(x) &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# V: batch_size * seq_len * dim_v&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        atten &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Softmax(dim&lt;span style=&#34;color:#666&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;)(torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;bmm(Q,K&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;permute(&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;))) &lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt; self&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;_norm_fact &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Q * K.T() # batch_size * seq_len * seq_len&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        output &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;bmm(atten,V) &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;# Q * K.T() * V # batch_size * seq_len * dim_v&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; output
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/410776234&#34;&gt;超详细图解Self-Attention&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Faster R-CNN</title>
      <link>https://preminstrel.github.io/blog/post/2022/01/14/faster-r-cnn/</link>
      <pubDate>Fri, 14 Jan 2022 13:32:15 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/01/14/faster-r-cnn/</guid>
      
      <description>&lt;p&gt;Faster R-CNN 可以简单看成是&lt;strong&gt;区域生成网络&lt;/strong&gt; + Fast R-CNN 的模型，用区域生成网络(&lt;em&gt;&lt;strong&gt;Region Proposal Network, RPN&lt;/strong&gt;&lt;/em&gt;)来替代 Fast R-CNN 中的选择性搜索方法，结构如下：&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/iEOGhpnroZqN19w&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/iEOGhpnroZqN19w.png&#34; width=&#34;400px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h2 id=&#34;pipeline&#34;&gt;Pipeline&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;首先向 CNN 网络(VGG-16)输入图片，Faster R-CNN 使用一组基础的 conv + relu + pooling 层提取 feature map。&lt;strong&gt;该 feature map 被共享用于后续 RPN 层和 fc 层。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RPN 网络用于生成 region proposals，Faster R-CNN 中称之为 &lt;em&gt;&lt;strong&gt;anchors&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;通过 softmax 判断 anchors 属于 foreground 或者 background&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;再利用 bounding box regression 修正 anchors 获得精确的 proposals，输出其 Top-N(默认 300)的区域给 Rol pooling&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生成 anchors $\rightarrow$ softmax 分类器提取 fg anchors $\rightarrow$ bbox reg 回归 fg anchors $\rightarrow$ Proposal Layer 生成proposals&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;后续就是 Fast R-CNN 操作&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rpn&#34;&gt;RPN&lt;/h3&gt;
&lt;p&gt;RPN 网络的主要作用是得到比较准确的候选区域，整个过程分为两步&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用 $n\times n$ (默认 $3\times 3$) 的大小窗口去扫描特征图，每个滑窗位置映射倒一个低维的向量(默认 256 维)，并为每个滑窗位置考虑 $k$ 种(在论文设计中 $k=9$)&lt;strong&gt;可能的参考窗口(论文中称为 anchors)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/6ropzGCEjRAw1Fc&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/6ropzGCEjRAw1Fc.png&#34; width=&#34;600px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3 id=&#34;anchors&#34;&gt;Anchors&lt;/h3&gt;
&lt;p&gt;$3\times 3$ 卷积核的中心点对应原图上的位置，将该点作为 anchor 的中心点，在原图中框出多尺度、多种长宽比的 anchors，三种尺度 $\{128,256,512\}$，三种长宽比 $\{1:1,1:2,2:1\}$，每个特征图中的像素点有 9 个框。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;窗口输出 $[N，256]\rightarrow$ 分类：判断是否是背景&lt;/li&gt;
&lt;li&gt;回归位置：N 个候选框与自己对应目标值 GT 做回归，修正位置。得到更好的候选区域提供给 ROl pooling 使用&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;training&#34;&gt;Training&lt;/h2&gt;
&lt;p&gt;Faster R-CNN 的训练分为两部分，即两个网络的训练。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RPN 训练&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;从众多的候选区域中提取出 score 较高的，并且经过 regression 调整的候选区域&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fast R-CNN部分的训练&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Fast R-CNN &lt;em&gt;&lt;strong&gt;classification(over classes, softmax)&lt;/strong&gt;&lt;/em&gt;︰所有类别分类 N+1，得到候选区域每个类别概率&lt;/li&gt;
&lt;li&gt;Fast R-CNN &lt;em&gt;&lt;strong&gt;regression(bbox regression, MAE)&lt;/strong&gt;&lt;/em&gt;：得到更好的位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;样本准备：正负 anchors 样本比例为 $1:3$&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/VJW9yaSCjHXeu1E&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/VJW9yaSCjHXeu1E.png&#34; width=&#34;600px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;metrics&lt;/th&gt;
&lt;th&gt;R-CNN&lt;/th&gt;
&lt;th&gt;Fast R-CNN&lt;/th&gt;
&lt;th&gt;Faster R-CNN&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Test time/image&lt;/td&gt;
&lt;td&gt;50.0s&lt;/td&gt;
&lt;td&gt;2.0s&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.2s&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mAP(VOC2007)&lt;/td&gt;
&lt;td&gt;66.0&lt;/td&gt;
&lt;td&gt;66.9&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;66.9&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;RPN&lt;/li&gt;
&lt;li&gt;End-to-End&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;训练参数太大&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;改进：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RPN(Region Proposal Networks) 改进对于小目标选择利用多尺度特征信息进行 RPN&lt;/li&gt;
&lt;li&gt;速度提升，如 YOLO 系列算法，删去RPN，直接对 proposal 进行分类回归，极大的提升了网络的速度&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1506.01497&#34;&gt;Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Fast R-CNN</title>
      <link>https://preminstrel.github.io/blog/post/2022/01/13/fast-r-cnn/</link>
      <pubDate>Thu, 13 Jan 2022 22:31:08 +0800</pubDate>
      <author>preminstrel@gmail.com (Hanshi Sun)</author>
      <guid>https://preminstrel.github.io/blog/post/2022/01/13/fast-r-cnn/</guid>
      
      <description>&lt;p&gt;SPP-net 的性能已经得到很大的改善，但是由于网络之间不统一训练，造成很大的麻烦，所以 &lt;em&gt;&lt;strong&gt;Fast R-CNN&lt;/strong&gt;&lt;/em&gt; 就是为了解决这样的问题。其改进的之处为：提出一个 &lt;em&gt;&lt;strong&gt;Rol pooling&lt;/strong&gt;&lt;/em&gt;，然后整合整个模型，把 CNN、Rol pooling、分类器、bbox 回归几个模块&lt;strong&gt;整个一起训练&lt;/strong&gt;。&lt;/p&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/AWih7QImN5c9zYC&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/AWih7QImN5c9zYC.png&#34; widt=&#34;600px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h2 id=&#34;pipeline&#34;&gt;Pipeline&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;首先将整个图片输入到一个基础卷积网络，得到整张图的 feature map&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将选择性搜索算法的结果 region proposal (Rol）映射到 feature map 中&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rol pooling layer 提取一个固定长度的特征向量，每个特征会输入到一系列全连接层，得到一个 Rol 特征向量 &lt;strong&gt;(此步骤是对每一个候选区域都会进行同样的操作)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其中一个是传统 &lt;em&gt;&lt;strong&gt;softmax&lt;/strong&gt;&lt;/em&gt; 层进行分类，输出类别有 K 个类别加上”背景”类&lt;/li&gt;
&lt;li&gt;另一个是 &lt;em&gt;&lt;strong&gt;bounding box regressor&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rol-pooling&#34;&gt;Rol Pooling&lt;/h3&gt;
&lt;p&gt;首先 Rol pooling 只是一个简单版本的 SSP，目的是为了减少计算时间并得到固定长度的向量。Rol 池化层使用最大池化将任何有效的 Rol 区域内的特征转换为具有 $H\times W$ 的固定空间范围的小 feature map，其中 $H,W$ 是超参数，它们独立于任何特定的 Rol。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;single scale&lt;/strong&gt;&lt;/em&gt;：直接将 image 定为某种 scale，直接输入网络来训练即可。（Fast R-CNN）&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;multi scale&lt;/strong&gt;&lt;/em&gt;：生成一个金字塔，即 SPP-net&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;后者比前者更加准确，没有突出很多，但是第一种节省了很多的时间，所以 Fast R-CNN 要比 SPP-net 快很多。&lt;/p&gt;
&lt;h3 id=&#34;end-to-end-model&#34;&gt;End-to-End Model&lt;/h3&gt;
&lt;p&gt;输出端可以直接进行完整的反向传播，整体优化目标函数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;特征提取 CNN 和训练 SVM 分类器的训练在时间上是先后顺序，二者训练方式独立，因此 SVMs 的训练 Loss 无法更新之前的卷积层参数，于是去掉 SVM，便可以形成 End-to-End 模型。&lt;/li&gt;
&lt;li&gt;使用了 softmax&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=center&gt;
&lt;a href=&#34;https://sm.ms/image/SOFVNrZXLalG7fm&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://s2.loli.net/2022/04/14/SOFVNrZXLalG7fm.png&#34; width=&#34;600px&#34;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3 id=&#34;multi-task-loss&#34;&gt;Multi-task Loss&lt;/h3&gt;
&lt;p&gt;两个 loss，分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于分类 loss，是一个 N+1 路的 softmax 输出，其中 N 是类别个数，1 是背景，使用&lt;strong&gt;交叉熵损失&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;对于回归 loss，是一个 4N 路输出的 regressor，也就是说对于每个类别都会训练一个单独的 regressor 的意思，&lt;strong&gt;使用平均绝对误差(MAE)损失，即 L1 损失&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;fine-tuning 训练中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调整 CNN + Rol pooling + softmax&lt;/li&gt;
&lt;li&gt;调整 bbox regressor 回归当中的参数&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;metrics&lt;/th&gt;
&lt;th&gt;R-CNN&lt;/th&gt;
&lt;th&gt;SPP-net&lt;/th&gt;
&lt;th&gt;Fast R-CNN&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;training time(h)&lt;/td&gt;
&lt;td&gt;84&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;9.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;test time/picture(s)&lt;/td&gt;
&lt;td&gt;47.0&lt;/td&gt;
&lt;td&gt;2.3&lt;/td&gt;
&lt;td&gt;0.32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mAP&lt;/td&gt;
&lt;td&gt;66.0&lt;/td&gt;
&lt;td&gt;63.1&lt;/td&gt;
&lt;td&gt;66.9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;drawbacks&#34;&gt;Drawbacks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;使用 Selective Search 提取 Region Proposals，没有实现真正意义山东个端对端，操作十分耗时间。&lt;/li&gt;
&lt;li&gt;一个更高效的方法来求出候选框—— &lt;em&gt;&lt;strong&gt;Faster R-CNN&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1504.08083&#34;&gt;Fast R-CNN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
  </channel>
</rss>
