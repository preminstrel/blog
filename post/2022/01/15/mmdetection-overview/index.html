<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">

  
  <meta name="author" content="Hanshi Sun">

  
  
  <meta name="description" content="MMDetection 是一个基于 PyTorch 的目标检测开源工具箱。它是 OpenMMLab 项目的一部分。目前已经复现了大部分主流和前沿模型，例如 Faster R-CNN 系列、Mask R-CNN 系列、YOLO 系列和比较">
  

  
  <link rel="icon" href="https://preminstrel.github.io/blog/favicon.ico">

  
  
  <meta name="keywords" content=" hugo  latex  theme ">
  

  
  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css"
  integrity="sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
  integrity="sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js"
  integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '\\[', right: '\\]', display: true },
        { left: '$', right: '$', display: false },
        { left: '\\(', right: '\\)', display: false }
      ],
      ignoredTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code', 'option'],
      throwOnError: false
    });
  });
</script>


  

  
  <meta property="og:title" content="MMDetection Overview" />
<meta property="og:description" content="MMDetection 是一个基于 PyTorch 的目标检测开源工具箱。它是 OpenMMLab 项目的一部分。目前已经复现了大部分主流和前沿模型，例如 Faster R-CNN 系列、Mask R-CNN 系列、YOLO 系列和比较" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://preminstrel.github.io/blog/post/2022/01/15/mmdetection-overview/" />
<meta property="article:published_time" content="2022-01-15T12:12:07+08:00" />
<meta property="article:modified_time" content="2022-01-15T00:00:00+00:00" />


  
  <link rel="canonical" href="https://preminstrel.github.io/blog/post/2022/01/15/mmdetection-overview/">

  
  
  <meta itemprop="name" content="MMDetection Overview">
<meta itemprop="description" content="MMDetection 是一个基于 PyTorch 的目标检测开源工具箱。它是 OpenMMLab 项目的一部分。目前已经复现了大部分主流和前沿模型，例如 Faster R-CNN 系列、Mask R-CNN 系列、YOLO 系列和比较">
<meta itemprop="datePublished" content="2022-01-15T12:12:07&#43;08:00" />
<meta itemprop="dateModified" content="2022-01-15T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="3791">



<meta itemprop="keywords" content="Object Detection,Deep Learning,MMDetection," />

  
  <link media="screen" rel="stylesheet" href='https://preminstrel.github.io/blog/css/common.css'>
  <link media="screen" rel="stylesheet" href='https://preminstrel.github.io/blog/css/content.css'>

  
  
  <title>MMDetection Overview - Blog de Preminstrel</title>
  

  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="MMDetection Overview"/>
<meta name="twitter:description" content="MMDetection 是一个基于 PyTorch 的目标检测开源工具箱。它是 OpenMMLab 项目的一部分。目前已经复现了大部分主流和前沿模型，例如 Faster R-CNN 系列、Mask R-CNN 系列、YOLO 系列和比较"/>


  
<link rel="stylesheet" href='https://preminstrel.github.io/blog/css/single.css'>

</head>

<body>
  <div id="wrapper">
    <header id="header">
  <h1>
    <a href="https://preminstrel.github.io/blog/">Blog de Preminstrel</a>
  </h1>

  <nav>
    
    <span class="nav-bar-item">
      <a class="link" href="/blog/">Post</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/blog/post/">Archives</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/blog/about/">About</a>
    </span>
    
  </nav>
</header>

    
<main id="main" class="post">
  
  
  <h1>MMDetection Overview</h1>
  
  <div>
    <b>Keywords: </b>
    
    <a class="link" href='https://preminstrel.github.io/blog/tags/object-detection'>#Object Detection</a>
    
    <a class="link" href='https://preminstrel.github.io/blog/tags/deep-learning'>#Deep Learning</a>
    
    <a class="link" href='https://preminstrel.github.io/blog/tags/mmdetection'>#MMDetection</a>
    
  </div>
  
  
  <article class="content">
    
    <p><a href="https://github.com/open-mmlab/mmdetection">MMDetection</a> 是一个基于 PyTorch 的目标检测开源工具箱。它是 <a href="https://openmmlab.com/">OpenMMLab</a> 项目的一部分。目前已经复现了大部分主流和前沿模型，例如 Faster R-CNN 系列、Mask R-CNN 系列、YOLO 系列和比较新的 DETR 等等，模型库非常丰富，在学术研究和工业落地中应用非常广泛。</p>
<div align=center>
<img src="/img/20220115131101.png" width="800px"/>
</div>
<h1 id="classifications">Classifications</h1>
<p>按照目前目标检测的发展，可以大概归纳为如下所示：</p>
<div class="mermaid">
graph LR
	id1(Object Detection)---id2(satge);
	id1---id3(anchor);
	id1---id4(transformer)-.-id9(DETR, Deformable DETR, ...)
	id2---id5(two-stage)-.-id11(Faster R-CNN, Cascade R-CNN, Libra R-CNN, ...)
	id5(two-stage)-.-id12(TridentNet,...)
	id2---id6(one-stage)-.-id13(RetinaNet, YOLO, FCOS, PrePoints, ...)
	id3---id7(anchor-based)-.-id14(Faster R-CNN, YOLO, ...)
	id3---id8(anchor-free)-.-id15(FCOS, ...)
</div>
<p>注意上面仅仅写了几个典型算法而已，简单来说目标检测算法可以按照 3 个维度划分：</p>
<ul>
<li><strong>按照 stage 个数划分</strong>，常规是 one-stage 和 two-stage，但是实际上界限不是特别清晰，例如带 refine 阶段的算法 RepPoints，实际上可以认为是1.5 stage 算法，而 Cascade R-CNN 可以认为是多阶段算法，为了简单，上面图示没有划分如此细致</li>
<li><strong>按照是否需要预定义 anchor 划分</strong>，常规是 anchor-based 和 anchor-free，当然也有些算法是两者混合的</li>
<li><strong>按照是否采用了 transformer 结构划分</strong>，目前基于 transformer 结构的目标检测算法发展迅速，也引起了极大的关注，所以这里特意增加了这个类别的划分</li>
</ul>
<p>不管哪种划分方式，其实都可以分成若干固定模块，然后通过模块堆叠来构建整个检测算法体系。</p>
<h1 id="pipeline">Pipeline</h1>
<p>现在这个框架将检测拆解模块化为 <em><strong>backbone</strong></em>，<em><strong>neck</strong></em>，<em><strong>head</strong></em>，无论是单阶段还是双阶段。线索清晰，体系自成。基于目前代码实现，所有目标检测算法都按照以下流程进行划分：</p>
<div align=center>
<img src="/img/20220115135201.jpg" width="600px"/>
</div>
<h2 id="train">Train</h2>
<p>训练部分一般包括 9 个核心组件，总体流程是：</p>
<ol>
<li>任何一个 batch 的图片先输入到 backbone 中进行特征提取，典型的骨干网络是 <em><strong>ResNet</strong></em></li>
<li>输出的单尺度或者多尺度特征图输入到 neck 模块中进行特征融合或者增强，典型的 neck 是 <em><strong>FPN</strong></em></li>
<li>上述多尺度特征最终输入到 head 部分，一般都会包括分类和回归分支输出</li>
<li>在整个网络构建阶段都可以引入一些即插即用增强算子来增加提取提取能力，典型的例如 SPP、DCN 等等</li>
<li>目标检测 head 输出一般是特征图，对于分类任务存在严重的正负样本不平衡，可以通过正负样本属性分配和采样控制</li>
<li>为了方便收敛和平衡多分支，一般都会对 gt bbox 进行编码</li>
<li>最后一步是计算分类和回归 loss，进行训练</li>
<li>在训练过程中也包括非常多的 trick，例如优化器选择等，参数调节也非常关键</li>
</ol>
<p>注意上述 9 个组件不是每个算法都需要的，下面详细分析。</p>
<h3 id="backbone">Backbone</h3>
<div class="mermaid">
graph LR
	id1(ResNet)---id2(ResNext)---id3(Res2Net)---id4(ResNeSt)---id5(DarkNet)---id7(SSD_VGG);
</div>
<p>backbone 作用主要是<strong class=chinese>特征提取</strong>。目前 MMDetection 中已经集成了大部分骨架网络，具体见文件：<code>mmdet/models/backbones</code>，已经实现的骨架有：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">__all__ <span style="color:#666">=</span> [
    <span style="color:#b44">&#39;RegNet&#39;</span>, <span style="color:#b44">&#39;ResNet&#39;</span>, <span style="color:#b44">&#39;ResNetV1d&#39;</span>, <span style="color:#b44">&#39;ResNeXt&#39;</span>, <span style="color:#b44">&#39;SSDVGG&#39;</span>, <span style="color:#b44">&#39;HRNet&#39;</span>, <span style="color:#b44">&#39;Res2Net&#39;</span>,
    <span style="color:#b44">&#39;HourglassNet&#39;</span>, <span style="color:#b44">&#39;DetectoRS_ResNet&#39;</span>, <span style="color:#b44">&#39;DetectoRS_ResNeXt&#39;</span>, <span style="color:#b44">&#39;Darknet&#39;</span>,
    <span style="color:#b44">&#39;ResNeSt&#39;</span>, <span style="color:#b44">&#39;TridentResNet&#39;</span>
]
</code></pre></div><p>最常用的是 ResNet 系列、ResNetV1d 系列和 Res2Net 系列。如果需要对骨架进行扩展，可以继承上述网络，然后通过<strong class=chinese>注册器机制注册使用</strong>。一个典型用法为：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-style:italic"># 骨架的预训练权重路径</span>
pretrained<span style="color:#666">=</span><span style="color:#b44">&#39;torchvision://resnet50&#39;</span>,
backbone<span style="color:#666">=</span><span style="color:#a2f">dict</span>(
    <span style="color:#a2f">type</span><span style="color:#666">=</span><span style="color:#b44">&#39;ResNet&#39;</span>, <span style="color:#080;font-style:italic"># 骨架类名，后面的参数都是该类的初始化参数</span>
    depth<span style="color:#666">=</span><span style="color:#666">50</span>,
    num_stages<span style="color:#666">=</span><span style="color:#666">4</span>,
    out_indices<span style="color:#666">=</span>(<span style="color:#666">0</span>, <span style="color:#666">1</span>, <span style="color:#666">2</span>, <span style="color:#666">3</span>),
    frozen_stages<span style="color:#666">=</span><span style="color:#666">1</span>,
    norm_cfg<span style="color:#666">=</span><span style="color:#a2f">dict</span>(<span style="color:#a2f">type</span><span style="color:#666">=</span><span style="color:#b44">&#39;BN&#39;</span>, requires_grad<span style="color:#666">=</span>True), 
    norm_eval<span style="color:#666">=</span>True,
    style<span style="color:#666">=</span><span style="color:#b44">&#39;pytorch&#39;</span>),
</code></pre></div><p>通过 MMCV 中的注册器机制，<strong>可以通过 dict 形式的配置来实例化任何已经注册的类</strong>，非常方便和灵活。</p>
<h3 id="neck">Neck</h3>
<div class="mermaid">
graph LR
	id1(FPN)---id2(BFP)---id3(RFP)---id4(PAFPN)---id5(NAS_FPN)---id7(HRFPN);
</div>
<p>neck 可以认为是 backbone 和 head 的<strong class=chinese>连接层</strong>，主要负责<strong>对 backbone 的特征进行高效融合和增强，能够对输入的单尺度或者多尺度特征进行融合、增强输出等</strong>。具体见文件：<code>mmdet/models/necks</code>，已经实现的 neck 如下：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">__all__ <span style="color:#666">=</span> [
    <span style="color:#b44">&#39;FPN&#39;</span>, <span style="color:#b44">&#39;BFP&#39;</span>, <span style="color:#b44">&#39;ChannelMapper&#39;</span>, <span style="color:#b44">&#39;HRFPN&#39;</span>, <span style="color:#b44">&#39;NASFPN&#39;</span>, <span style="color:#b44">&#39;FPN_CARAFE&#39;</span>, <span style="color:#b44">&#39;PAFPN&#39;</span>,
    <span style="color:#b44">&#39;NASFCOS_FPN&#39;</span>, <span style="color:#b44">&#39;RFP&#39;</span>, <span style="color:#b44">&#39;YOLOV3Neck&#39;</span>
]
</code></pre></div><p>最常用的应该是 <em><strong>FPN</strong></em>，一个典型用法是：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">neck<span style="color:#666">=</span><span style="color:#a2f">dict</span>(
    <span style="color:#a2f">type</span><span style="color:#666">=</span><span style="color:#b44">&#39;FPN&#39;</span>,
    in_channels<span style="color:#666">=</span>[<span style="color:#666">256</span>, <span style="color:#666">512</span>, <span style="color:#666">1024</span>, <span style="color:#666">2048</span>], <span style="color:#080;font-style:italic"># 骨架多尺度特征图输出通道</span>
    out_channels<span style="color:#666">=</span><span style="color:#666">256</span>, <span style="color:#080;font-style:italic"># 增强后通道输出</span>
    num_outs<span style="color:#666">=</span><span style="color:#666">5</span>), <span style="color:#080;font-style:italic"># 输出num_outs个多尺度特征图</span>
</code></pre></div><h3 id="head">Head</h3>
<div class="mermaid">
graph LR
	id1(FC Mode)---id2(Conv Mode);
</div>
<p>目标检测算法输出一般包括<strong class=chinese>分类和框坐标回归</strong>两个分支，不同算法 head 模块复杂程度不一样，灵活度比较高。在网络构建方面，理解目标检测算法主要是要理解 head 模块。</p>
<p>MMDetection 中 head 模块又划分为 <strong>two-stage 所需的 RoIHead 和 one-stage 所需的 DenseHead</strong>，也就是说所有的 one-stage 算法的 head 模块都在<code>mmdet/models/dense_heads</code>中，而 two-stage 算法还包括额外的<code>mmdet/models/roi_heads</code>。</p>
<p>目前中已经实现的 dense_heads 包括：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">__all__ <span style="color:#666">=</span> [
    <span style="color:#b44">&#39;AnchorFreeHead&#39;</span>, <span style="color:#b44">&#39;AnchorHead&#39;</span>, <span style="color:#b44">&#39;GuidedAnchorHead&#39;</span>, <span style="color:#b44">&#39;FeatureAdaption&#39;</span>,
    <span style="color:#b44">&#39;RPNHead&#39;</span>, <span style="color:#b44">&#39;GARPNHead&#39;</span>, <span style="color:#b44">&#39;RetinaHead&#39;</span>, <span style="color:#b44">&#39;RetinaSepBNHead&#39;</span>, <span style="color:#b44">&#39;GARetinaHead&#39;</span>,
    <span style="color:#b44">&#39;SSDHead&#39;</span>, <span style="color:#b44">&#39;FCOSHead&#39;</span>, <span style="color:#b44">&#39;RepPointsHead&#39;</span>, <span style="color:#b44">&#39;FoveaHead&#39;</span>,
    <span style="color:#b44">&#39;FreeAnchorRetinaHead&#39;</span>, <span style="color:#b44">&#39;ATSSHead&#39;</span>, <span style="color:#b44">&#39;FSAFHead&#39;</span>, <span style="color:#b44">&#39;NASFCOSHead&#39;</span>,
    <span style="color:#b44">&#39;PISARetinaHead&#39;</span>, <span style="color:#b44">&#39;PISASSDHead&#39;</span>, <span style="color:#b44">&#39;GFLHead&#39;</span>, <span style="color:#b44">&#39;CornerHead&#39;</span>, <span style="color:#b44">&#39;YOLACTHead&#39;</span>,
    <span style="color:#b44">&#39;YOLACTSegmHead&#39;</span>, <span style="color:#b44">&#39;YOLACTProtonet&#39;</span>, <span style="color:#b44">&#39;YOLOV3Head&#39;</span>, <span style="color:#b44">&#39;PAAHead&#39;</span>,
    <span style="color:#b44">&#39;SABLRetinaHead&#39;</span>, <span style="color:#b44">&#39;CentripetalHead&#39;</span>, <span style="color:#b44">&#39;VFNetHead&#39;</span>, <span style="color:#b44">&#39;TransformerHead&#39;</span>
]
</code></pre></div><p>几乎每个算法都包括一个独立的 head，而 roi_heads 比较杂，就不列出了。</p>
<p>需要注意的是：<strong>two-stage 或者 mutli-stage 算法，会额外包括一个区域提取器 roi extractor，用于将不同大小的 RoI 特征图统一成相同大小</strong>。</p>
<p>虽然 head 部分的网络构建比较简单，但是由于正负样本属性定义、正负样本采样和 bbox 编解码模块都在 head 模块中进行组合调用，故 MMDetection <strong>中最复杂的模块就是 head</strong>。在最后的整体流程部分会对该模块进行详细分析。</p>
<h3 id="enhance">Enhance</h3>
<div class="mermaid">
graph LR
	id1(SPP)---id2(ASP)---id3(Attention);
</div>
<p>enhance 是<strong>即插即用、能够对特征进行增强的模块</strong>，其具体代码可以通过 dict 形式注册到 backbone、neck 和 head 中，非常方便。常用的 enhance 模块是 SPP、ASPP、RFB、Dropout、Dropblock、DCN 和各种注意力模块 SeNet、Non_Local、CBA 等。目前 MMDetection 中部分模块支持 enhance 的接入，例如 ResNet 骨架中的 plugins。</p>
<h3 id="bbox-assigner">BBox Assigner</h3>
<p>正负样本属性分配模块作用是进行正负样本定义或者正负样本分配（可能也包括忽略样本定义），正样本就是常说的前景样本（可以是任何类别），负样本就是背景样本。因为目标检测是一个同时进行分类和回归的问题，对于分类场景必然需要确定正负样本，否则无法训练。<strong>该模块至关重要，不同的正负样本分配策略会带来显著的性能差异</strong>，目前大部分目标检测算法都会对这个部分进行改进，至关重要。</p>
<p>对应的代码在<code>mmdet/core/bbox/assigners</code>中，主要包括：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">__all__ <span style="color:#666">=</span> [
    <span style="color:#b44">&#39;BaseAssigner&#39;</span>, <span style="color:#b44">&#39;MaxIoUAssigner&#39;</span>, <span style="color:#b44">&#39;ApproxMaxIoUAssigner&#39;</span>, 
    <span style="color:#b44">&#39;PointAssigner&#39;</span>, <span style="color:#b44">&#39;ATSSAssigner&#39;</span>, <span style="color:#b44">&#39;CenterRegionAssigner&#39;</span>, <span style="color:#b44">&#39;GridAssigner&#39;</span>,
    <span style="color:#b44">&#39;HungarianAssigner&#39;</span>
]
</code></pre></div><h3 id="bbox-sampler">BBox Sampler</h3>
<p>在确定每个样本的正负属性后，可能还需要进行<strong class=chinese>样本平衡操作</strong>。本模块作用是<strong>对前面定义的正负样本不平衡进行采样，力争克服该问题</strong>。一般在目标检测中 gt bbox 都是非常少的，所以正负样本比是远远小于 1 的。而基于机器学习观点：在数据极度不平衡情况下进行分类会出现预测倾向于样本多的类别，出现过拟合，为了克服该问题，适当的正负样本采样策略是非常必要的。</p>
<p>对应的代码在<code>mmdet/core/bbox/samplers</code>中，主要包括：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">__all__ <span style="color:#666">=</span> [
    <span style="color:#b44">&#39;BaseSampler&#39;</span>, <span style="color:#b44">&#39;PseudoSampler&#39;</span>, <span style="color:#b44">&#39;RandomSampler&#39;</span>,
    <span style="color:#b44">&#39;InstanceBalancedPosSampler&#39;</span>, <span style="color:#b44">&#39;IoUBalancedNegSampler&#39;</span>, <span style="color:#b44">&#39;CombinedSampler&#39;</span>,
    <span style="color:#b44">&#39;OHEMSampler&#39;</span>, <span style="color:#b44">&#39;SamplingResult&#39;</span>, <span style="color:#b44">&#39;ScoreHLRSampler&#39;</span>
]
</code></pre></div><h3 id="training-tricks">Training tricks</h3>
<p>训练技巧非常多，常说的调参很大一部分工作都是在设置这部分超参。这部分内容比较杂乱，很难做到完全统一。</p>
<h2 id="test">Test</h2>
<p>测试核心组件和训练非常类似，但是简单很多，除了必备的网络构建部分外( backbone、neck、head 和 enhance )，不需要正负样本定义、正负样本采样和 loss 计算三个最难的部分，但是其额外需要一个 bbox 后处理模块和测试 trick。</p>
<h3 id="bbox-decoder">BBox Decoder</h3>
<p>训练时候进行了编码，那么对应的测试环节需要进行解码。根据编码的不同，解码也是不同的。举个简单例子：假设训练时候对宽高是直接除以图片宽高进行归一化的，那么解码过程也仅仅需要乘以图片宽高即可。其代码和 bbox encoder 放在一起，在<code>mmdet/core/bbox/coder</code>中。</p>
<h3 id="bbox-postprocess">BBox PostProcess</h3>
<p>在得到原图尺度 bbox 后，由于可能会出现重叠 bbox 现象，故一般都需要进行后处理，最常用的后处理就是非极大值抑制以及其变种。</p>
<p>其对应的文件在<code>mmdet/core/post_processing</code>中，主要包括：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">__all__ <span style="color:#666">=</span> [
    <span style="color:#b44">&#39;multiclass_nms&#39;</span>, <span style="color:#b44">&#39;merge_aug_proposals&#39;</span>, <span style="color:#b44">&#39;merge_aug_bboxes&#39;</span>,
    <span style="color:#b44">&#39;merge_aug_scores&#39;</span>, <span style="color:#b44">&#39;merge_aug_masks&#39;</span>, <span style="color:#b44">&#39;fast_nms&#39;</span>
]
</code></pre></div><h3 id="testing-tricks">Testing tricks</h3>
<p>为了提高检测性能，测试阶段也会采用 trick。这个阶段的 tricks 也非常多，难以完全统一，最典型的是多尺度测试以及各种模型集成手段，典型配置如下：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f">dict</span>(
    <span style="color:#a2f">type</span><span style="color:#666">=</span><span style="color:#b44">&#39;MultiScaleFlipAug&#39;</span>,
    img_scale<span style="color:#666">=</span>(<span style="color:#666">1333</span>, <span style="color:#666">800</span>),
    flip<span style="color:#666">=</span>True,
    transforms<span style="color:#666">=</span>[
        <span style="color:#a2f">dict</span>(<span style="color:#a2f">type</span><span style="color:#666">=</span><span style="color:#b44">&#39;Resize&#39;</span>, keep_ratio<span style="color:#666">=</span>True),
        <span style="color:#a2f">dict</span>(<span style="color:#a2f">type</span><span style="color:#666">=</span><span style="color:#b44">&#39;RandomFlip&#39;</span>),
        <span style="color:#a2f">dict</span>(<span style="color:#a2f">type</span><span style="color:#666">=</span><span style="color:#b44">&#39;Normalize&#39;</span>, <span style="color:#666">**</span>img_norm_cfg),
        <span style="color:#a2f">dict</span>(<span style="color:#a2f">type</span><span style="color:#666">=</span><span style="color:#b44">&#39;Pad&#39;</span>, size_divisor<span style="color:#666">=</span><span style="color:#666">32</span>),
        <span style="color:#a2f">dict</span>(<span style="color:#a2f">type</span><span style="color:#666">=</span><span style="color:#b44">&#39;ImageToTensor&#39;</span>, keys<span style="color:#666">=</span>[<span style="color:#b44">&#39;img&#39;</span>]),
        <span style="color:#a2f">dict</span>(<span style="color:#a2f">type</span><span style="color:#666">=</span><span style="color:#b44">&#39;Collect&#39;</span>, keys<span style="color:#666">=</span>[<span style="color:#b44">&#39;img&#39;</span>]),
    ])
</code></pre></div><h3 id="example">Example</h3>
<p>在分析完每个训练流程的各个核心组件后，为了方便大家理解整个算法构建，下面分析 MMDetection 是如何组合各个组件进行训练的，这里以 one-stage 检测器为例，two-stage 也比较类似。</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">SingleStageDetector</span>(<span style="color:#666">---</span>):

   <span style="color:#a2f;font-weight:bold">def</span> __init__(<span style="color:#666">...</span>):
        <span style="color:#080;font-style:italic"># 构建骨架、neck和head</span>
        self<span style="color:#666">.</span>backbone <span style="color:#666">=</span> build_backbone(backbone)
        <span style="color:#a2f;font-weight:bold">if</span> neck <span style="color:#a2f;font-weight:bold">is</span> <span style="color:#a2f;font-weight:bold">not</span> None:
            self<span style="color:#666">.</span>neck <span style="color:#666">=</span> build_neck(neck)
        self<span style="color:#666">.</span>bbox_head <span style="color:#666">=</span> build_head(bbox_head)

  <span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward_train</span>(<span style="color:#666">---</span>): 
        <span style="color:#080;font-style:italic"># 先运行backbone+neck进行特征提取</span>
        x <span style="color:#666">=</span> self<span style="color:#666">.</span>extract_feat(img)
        <span style="color:#080;font-style:italic"># 对head进行forward train，输出loss</span>
        losses <span style="color:#666">=</span> self<span style="color:#666">.</span>bbox_head<span style="color:#666">.</span>forward_train(x, img_metas, gt_bboxes,
                                              gt_labels, gt_bboxes_ignore)
        <span style="color:#a2f;font-weight:bold">return</span> losses

  <span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">simple_test</span>(<span style="color:#666">---</span>):
        <span style="color:#080;font-style:italic"># 先运行backbone+neck进行特征提取</span>
        x <span style="color:#666">=</span> self<span style="color:#666">.</span>extract_feat(img)
        <span style="color:#080;font-style:italic"># head输出预测特征图</span>
        outs <span style="color:#666">=</span> self<span style="color:#666">.</span>bbox_head(x)
        <span style="color:#080;font-style:italic"># bbox解码和还原</span>
        bbox_list <span style="color:#666">=</span> self<span style="color:#666">.</span>bbox_head<span style="color:#666">.</span>get_bboxes(
            <span style="color:#666">*</span>outs, img_metas, rescale<span style="color:#666">=</span>rescale)
        <span style="color:#080;font-style:italic"># 重组结果返回</span>
        bbox_results <span style="color:#666">=</span> [
            bbox2result(det_bboxes, det_labels, self<span style="color:#666">.</span>bbox_head<span style="color:#666">.</span>num_classes)
            <span style="color:#a2f;font-weight:bold">for</span> det_bboxes, det_labels <span style="color:#a2f;font-weight:bold">in</span> bbox_list
        ]
        <span style="color:#a2f;font-weight:bold">return</span> bbox_results
</code></pre></div><p>以上就是整个检测器算法训练和测试最简逻辑，可以发现训练部分最核心的就是<code>bbox_head.forward_train</code>，测试部分最核心的是<code>bbox_head.get_bboxes</code>，下面单独简要分析。</p>
<h4 id="bbox_headforward_train">bbox_head.forward_train</h4>
<p><code>forward_train</code> 是通用函数，如下所示：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward_train</span>(<span style="color:#666">...</span>):
    <span style="color:#080;font-style:italic"># 调用每个head自身的forward方法</span>
    outs <span style="color:#666">=</span> self(x)
    <span style="color:#a2f;font-weight:bold">if</span> gt_labels <span style="color:#a2f;font-weight:bold">is</span> None:
        loss_inputs <span style="color:#666">=</span> outs <span style="color:#666">+</span> (gt_bboxes, img_metas)
    <span style="color:#a2f;font-weight:bold">else</span>:
        loss_inputs <span style="color:#666">=</span> outs <span style="color:#666">+</span> (gt_bboxes, gt_labels, img_metas)
    <span style="color:#080;font-style:italic"># 计算每个head自身的loss方法</span>
    losses <span style="color:#666">=</span> self<span style="color:#666">.</span>loss(<span style="color:#666">*</span>loss_inputs, gt_bboxes_ignore<span style="color:#666">=</span>gt_bboxes_ignore)
    <span style="color:#080;font-style:italic"># 返回</span>
    <span style="color:#a2f;font-weight:bold">return</span> losses
</code></pre></div><p>对于不同的 head，虽然 forward 内容不一样，但是依然可以抽象为： <code>outs = self(x)</code></p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward</span>(self, feats):
   <span style="color:#080;font-style:italic"># 多尺度特征图，一个一个迭代进行forward_single</span>
   <span style="color:#a2f;font-weight:bold">return</span> multi_apply(self<span style="color:#666">.</span>forward_single, feats)

<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward_single</span>(self, x):
   <span style="color:#080;font-style:italic"># 运行各个head独特的head forward方法，得到预测图</span>
   <span style="color:#666">....</span>
   <span style="color:#a2f;font-weight:bold">return</span> cls_score, bbox_pred<span style="color:#666">...</span>
</code></pre></div><p>而对于不同的 head，其 loss 计算部分也比较复杂，可以简单抽象为：<code>losses = self.loss(...)</code></p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">loss</span>(<span style="color:#666">...</span>):
    <span style="color:#080;font-style:italic"># 1 生成anchor-base需要的anchor或者anchor-free需要的points</span>
    <span style="color:#080;font-style:italic"># 2 利用gt bbox对特征图或者anchor计算其正负和忽略样本属性</span>
    <span style="color:#080;font-style:italic"># 3 进行正负样本采样</span>
    <span style="color:#080;font-style:italic"># 4 对gt bbox进行bbox编码</span>
    <span style="color:#080;font-style:italic"># 5 loss计算，并返回</span>
    <span style="color:#a2f;font-weight:bold">return</span> <span style="color:#a2f">dict</span>(loss_cls<span style="color:#666">=</span>losses_cls, loss_bbox<span style="color:#666">=</span>losses_bbox,<span style="color:#666">...</span>)
</code></pre></div><h4 id="bbox_headget_bboxes">bbox_head.get_bboxes</h4>
<p><code>get_bboxes</code> 函数更加简单</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">get_bboxes</span>(<span style="color:#666">...</span>):
   <span style="color:#080;font-style:italic"># 1 生成anchor-base需要的anchor或者anchor-free需要的points</span>
   <span style="color:#080;font-style:italic"># 2 遍历每个输出层，遍历batch内部的每张图片，对每张图片先提取指定个数的预测结果，缓解后面后处理压力；对保留的位置进行bbox解码和还原到原图尺度</span>
   <span style="color:#080;font-style:italic"># 3 统一nms后处理</span>
   <span style="color:#a2f;font-weight:bold">return</span> det_bboxes, det_labels<span style="color:#666">...</span>
</code></pre></div><h2 id="conclusion">Conclusion</h2>
<p>本文重点分析了一个目标检测器是如何通过多个核心组件堆叠而成，不涉及具体代码，其中最应该了解的是：<strong>任何一个目标检测算法都可以分成 n 个核心组件，组件和组件之间是隔离的，方便复用和设计</strong>。当面对一个新算法时候我们可以先分析其主要是改进了哪几个核心组件，然后就可以高效的掌握该算法。</p>
<h1 id="reference">Reference</h1>
<ul>
<li>原文：<a href="https://zhuanlan.zhihu.com/p/337375549">轻松掌握 MMDetection 整体构建流程</a></li>
</ul>

    
  </article>
  <div class="paginator">
    
    <a class="link" href="https://preminstrel.github.io/blog/post/2022/01/14/faster-r-cnn/">← prev</a>
    
    
    <a class="link" href="https://preminstrel.github.io/blog/post/2022/01/16/mmdetection-framework/">next →</a>
    
  </div>
  <div class="comment">
    
    
    
    
    
    
  </div>
  
</main>

    <footer id="footer">
  <div>
    <span>© 2021</span> - <span>2022</span>
  </div>

  <div>
    <span>Powered by </span>
    <a class="link" href="https://gohugo.io/">Hugo</a>
    <span> 🍦 Theme </span>
    <a class="link" href="https://github.com/queensferryme/hugo-theme-texify">TeXify</a>
  </div>

  <div class="footnote">
    <span>Follow me on <a class=link href=https://github.com/preminstrel>GitHub</a>,
<a class=link href=https://twitter.com/preminstrel>Twitter</a> or
<a class=link href=/index.xml>RSS</a> |
<a class=link href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank rel=noopener>CC BY-NC-SA 4.0</a>
</span>
  </div>
</footer>

  </div>

  
  

  
  

  
  

</body>

</html>
