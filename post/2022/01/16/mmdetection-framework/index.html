<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">

  
  <meta name="author" content="Hanshi Sun">

  
  
  <meta name="description" content="本文核心内容是按照抽象到具体方式，从多个层次进行训练和测试流程深入解析，从最抽象层开始，到最后核心代码实现，进一步理解 MMDetection 开源框架整体构建细节">
  

  
  <link rel="icon" href="https://preminstrel.github.io/blog/favicon.ico">

  
  
  <meta name="keywords" content=" hugo  latex  theme ">
  

  
  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css"
  integrity="sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
  integrity="sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js"
  integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '\\[', right: '\\]', display: true },
        { left: '$', right: '$', display: false },
        { left: '\\(', right: '\\)', display: false }
      ],
      ignoredTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code', 'option'],
      throwOnError: false
    });
  });
</script>


  

  
  <meta property="og:title" content="MMDetection Framework" />
<meta property="og:description" content="本文核心内容是按照抽象到具体方式，从多个层次进行训练和测试流程深入解析，从最抽象层开始，到最后核心代码实现，进一步理解 MMDetection 开源框架整体构建细节" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://preminstrel.github.io/blog/post/2022/01/16/mmdetection-framework/" />
<meta property="article:published_time" content="2022-01-16T12:42:21+08:00" />
<meta property="article:modified_time" content="2022-01-16T00:00:00+00:00" />


  
  <link rel="canonical" href="https://preminstrel.github.io/blog/post/2022/01/16/mmdetection-framework/">

  
  
  <meta itemprop="name" content="MMDetection Framework">
<meta itemprop="description" content="本文核心内容是按照抽象到具体方式，从多个层次进行训练和测试流程深入解析，从最抽象层开始，到最后核心代码实现，进一步理解 MMDetection 开源框架整体构建细节">
<meta itemprop="datePublished" content="2022-01-16T12:42:21&#43;08:00" />
<meta itemprop="dateModified" content="2022-01-16T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="3849">



<meta itemprop="keywords" content="Object Detection,Deep Learning,MMDetection," />

  
  <link media="screen" rel="stylesheet" href='https://preminstrel.github.io/blog/css/common.css'>
  <link media="screen" rel="stylesheet" href='https://preminstrel.github.io/blog/css/content.css'>

  
  
  <title>MMDetection Framework - Blog de Preminstrel</title>
  

  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="MMDetection Framework"/>
<meta name="twitter:description" content="本文核心内容是按照抽象到具体方式，从多个层次进行训练和测试流程深入解析，从最抽象层开始，到最后核心代码实现，进一步理解 MMDetection 开源框架整体构建细节"/>


  
<link rel="stylesheet" href='https://preminstrel.github.io/blog/css/single.css'>

</head>

<body>
  <div id="wrapper">
    <header id="header">
  <h1>
    <a href="https://preminstrel.github.io/blog/">Blog de Preminstrel</a>
  </h1>

  <nav>
    
    <span class="nav-bar-item">
      <a class="link" href="/blog/">Post</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/blog/post/">Archives</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/blog/about/">About</a>
    </span>
    
  </nav>
</header>

    
<main id="main" class="post">
  
  
  <h1>MMDetection Framework</h1>
  
  <div>
    <b>Keywords: </b>
    
    <a class="link" href='https://preminstrel.github.io/blog/tags/object-detection'>#Object Detection</a>
    
    <a class="link" href='https://preminstrel.github.io/blog/tags/deep-learning'>#Deep Learning</a>
    
    <a class="link" href='https://preminstrel.github.io/blog/tags/mmdetection'>#MMDetection</a>
    
  </div>
  
  
  <article class="content">
    
    <p>本文核心内容是<strong>按照抽象到具体方式，从多个层次进行训练和测试流程深入解析</strong>，从最抽象层开始，到最后核心代码实现，进一步理解 MMDetection 开源框架整体构建细节。</p>
<h1 id="first-level">First Level</h1>
<div align=center>
<img src="/img/20220116124701.jpg" width="700px"/>
</div>
<p>上图为 MMDetection 框架整体训练和测试抽象流程图。按照数据流过程，训练流程可以简单总结为：</p>
<ol>
<li>给定任何一个数据集，首先需要构建 Dataset 类，用于迭代输出数据</li>
<li>在迭代输出数据的时候需要通过数据 Pipeline 对数据进行各种处理，最典型的处理流是训练中的<strong class=chinese>数据增强</strong>操作，测试中的<strong class=chinese>数据预处理</strong>等等</li>
<li>通过 Sampler 采样器可以控制 Dataset 输出的数据顺序，最常用的是随机采样器 <em><strong>RandomSampler</strong></em>。由于 Dataset 中输出的图片大小不一样，为了尽可能<strong>减少后续组成 batch 时 pad 的像素个数</strong>，MM-Detection 引入了分组采样器 GroupSampler 和 DistributedGroupSampler，相当于在 RandomSampler 基础上额外新增了根据图片宽高比进行 group 功能</li>
<li>将 Sampler 和 Dataset 都输入给 DataLoader，然后通过 DataLoader 输出已组成 batch 的数据，作为 Model 的输入</li>
<li>对于任何一个 Model，为了方便处理数据流以及分布式需求，MMDetection 引入了两个 Model 的上层封装：单机版本 MMDataParallel、分布式（单机多卡或多机多卡）版本 MMDistributedDataParallel</li>
<li>Model 运行后会输出 loss 以及其他一些信息，会通过 <em><strong>logger</strong></em> 进行保存或者可视化</li>
<li>为了更好地解耦， 方便地获取各个组件之间依赖和灵活扩展，MMDetection 引入了 <em><strong>Runner</strong></em> 类进行全生命周期管理，并且<strong>通过 Hook 方便的获取、修改和拦截任何生命周期数据流</strong>，扩展非常便捷</li>
</ol>
<p>而测试流程就比较简单了，直接对 DataLoader 输出的数据进行前向推理即可，还原到最终原图尺度过程也是在 Model 中完成。</p>
<p>以上就是 MMDetection 框架整体训练和测试抽象流程，上图不仅仅反映了训练和测试数据流，而且还包括了模块和模块之间的调用关系。对于训练而言，最核心部分应该是 Runner，理解了 Runner 的运行流程，也就理解了整个 MMDetection 数据流。</p>
<h1 id="second-level">Second Level</h1>
<p>在总体把握了整个 MMDetection 框架训练和测试流程后，下个层次是每个模块内部抽象流程，主要包括 Pipeline、DataParallel、Model、Runner 和 Hooks。</p>
<h2 id="pipeline">Pipeline</h2>
<p>Pipeline 实际上由一系列按照插入顺序运行的数据处理模块组成，每个模块完成某个特定功能，例如 Resize，因为其流式顺序运行特性，故叫做 Pipeline。</p>
<div align=center>
<img src="/img/20220116130000.jpg" width="800px"/>
</div>
<p>上图是一个非常典型的训练流程 Pipeline，每个类都接收字典输入，输出也是字典，顺序执行，其中<strong>绿色表示该类运行后新增字段，橙色表示对该字段可能会进行修改</strong>。如果进一步细分的话，不同算法的 Pipeline 都可以划分为如下部分：</p>
<ul>
<li><strong class=chinese>图片和标签加载</strong>，通常用的类是 LoadImageFromFile 和 LoadAnnotations</li>
<li><strong class=chinese>数据前处理</strong>，例如统一 Resize</li>
<li><strong class=chinese>数据增强</strong>，典型的例如各种图片几何变换等，这部分是训练流程特有，测试阶段一般不采用(多尺度测试采用其他实现方式)</li>
<li><strong class=chinese>数据收集</strong>，例如 Collect</li>
</ul>
<p>在 MMDetection 框架中，图片和标签加载和数据后处理流程一般是固定的，用户主要可能修改的是数据增强步骤，目前已经接入了第三方增强库 Albumentations，可以按照示例代码轻松构建属于你自己的数据增强 Pipeline。</p>
<p><strong>在构建自己的 Pipeline 时候一定要仔细检查修改或者新增的字典 key 和 value，因为一旦错误地覆盖或者修改原先字典里面的内容，代码也可能不会报错，如果出现 bug，则比较难排查</strong>。</p>
<h2 id="dataparallel--model">DataParallel &amp; Model</h2>
<p>在 MMDetection 中 DataLoader 输出的内容<strong>不是 PyTorch 能处理的标准格式</strong>，还包括了 <em><strong>DataContainer</strong></em> 对象，该对象的作用是包装不同类型的对象使之能按需组成 batch。在目标检测中，每张图片 gt bbox 个数是不一样的，如果想组成 batch tensor，要么你设置最大长度，要么你自己想办法组成 batch。而考虑到内存和效率，MMDetection 通过引入 DataContainer 模块来解决上述问题，但是随之带来的问题是 PyTorch 无法解析 DataContainer 对象，故需要在 MMDetection 中自行处理。</p>
<p>解决办法其实非常多，MMDetection 选择了一种比较优雅的实现方式：MMDataParallel 和 MMDistributed-DataParallel。具体来说，这两个类相比 PyTorch 自带的 DataParallel 和 DistributedDataParallel 区别是：</p>
<ul>
<li>可以处理 DataContainer 对象</li>
<li>额外实现了 <code>train_step()</code> 和 <code>val_step()</code> 两个函数，可以被 Runner 调用</li>
</ul>
<p>关于这两个类的具体实现后面会描述。</p>
<h2 id="runner-和-hooks">Runner 和 Hooks</h2>
<p>对于任何一个目标检测算法，都需要包括<strong>优化器、学习率设置、权重保存</strong>等等组件才能构成完整训练流程，而这些组件是通用的。为了方便 OpenMMLab 体系下的所有框架复用，在 MMCV 框架中引入了 Runner 类来统一管理训练和验证流程，并且通过 Hooks 机制以一种非常灵活、解耦的方式来实现丰富扩展功能。</p>
<p>关于 Runner 和 Hooks 详细解读会发布在 MMCV 系列解读文章中，简单来说 <strong>Runner 封装了 OpenMMLab 体系下各个框架的训练和验证详细流程，其负责管理训练和验证过程中的整个生命周期，通过预定义回调函数，用户可以插入定制化 Hook ，从而实现各种各样的需求</strong>。下面列出了在 MMDetection 几个非常重要的 hook 以及其作用的生命周期：</p>
<div align=center>
<img src="/img/20220116131700.jpg" width="600px"/>
</div>
<p>例如 CheckpointHook 在每个训练 epoch 完成后会被调用，从而实现保存权重功能。用户也可以将自己定制实现的 Hook 采用上述方式绘制，对理解整个流程或许有帮助。</p>
<h1 id="third-level">Third Level</h1>
<p>前面两层抽象分析流程，基本上把整个 MMDetection 的训练和测试流程分析完了，下面从具体代码层面进行抽象分析。</p>
<h2 id="train--test">Train &amp; Test</h2>
<div align=center>
<img src="/img/20220116131900.jpg" width="600px"/>
</div>
上图为训练和验证的和具体代码相关的整体抽象流程，对应到代码上，其核心代码如下：
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-style:italic">#=================== tools/train.py ==================</span>
<span style="color:#080;font-style:italic"># 1.初始化配置</span>
cfg <span style="color:#666">=</span> Config<span style="color:#666">.</span>fromfile(args<span style="color:#666">.</span>config)

<span style="color:#080;font-style:italic"># 2.判断是否为分布式训练模式</span>

<span style="color:#080;font-style:italic"># 3.初始化 logger</span>
logger <span style="color:#666">=</span> get_root_logger(log_file<span style="color:#666">=</span>log_file, log_level<span style="color:#666">=</span>cfg<span style="color:#666">.</span>log_level)

<span style="color:#080;font-style:italic"># 4.收集运行环境并且打印，方便排查硬件和软件相关问题</span>
env_info_dict <span style="color:#666">=</span> collect_env()

<span style="color:#080;font-style:italic"># 5.初始化 model</span>
model <span style="color:#666">=</span> build_detector(cfg<span style="color:#666">.</span>model, <span style="color:#666">...</span>)

<span style="color:#080;font-style:italic"># 6.初始化 datasets</span>

<span style="color:#080;font-style:italic">#=================== mmdet/apis/train.py ==================</span>
<span style="color:#080;font-style:italic"># 1.初始化 data_loaders ，内部会初始化 GroupSampler</span>
data_loader <span style="color:#666">=</span> DataLoader(dataset,<span style="color:#666">...</span>)

<span style="color:#080;font-style:italic"># 2.基于是否使用分布式训练，初始化对应的 DataParallel</span>
<span style="color:#a2f;font-weight:bold">if</span> distributed:
  model <span style="color:#666">=</span> MMDistributedDataParallel(<span style="color:#666">...</span>)
<span style="color:#a2f;font-weight:bold">else</span>:
  model <span style="color:#666">=</span> MMDataParallel(<span style="color:#666">...</span>)

<span style="color:#080;font-style:italic"># 3.初始化 runner</span>
runner <span style="color:#666">=</span> EpochBasedRunner(<span style="color:#666">...</span>)

<span style="color:#080;font-style:italic"># 4.注册必备 hook</span>
runner<span style="color:#666">.</span>register_training_hooks(cfg<span style="color:#666">.</span>lr_config, optimizer_config,
                               cfg<span style="color:#666">.</span>checkpoint_config, cfg<span style="color:#666">.</span>log_config,
                               cfg<span style="color:#666">.</span>get(<span style="color:#b44">&#39;momentum_config&#39;</span>, None))

<span style="color:#080;font-style:italic"># 5.如果需要 val，则还需要注册 EvalHook           </span>
runner<span style="color:#666">.</span>register_hook(eval_hook(val_dataloader, <span style="color:#666">**</span>eval_cfg))

<span style="color:#080;font-style:italic"># 6.注册用户自定义 hook</span>
runner<span style="color:#666">.</span>register_hook(hook, priority<span style="color:#666">=</span>priority)

<span style="color:#080;font-style:italic"># 7.权重恢复和加载</span>
<span style="color:#a2f;font-weight:bold">if</span> cfg<span style="color:#666">.</span>resume_from:
    runner<span style="color:#666">.</span>resume(cfg<span style="color:#666">.</span>resume_from)
<span style="color:#a2f;font-weight:bold">elif</span> cfg<span style="color:#666">.</span>load_from:
    runner<span style="color:#666">.</span>load_checkpoint(cfg<span style="color:#666">.</span>load_from)

<span style="color:#080;font-style:italic"># 8.运行，开始训练</span>
runner<span style="color:#666">.</span>run(data_loaders, cfg<span style="color:#666">.</span>workflow, cfg<span style="color:#666">.</span>total_epochs)
</code></pre></div><p>上面的流程比较简单，一般大家比较难以理解的是 <code>runner.run</code> 内部逻辑，下小节进行详细分析，而对于测试逻辑由于比较简单，就不详细描述了，简单来说测试流程下不需要 runner，直接加载训练好的权重，然后进行 model 推理即可。</p>
<h2 id="runner">Runner</h2>
<p>runner 对象内部的 run 方式是一个通用方法，可以运行任何 workflow，目前常用的主要是 train 和 val。</p>
<ul>
<li>当配置为：workflow = [(&lsquo;train&rsquo;, 1)]，表示仅仅进行 train workflow，也就是迭代训练</li>
<li>当配置为：workflow = [(&lsquo;train&rsquo;, n),(&lsquo;val&rsquo;, 1)]，表示先进行 n 个 epoch 的训练，然后再进行1个 epoch 的验证，然后循环往复,如果写成 [(&lsquo;val&rsquo;, 1),(&lsquo;train&rsquo;, n)] 表示先进行验证，然后才开始训练</li>
</ul>
<p>当进入对应的 workflow，则会调用 runner 里面的 train() 或者 val()，表示进行一次 epoch 迭代。其代码也非常简单，如下所示：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">train</span>(self, data_loader, <span style="color:#666">**</span>kwargs):
    self<span style="color:#666">.</span>model<span style="color:#666">.</span>train()
    self<span style="color:#666">.</span>mode <span style="color:#666">=</span> <span style="color:#b44">&#39;train&#39;</span>
    self<span style="color:#666">.</span>data_loader <span style="color:#666">=</span> data_loader
    self<span style="color:#666">.</span>call_hook(<span style="color:#b44">&#39;before_train_epoch&#39;</span>)
    <span style="color:#a2f;font-weight:bold">for</span> i, data_batch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">enumerate</span>(self<span style="color:#666">.</span>data_loader):
        self<span style="color:#666">.</span>call_hook(<span style="color:#b44">&#39;before_train_iter&#39;</span>)
        self<span style="color:#666">.</span>run_iter(data_batch, train_mode<span style="color:#666">=</span>True)
        self<span style="color:#666">.</span>call_hook(<span style="color:#b44">&#39;after_train_iter&#39;</span>)

    self<span style="color:#666">.</span>call_hook(<span style="color:#b44">&#39;after_train_epoch&#39;</span>)


<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">val</span>(self, data_loader, <span style="color:#666">**</span>kwargs):
    self<span style="color:#666">.</span>model<span style="color:#666">.</span>eval()
    self<span style="color:#666">.</span>mode <span style="color:#666">=</span> <span style="color:#b44">&#39;val&#39;</span>
    self<span style="color:#666">.</span>data_loader <span style="color:#666">=</span> data_loader
    self<span style="color:#666">.</span>call_hook(<span style="color:#b44">&#39;before_val_epoch&#39;</span>)
    <span style="color:#a2f;font-weight:bold">for</span> i, data_batch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#a2f">enumerate</span>(self<span style="color:#666">.</span>data_loader):
        self<span style="color:#666">.</span>call_hook(<span style="color:#b44">&#39;before_val_iter&#39;</span>)
        <span style="color:#a2f;font-weight:bold">with</span> torch<span style="color:#666">.</span>no_grad():
            self<span style="color:#666">.</span>run_iter(data_batch, train_mode<span style="color:#666">=</span>False)
        self<span style="color:#666">.</span>call_hook(<span style="color:#b44">&#39;after_val_iter&#39;</span>)
    self<span style="color:#666">.</span>call_hook(<span style="color:#b44">&#39;after_val_epoch&#39;</span>)
</code></pre></div><p>核心函数实际上是 self.run_iter()，如下：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">run_iter</span>(self, data_batch, train_mode, <span style="color:#666">**</span>kwargs):
    <span style="color:#a2f;font-weight:bold">if</span> train_mode:
        <span style="color:#080;font-style:italic"># 对于每次迭代，最终是调用如下函数</span>
        outputs <span style="color:#666">=</span> self<span style="color:#666">.</span>model<span style="color:#666">.</span>train_step(data_batch,<span style="color:#666">...</span>)
    <span style="color:#a2f;font-weight:bold">else</span>:
        <span style="color:#080;font-style:italic"># 对于每次迭代，最终是调用如下函数</span>
        outputs <span style="color:#666">=</span> self<span style="color:#666">.</span>model<span style="color:#666">.</span>val_step(data_batch,<span style="color:#666">...</span>)

    <span style="color:#a2f;font-weight:bold">if</span> <span style="color:#b44">&#39;log_vars&#39;</span> <span style="color:#a2f;font-weight:bold">in</span> outputs:
        self<span style="color:#666">.</span>log_buffer<span style="color:#666">.</span>update(outputs[<span style="color:#b44">&#39;log_vars&#39;</span>],<span style="color:#666">...</span>)
    self<span style="color:#666">.</span>outputs <span style="color:#666">=</span> outputs
</code></pre></div><p>上述 self.call_hook() 表示在不同生命周期调用所有已经注册进去的 hook，而字符串参数表示对应的生命周期。以 OptimizerHook 为例，其执行反向传播、梯度裁剪和参数更新等核心训练功能：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a2f">@HOOKS.register_module</span>()
<span style="color:#a2f;font-weight:bold">class</span> <span style="color:#00f">OptimizerHook</span>(Hook):

    <span style="color:#a2f;font-weight:bold">def</span> __init__(self, grad_clip<span style="color:#666">=</span>None):
        self<span style="color:#666">.</span>grad_clip <span style="color:#666">=</span> grad_clip

    <span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">after_train_iter</span>(self, runner):
        runner<span style="color:#666">.</span>optimizer<span style="color:#666">.</span>zero_grad()
        runner<span style="color:#666">.</span>outputs[<span style="color:#b44">&#39;loss&#39;</span>]<span style="color:#666">.</span>backward()
        <span style="color:#a2f;font-weight:bold">if</span> self<span style="color:#666">.</span>grad_clip <span style="color:#a2f;font-weight:bold">is</span> <span style="color:#a2f;font-weight:bold">not</span> None:
            grad_norm <span style="color:#666">=</span> self<span style="color:#666">.</span>clip_grads(runner<span style="color:#666">.</span>model<span style="color:#666">.</span>parameters())
        runner<span style="color:#666">.</span>optimizer<span style="color:#666">.</span>step()
</code></pre></div><p>可以发现 OptimizerHook 注册到的生命周期是 after_train_iter，故在每次 train() 里面运行到 <code>self.call_hook('after_val_iter')</code> 时候就会被调用，其他 hook 也是同样运行逻辑。</p>
<h2 id="model">Model</h2>
<p>前面说个，训练和验证的时候实际上调用了 model 内部的 <code>train_step</code> 和 <code>val_step</code> 函数，<strong>理解了两个函数调用流程就理解了 MMDetection 训练和测试流程</strong>。</p>
<p>注意，由于 model 对象会被 DataParallel 类包裹，故实际上上此时的 model，是指的 MMDataParallel 或者 MMDistributedDataParallel。以非分布式 train_step 流程为例，其内部完成调用流程图示如下：</p>
<div align=center>
<img src="/img/20220116132200.jpg" width="600px"/>
</div>
<h2 id="train--val">Train &amp; Val</h2>
<p><strong>(1) 调用 runner 中的 <code>train_step</code> 或者 <code>val_step</code></strong></p>
<p>在 runner 中调用 <code>train_step</code> 或者 <code>val_step</code>，代码如下：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-style:italic">#=================== mmcv/runner/epoch_based_runner.py ==================</span>
<span style="color:#a2f;font-weight:bold">if</span> train_mode:
    outputs <span style="color:#666">=</span> self<span style="color:#666">.</span>model<span style="color:#666">.</span>train_step(data_batch,<span style="color:#666">...</span>)
<span style="color:#a2f;font-weight:bold">else</span>:
    outputs <span style="color:#666">=</span> self<span style="color:#666">.</span>model<span style="color:#666">.</span>val_step(data_batch,<span style="color:#666">...</span>)
</code></pre></div><p>实际上，首先会调用 DataParallel 中的 <code>train_step</code> 或者 <code>val_step</code> ，其具体调用流程为：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-style:italic"># 非分布式训练</span>
<span style="color:#080;font-style:italic">#=================== mmcv/parallel/data_parallel.py/MMDataParallel ==================</span>
<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">train_step</span>(self, <span style="color:#666">*</span>inputs, <span style="color:#666">**</span>kwargs):
    <span style="color:#a2f;font-weight:bold">if</span> <span style="color:#a2f;font-weight:bold">not</span> self<span style="color:#666">.</span>device_ids:
        inputs, kwargs <span style="color:#666">=</span> self<span style="color:#666">.</span>scatter(inputs, kwargs, [<span style="color:#666">-</span><span style="color:#666">1</span>])
        <span style="color:#080;font-style:italic"># 此时才是调用 model 本身的 train_step</span>
        <span style="color:#a2f;font-weight:bold">return</span> self<span style="color:#666">.</span>module<span style="color:#666">.</span>train_step(<span style="color:#666">*</span>inputs, <span style="color:#666">**</span>kwargs)
    <span style="color:#080;font-style:italic"># 单 gpu 模式</span>
    inputs, kwargs <span style="color:#666">=</span> self<span style="color:#666">.</span>scatter(inputs, kwargs, self<span style="color:#666">.</span>device_ids)
    <span style="color:#080;font-style:italic"># 此时才是调用 model 本身的 train_step</span>
    <span style="color:#a2f;font-weight:bold">return</span> self<span style="color:#666">.</span>module<span style="color:#666">.</span>train_step(<span style="color:#666">*</span>inputs[<span style="color:#666">0</span>], <span style="color:#666">**</span>kwargs[<span style="color:#666">0</span>])

<span style="color:#080;font-style:italic"># val_step 也是的一样逻辑</span>
<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">val_step</span>(self, <span style="color:#666">*</span>inputs, <span style="color:#666">**</span>kwargs):
    inputs, kwargs <span style="color:#666">=</span> self<span style="color:#666">.</span>scatter(inputs, kwargs, self<span style="color:#666">.</span>device_ids)
    <span style="color:#080;font-style:italic"># 此时才是调用 model 本身的 val_step</span>
    <span style="color:#a2f;font-weight:bold">return</span> self<span style="color:#666">.</span>module<span style="color:#666">.</span>val_step(<span style="color:#666">*</span>inputs[<span style="color:#666">0</span>], <span style="color:#666">**</span>kwargs[<span style="color:#666">0</span>])
</code></pre></div><p>可以发现，在调用 model 本身的 train_step 前，需要额外调用 scatter 函数，前面说过该函数的作用是处理 DataContainer 格式数据，使其能够组成 batch，否则程序会报错。</p>
<p>如果是分布式训练，则调用的实际上是 <code>mmcv/parallel/distributed.py/MMDistributedDataParallel</code>，最终调用的依然是 model 本身的 <code>train_step</code> 或者 <code>val_step</code>。</p>
<p><strong>(2) 调用 model 中的 <code>train_step</code> 或者 <code>val_step</code></strong></p>
<p>其核心代码如下：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-style:italic">#=================== mmdet/models/detectors/base.py/BaseDetector ==================</span>
<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">train_step</span>(self, data, optimizer):
    <span style="color:#080;font-style:italic"># 调用本类自身的 forward 方法</span>
    losses <span style="color:#666">=</span> self(<span style="color:#666">**</span>data)
    <span style="color:#080;font-style:italic"># 解析 loss</span>
    loss, log_vars <span style="color:#666">=</span> self<span style="color:#666">.</span>_parse_losses(losses)
    <span style="color:#080;font-style:italic"># 返回字典对象</span>
    outputs <span style="color:#666">=</span> <span style="color:#a2f">dict</span>(
        loss<span style="color:#666">=</span>loss, log_vars<span style="color:#666">=</span>log_vars, num_samples<span style="color:#666">=</span><span style="color:#a2f">len</span>(data[<span style="color:#b44">&#39;img_metas&#39;</span>]))
    <span style="color:#a2f;font-weight:bold">return</span> outputs

<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward</span>(self, img, img_metas, return_loss<span style="color:#666">=</span>True, <span style="color:#666">**</span>kwargs):
    <span style="color:#a2f;font-weight:bold">if</span> return_loss:
        <span style="color:#080;font-style:italic"># 训练模式</span>
        <span style="color:#a2f;font-weight:bold">return</span> self<span style="color:#666">.</span>forward_train(img, img_metas, <span style="color:#666">**</span>kwargs)
    <span style="color:#a2f;font-weight:bold">else</span>:
        <span style="color:#080;font-style:italic"># 测试模式</span>
        <span style="color:#a2f;font-weight:bold">return</span> self<span style="color:#666">.</span>forward_test(img, img_metas, <span style="color:#666">**</span>kwargs)
</code></pre></div><p><code>forward_train</code> 和 <code>forward_test</code> 需要在不同的算法子类中实现，输出是 Loss 或者 预测结果。</p>
<p><strong>(3) 调用子类中的 <code>forward_train</code> 方法</strong></p>
<p>目前提供了两个具体子类，<code>TwoStageDetector</code> 和 <code>SingleStageDetector</code> ，用于实现 two-stage 和 single-stage 算法。</p>
<p>对于 <code>TwoStageDetector</code> 而言，其核心逻辑是：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-style:italic">#============= mmdet/models/detectors/two_stage.py/TwoStageDetector ============</span>
<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward_train</span>(<span style="color:#666">...</span>):
    <span style="color:#080;font-style:italic"># 先进行 backbone+neck 的特征提取</span>
    x <span style="color:#666">=</span> self<span style="color:#666">.</span>extract_feat(img)
    losses <span style="color:#666">=</span> <span style="color:#a2f">dict</span>()
    <span style="color:#080;font-style:italic"># RPN forward and loss</span>
    <span style="color:#a2f;font-weight:bold">if</span> self<span style="color:#666">.</span>with_rpn:
        <span style="color:#080;font-style:italic"># 训练 RPN</span>
        proposal_cfg <span style="color:#666">=</span> self<span style="color:#666">.</span>train_cfg<span style="color:#666">.</span>get(<span style="color:#b44">&#39;rpn_proposal&#39;</span>,
                                          self<span style="color:#666">.</span>test_cfg<span style="color:#666">.</span>rpn)
        <span style="color:#080;font-style:italic"># 主要是调用 rpn_head 内部的 forward_train 方法</span>
        rpn_losses, proposal_list <span style="color:#666">=</span> self<span style="color:#666">.</span>rpn_head<span style="color:#666">.</span>forward_train(x,<span style="color:#666">...</span>)
        losses<span style="color:#666">.</span>update(rpn_losses)
    <span style="color:#a2f;font-weight:bold">else</span>:
        proposal_list <span style="color:#666">=</span> proposals
    <span style="color:#080;font-style:italic"># 第二阶段，主要是调用 roi_head 内部的 forward_train 方法</span>
    roi_losses <span style="color:#666">=</span> self<span style="color:#666">.</span>roi_head<span style="color:#666">.</span>forward_train(x, <span style="color:#666">...</span>)
    losses<span style="color:#666">.</span>update(roi_losses)
    <span style="color:#a2f;font-weight:bold">return</span> losses
</code></pre></div><p>对于 <code>SingleStageDetector</code> 而言，其核心逻辑是：</p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-style:italic">#============= mmdet/models/detectors/single_stage.py/SingleStageDetector ============</span>
<span style="color:#a2f;font-weight:bold">def</span> <span style="color:#00a000">forward_train</span>(<span style="color:#666">...</span>):
    <span style="color:#a2f">super</span>(SingleStageDetector, self)<span style="color:#666">.</span>forward_train(img, img_metas)
    <span style="color:#080;font-style:italic"># 先进行 backbone+neck 的特征提取</span>
    x <span style="color:#666">=</span> self<span style="color:#666">.</span>extract_feat(img)
    <span style="color:#080;font-style:italic"># 主要是调用 bbox_head 内部的 forward_train 方法</span>
    losses <span style="color:#666">=</span> self<span style="color:#666">.</span>bbox_head<span style="color:#666">.</span>forward_train(x, <span style="color:#666">...</span>)
    <span style="color:#a2f;font-weight:bold">return</span> losses
</code></pre></div><p>如果再往里分析，那就到各个 Head 模块的训练环节了，这部分内容请读者自行分析，应该不难。</p>
<h2 id="test">Test</h2>
<p>由于没有 runner 对象，测试流程简单很多，下面简要概述：</p>
<ol>
<li>调用 MMDataParallel 或 MMDistributedDataParallel 中的 <code>forward</code> 方法</li>
<li>调用 base.py 中的 <code>forward</code> 方法</li>
<li>调用 base.py 中的 <code>self.forward_test</code> 方法</li>
<li>如果是单尺度测试，则会调用 TwoStageDetector 或 SingleStageDetector 中的 <code>simple_test</code> 方法，如果是多尺度测试，则调用 <code>aug_test</code> 方法</li>
<li>最终调用的是每个具体算法 Head 模块的 <code>simple_test</code> 或者 <code>aug_test</code> 方法</li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>本文从三个层面全面解读了 MMDetection 框架，对 MMDetection 框架设计思想、组件间关系和整体代码实现流程有一定的了解。</p>
<h1 id="reference">Reference</h1>
<ul>
<li>原文：<a href="https://zhuanlan.zhihu.com/p/341954021">轻松掌握 MMDetection 整体构建流程</a></li>
</ul>

    
  </article>
  <div class="paginator">
    
    <a class="link" href="https://preminstrel.github.io/blog/post/2022/01/15/mmdetection-overview/">← prev</a>
    
    
    <a class="link" href="https://preminstrel.github.io/blog/post/2022/01/17/mmdetection-head/">next →</a>
    
  </div>
  <div class="comment">
    
    
    
    
    
    
  </div>
  
</main>

    <footer id="footer">
  <div>
    <span>© 2021</span> - <span>2022</span>
  </div>

  <div>
    <span>Powered by </span>
    <a class="link" href="https://gohugo.io/">Hugo</a>
    <span> 🍦 Theme </span>
    <a class="link" href="https://github.com/queensferryme/hugo-theme-texify">TeXify</a>
  </div>

  <div class="footnote">
    <span>Follow me on <a class=link href=https://github.com/preminstrel>GitHub</a>,
<a class=link href=https://twitter.com/preminstrel>Twitter</a> or
<a class=link href=/index.xml>RSS</a> |
<a class=link href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank rel=noopener>CC BY-NC-SA 4.0</a>
</span>
  </div>
</footer>

  </div>

  
  

  
  

  
  

</body>

</html>
